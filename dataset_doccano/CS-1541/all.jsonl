{"id":103,"segment": ["train_set", "labeled"],  "course": "cs1541", "lec": "lec2.3_optimizing_pipeline_hazards","text":"Optimizing Pipeline Hazards\nCS 1541\nWonsun Ahn\n\n\fSolving Structural Hazards\n\n2\n\n\fStructural Hazard on Memory\n● Two instructions need to use the same hardware at the same time.\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nlw t0,0($0)\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nlw t1,4($0)\n\nlw t2,8($0)\n\nlw t3,12($0)\n\n5\n\n6\n\n7\n\nWB\n\n3\n\n\fWhat could we do??\n● Two people need to use one sink at the same time\no Well, in this case, it’s memory but same idea\n\n4\n\n\fWe can do something similar!\n● One option is to wait (a.k.a. stall).\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nlw t0,0($0)\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nYou know\nwhat’s worse?\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nlw t2,8($0)\n\nIF\n\nID\n\nEX\n\nMEM\n\nlw t3,12($0)\n\nThe pattern is\ngoing to repeat\n\nWAIT!\n\nIF\nWAIT!\n\nWAIT!\n\nlw t1,4($0)\n\n5\n\n6\n\n7\n\nWB\n\nIF\n\n5\n\n\fOr we could throw in more hardware!\n● For less commonly used CPU resources, stalling can work fine\n● But memory (and some other things) is used CONSTANTLY\n● How do the bathrooms solve this problem?\no Throw in lots of sinks!\no In other words, throw more hardware at the problem!\n● Memory's a resource with a lot of contention\no So have two memories, one for instructions, and one for data!\no Not literally but CPUs have separate instruction and data caches\n\n6\n\n\fStructural Hazard removed with two Memories\n● With separate i-cache and d-cache, MEM and IF can work in parallel\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nlw t0,0($0)\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nlw t1,4($0)\n\nlw t2,8($0)\n\nlw t3,12($0)\n\n5\n\n6\n\n7\n\nWB\n\n7\n\n\fStructural Hazard removed with two Memories\n● But is that the only hardware duplication going on here?\n\nInstruction\nMemory\n\nIns. Decoder\n\nPC\n\nPCSrc\n\n+\n\n4\n\n+\n\nimm field\n\ndst\nsrc1\nsrc2\n\nRegDataSrc\n\nData\nMemory\n\nRegister\nFile\n\nRegWrite\n\nimm field\n\nsxt\n\nMemWrite\n\nALUSrc\n\nALUOp\n\n8\n\n\fStructural Hazards removed with Multiple Adders\n● Why do we need 3 adders? To avoid stalls due to contention on ALU!\nEX Stage\n\nInstruction\nMemory\n\nIns. Decoder\n\nPC\n\nPCSrc\n\n+\n\n4\n\n+\n\nimm field\n\nIF Stage dst\nsrc1\nsrc2\n\nRegDataSrc\n\nData\nMemory\n\nRegister\nFile\n\nRegWrite\n\nimm field\n\nsxt\n\nMemWrite\n\nALUSrc\n\nALUOp\n\n9\n\n\fSolving Structural Hazards\n● There are mainly two ways to throw more hardware at the problem\n\n1. Duplicate contentious resource\no One memory cannot sustain MEM + IF stage at same cycle\n→ Duplicate into one instruction memory, one data memory\no One ALU cannot sustain IF + EX stage at same cycle\n→ Duplicate into one ALU and two simple adders\n2. Add ports to a single shared memory resource\no Port: Circuitry that allows either read or write access to memory\no If current number of ports cannot sustain rate of access per cycle\n→ Add more ports to memory structure for simultaneous access\n\n10\n\n\fTwo Register Read Ports\n● By adding more MUXes, you can add even more read ports\n\n11\n\n\fOne Register Write Port\n● By adding more decoders, you can add more write ports\n\n12\n\n\fTwo Register Write + Two Register Read Ports\n\nDave Tweed (https:\/\/electronics.stackexchange.com\/users\/11683\/dave-tweed),\nBuild A Two Port Write and Two Port Read Register File with 4 Registers, URL (version: 2017-02-21):\nhttps:\/\/electronics.stackexchange.com\/q\/273002\n\n13\n\n\fTwo read ports and one write port is the minimum\n● 2 read ports for 2 source registers, 1 write port for dest register\no Enough to sustain one ID and one WB stage per cycle\no Enough to sustain CPI = 1 (or in other words IPC = 1)\n● But what if we want an IPC > 1? (a.k.a superscalar processor)\no Must sustain more than one ID \/ WB stage per cycle\no Need more register read ports and write ports!\no Not only registers, (cache) memory would need more ports too!\n→ Muxes, decoders increase critical path (lowers frequency)\n→ Extra circuitry consumes more power\n\n● We’ll talk more about this when we discuss superscalars\n\n14\n\n\fSolving Data Hazards\n\n15\n\n\fData Hazards\n● An instruction depends on the output of a previous one.\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nadd t0,t1,t2\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nsub s0,t0,t1\n\n5\n\n6\n\n7\n\nWB\n\n● When does add finish computing its sum?\n● Well then... why not just use the sum when we need it?\n\n16\n\n\fSolution 1: Data Forwarding\n● Since we've pipelined control signals, we can check if instructions in\nthe pipeline depend on each other (see if registers match).\n● If we detect any dependencies, we can forward the needed data.\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nadd t0,t1,t2\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nsub s0,t0,t1\n\n5\n\n6\n\n7\n\nWB\n\n● This handles one kind of data forwarding...\n● Where else can data come from and be written into registers?\n● Memory!\n17\n\n\fData Forwarding from Memory\n● Well memory accesses happen a cycle later...\n● What are we going to have to do?\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nlw t0,0(t4)\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nsub s0,t0,t1\n\nWAIT!\n\nEX\n\n5\n\n6\n\nMEM\n\nWB\n\n7\n\n● This kind of stall is unavoidable in our current pipeline\n\n18\n\n\fForwarding Unit and Use-after-load-hazard\nIf dependent on MemRead (load) instruction,\neven forwarding unit can’t avoid stall\n\n19\n\n\fForwarding Unit\n● Just like the HDU, the Forwarding Unit is power hungry\n\n● Number of forwarding wires ∝ (pipeline stages)2\no Why the quadratic relationship?\no Per pipeline stage, N stages after it from which data is forwarded\n▪ In previous picture, see number of inputs to MUX before ALU!\no And there are N stages to which data must be forwarded\n▪ In previous picture, only one EX stage is shown,\nbut if there are multiple stages, need MUXes in all those stages\n● Deep pipelining has diminishing returns on power investment\no Cycle time improves by a factor of N\no Power consumption increases by a factor of N2 (or more)\no Not the only problem with deep pipelining that we will see\n20\n\n\fSolution 2: Avoid stalls by reordering\n● Let’s say the following is your morning routine (2 hours total)\n1. Have laundry running in washing machine (30 minutes)\n2. Have laundry running in dryer (30 minutes)\n3. Have some tea boiling in the pot (30 minutes)\n4. Drink tea (30 minutes)\n\n1\n2\n3\n\n4\n● Can you make this shorter? Yes! (1 hour total)\n1. Have washing machine running and 3. Tea boiling (30 minutes)\n2. Have dryer running and 4. Drink tea (30 minutes)\n\n● How? By simply by reordering our actions\no Steps 1 → 2 and 3 → 4 have data dependencies\no Other steps can be freely reordered with each other\n\n1\n\n3\n\n2\n\n4\n\n21\n\n\fData Hazard removed through Compiler Reordering\n● If the compiler has knowledge of how the pipeline works, it can\nreorder instructions to let loads complete before using their data.\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\nlw t0,0(t4)\n\nsub s0,t0,t1\n\nlw t2,4(t4)\n\nsub s1,t2,t3\n\n22\n\n\fData Hazard removed through Compiler Reordering\n● If the compiler has knowledge of how the pipeline works, it can\nreorder instructions to let loads complete before using their data.\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nlw t0,0(t4)\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nlw t2,4(t4)\nsub s0,t0,t1\n\nsub s1,t2,t3\n\n5\n\n6\n\n7\n\nWB\n\n23\n\n\fLimits of Static Scheduling\n● Reordering done by the compiler is called static scheduling\n\n● Static scheduling is a powerful tool but is in some ways limited\no Again, compiler must make assumptions about pipeline\n▪ Length of MEM stage is very hard to predict by the compiler\n▪ Remember the Memory Wall?\no Data dependencies are hard to figure out by a compiler\n▪ When data is in registers, trivial to figure out\n▪ When data is in memory locations, more difficult. Given:\nlw t0,0(t4)\nsw s0,8(t0) We want to reorder to remove the data hazard.\nlw t2,4(t4) But what if 8(t0) and 4(t4) are the same addresses?\n\nThis involves pointer analysis, a notoriously difficult analysis!\n24\n\n\fDynamic scheduling is another option\n● Dynamic scheduling is scheduling done by the CPU\n\n● It doesn’t have the limitations of static scheduling\no It doesn’t have to predict memory latency\n▪ It can adapt as things unfold\no It’s easy to figure out data dependencies, even memory ones\n▪ At runtime, addresses of 8(t0) and 4(t4) are easily calculated\n● But at runtime it uses lots of power for the data analysis\no … which again causes problems with the Power Wall\no But more on this later\n\n25\n\n\fSolving Control Hazards\n\n26\n\n\fLoops\n● Loops happen all the time in programs.\n\nfor(s0 = 0 .. 10)\nprint(s0);\nprintf(\"done\");\nHow often does this\nblt instruction go to\ntop? How often does\nit go to the following\nla instruction?\n\nli\n\ns0, 0\n\ntop:\nmove a0, s0\njal print\naddi s0, s0, 1\nblt s0, 10, top\nla\njal\n\na0, done_msg\nprintf\n\n27\n\n\fPipeline Flushes at Every Loop Iteration\n● The pipeline must be flushed every time the code loops back!\nTime\n\nblt s0,10,top\n\nla a0,done_msg\n\njal printf\ns0 < 10...\nOOPS!\nmove a0,s0\n\n0\n\n1\n\n2\n\n3\n\n4\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nIF\n\nID\n\n5\n\n6\n\n7\n\nEX\n\nMEM\n\nWB\n\nIF\n\n28\n\n\fPerformance Impact from Control Hazards\n● Frequency of flushes ∝ frequency of branches\no If we have a tight loop, branches happen every few instructions\no Typically, branches account for 15~20% of all instructions\n● Penalty from one flush ∝ depth of pipeline\no Number of flushed instructions == distance from IF to EX\no What if 3 IF stages, 4 ID stages, and 3 EX stages? Penalty == 10!\n\n● Current architectures can have more than 20 stages!\no May spend more time just flushing instructions than doing work!\no Another reason why deep pipelines are problematic\n\n29\n\n\fPerformance Impact from Control Hazards\n● CPI = CPInch + a * p * K\n\no CPInch : CPI with no control hazard\no a : fraction of branch instructions in the instruction mix\no p : probability a branch is actually taken\no K : penalty per pipeline flush\n\nExample: If 20% of instructions are branches and the probability that a\nbranch is taken is 50%, and pipeline flush penalty 7 cycles, then:\nCPI = CPInch + 0.2 * 0.5 * 7 = CPInch + 0.7 cycles per instruction\n\n● What if we had a compiler insert no-ops, with no HDU?\no It’s even worse, as we will soon see.\n\n30\n\n\fCompiler avoiding the control hazard without HDU\n● Since compiler does not know direction, must always insert two nops\nCycle\n\n1\n\n2\n\n3\n\n4\n\n5\n\nblt s0,10,top\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nIF\n\nID\n\nEX\n\nMEM\n\nnop\n\nnop\n\nmove a0,s0\n\n6\n\n7\n\n8\n\nWB\n\n31\n\n\fPerformance Impact without Hazard Detection Unit\n● CPI = CPInch + a * K\n\no CPInch : CPI with no control hazard\no a : fraction of branch instructions in the instruction mix\no K : no-ops inserted after each branch\n\nExample: If 20% of instructions are branches and the probability that a\nbranch is taken is 50%, and branch resolution delay of 7 no-ops, then:\nCPI = CPInch + 0.2 * 7 = CPInch + 1.4 cycles per instruction\n\no Branch-taken rate is irrelevant - compiler always inserts two nops\n● Is there a way to minimize the performance impact?\n\n32\n\n\fSolution 1: Delay Slots\n● Idea: Use compiler static scheduling to fill no-ops with useful work\no Remember? We did the same for no-ops due to data hazards.\n● Delay slot: One or more instructions immediately following a\nbranch instruction that executes regardless of branch direction\no Processor never needs to flush these instructions!\no ISA must be modified to support this branch semantic\no It’s compiler’s job to fill delay slots as best as it can,\nwith instructions not control dependent on the branch\n\n33\n\n\fCompiler static scheduling using delay slots\nblt s0, 10, else\nnop # Delay slot\nthen:\nadd t0, t1, t0\nj\nmerge\nelse:\nadd t1, t1, t0\nmerge:\naddi t2, t2, 1\n\nblt s0, 10, else\naddi t2, t2, 1 # Slot\nthen:\nadd t0, t1, t0\nj\nmerge\nelse:\nadd t1, t1, t0\nmerge:\n…\n\n• The addi instruction is moved into delay slot\n\no It is not control dependent on the branch outcome of blt\no It is not data dependent on registers t0 or t1\n34\n\n\fDelay slots are losing popularity\n● Sounded like a good idea on paper but didn’t work well in practice\n\n1. Turns out filling delay slots with the compiler is not always easy\no Often data and control independent instructions don’t exist\n2. Delay slots baked into the ISA were not future proof\no Number of delay slots did not match new generation of CPUs\no New generation of CPUs had fancier ways to avoid bubbles\no Delays slots ended up being a hindrance\n● Next idea please!\n\n35\n\n\fSolution 2: MORE SINKS! (a.k.a. hardware)\n\n36\n\n\fDo we reeeally need to compare at EX stage?\n● What if branch comparison was done at the ID stage, not EX stage?\nTime\n\nblt s0,10,top\n\nla a0,done_msg\ns0 < 10...\nOOPS!\nmove a0,s0\n\n0\n\n1\n\n2\n\n3\n\n4\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\n5\n\n6\n\nMEM\n\nWB\n\n7\n\nIF\n\n● Reduced penalty from 2 cycles → 1 cycle!\n● But of course that means we need a comparator at the ID stage\n37\n\n\fSolution 2: MORE SINKS! (a.k.a. hardware)\nExtra comparator to determine branch direction\nInstead of doing it here\n\n38\n\n\fNot all sunshine and rainbows\n● Extra delay on data hazards. Used to have no delay:\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nsub t0,t1,t2\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nbeq t0,$0,end\n\n5\n\n6\n\n7\n\n5\n\n6\n\n7\n\nMEM\n\nWB\n\nWB\n\n● Now we need to insert one bubble even with forwarding:\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nsub t0,t1,t2\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\nWAIT!\n\nID\n\nEX\n\nbeq t0,$0,end\n\n39\n\n\fNot all sunshine and rainbows\n● Extra delay on data forwarded from lw also:\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nlw t0,0($t1)\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\nWAIT!\n\nID\nWAIT!\n\nID\n\nbeq t0,$0,end\n\n5\n\n6\n\n7\n\nEX\n\nMEM\n\nWB\n\n● Now we must insert two bubbles instead of one!\n● Not to mention we must now add more forwarding paths:\n● EX → ID, MEM → ID\n● We also need to add MUXes before our new comparator\n\n40\n\n\fTextbook figure correction\nThe figure in textbook is incomplete.\nNeeds MUXes and forwarding lines just like the ALU.\n\n41\n\n\f","label":[[11,27,"Concept"],[57,75,"Concept"],[81,98,"Concept"],[102,108,"Concept"],[210,212,"Concept"],[214,216,"Concept"],[218,220,"Concept"],[222,225,"Concept"],[227,229,"Concept"],[231,233,"Concept"],[235,237,"Concept"],[239,241,"Concept"],[243,246,"Concept"],[248,250,"Concept"],[252,254,"Concept"],[256,258,"Concept"],[260,262,"Concept"],[264,267,"Concept"],[269,271,"Concept"],[273,275,"Concept"],[277,279,"Concept"],[281,283,"Concept"],[285,288,"Concept"],[339,341,"Concept"],[444,450,"Concept"],[531,536,"Concept"],[573,575,"Concept"],[577,579,"Concept"],[581,583,"Concept"],[585,588,"Concept"],[590,592,"Concept"],[618,620,"Concept"],[622,624,"Concept"],[626,628,"Concept"],[630,633,"Concept"],[635,637,"Concept"],[652,654,"Concept"],[656,658,"Concept"],[660,662,"Concept"],[664,667,"Concept"],[722,724,"Concept"],[761,763,"Concept"],[765,767,"Concept"],[849,857,"Concept"],[878,884,"Concept"],[1053,1061,"Concept"],[1087,1097,"Concept"],[1112,1120,"Concept"],[1192,1228,"Concept"],[1234,1251,"Concept"],[1269,1277,"Concept"],[1294,1301,"Concept"],[1306,1313,"Concept"],[1315,1318,"Concept"],[1323,1325,"Concept"],[1381,1383,"Concept"],[1385,1387,"Concept"],[1389,1391,"Concept"],[1393,1396,"Concept"],[1398,1400,"Concept"],[1402,1404,"Concept"],[1406,1408,"Concept"],[1410,1412,"Concept"],[1414,1417,"Concept"],[1419,1421,"Concept"],[1423,1425,"Concept"],[1427,1429,"Concept"],[1431,1433,"Concept"],[1435,1438,"Concept"],[1440,1442,"Concept"],[1444,1446,"Concept"],[1448,1450,"Concept"],[1452,1454,"Concept"],[1456,1459,"Concept"],[1510,1512,"Concept"],[1518,1535,"Concept"],[1553,1561,"Concept"],[1585,1605,"Concept"],[1622,1640,"Concept"],[1642,1654,"Concept"],[1656,1658,"Concept"],[1714,1725,"Concept"],[1727,1740,"Concept"],[1797,1815,"Concept"],[1881,1887,"Concept"],[1895,1905,"Concept"],[1909,1912,"Concept"],[1914,1916,"Concept"],[1924,1942,"Concept"],[1944,1956,"Concept"],[1958,1960,"Concept"],[2025,2036,"Concept"],[2038,2051,"Concept"],[2116,2134,"Concept"],[2205,2235,"Concept"],[2242,2248,"Concept"],[2264,2267,"Concept"],[2270,2272,"Concept"],[2287,2292,"Concept"],[2314,2332,"Concept"],[2338,2349,"Concept"],[2356,2359,"Concept"],[2375,2377,"Concept"],[2380,2382,"Concept"],[2424,2427,"Concept"],[2457,2462,"Concept"],[2500,2504,"Concept"],[2559,2565,"Concept"],[2589,2594,"Concept"],[2629,2634,"Concept"],[2646,2651,"Concept"],[2655,2671,"Concept"],[2715,2725,"Concept"],[2743,2748,"Concept"],[2772,2782,"Concept"],[2802,2812,"Concept"],[2830,2838,"Concept"],[2857,2868,"Concept"],[2875,2919,"Concept"],[3008,3012,"Concept"],[3027,3031,"Concept"],[3153,3163,"Concept"],[3172,3182,"Concept"],[3202,3212,"Concept"],[3239,3249,"Concept"],[3292,3294,"Concept"],[3303,3305,"Concept"],[3342,3345,"Concept"],[3419,3440,"Concept"],[3471,3473,"Concept"],[3476,3478,"Concept"],[3489,3494,"Concept"],[3516,3526,"Concept"],[3531,3542,"Concept"],[3567,3572,"Concept"],[3574,3580,"Concept"],[3597,3602,"Concept"],[3610,3615,"Concept"],[3617,3625,"Concept"],[3635,3648,"Concept"],[3657,3666,"Concept"],[3700,3705,"Concept"],[3779,3791,"Concept"],[3798,3810,"Concept"],[3904,3906,"Concept"],[3908,3910,"Concept"],[3912,3914,"Concept"],[3916,3919,"Concept"],[3921,3923,"Concept"],[3925,3927,"Concept"],[3929,3931,"Concept"],[3933,3935,"Concept"],[3937,3940,"Concept"],[3965,3967,"Concept"],[4086,4101,"Concept"],[4116,4125,"Concept"],[4126,4141,"Concept"],[4179,4187,"Concept"],[4254,4266,"Concept"],[4275,4282,"Concept"],[4335,4337,"Concept"],[4339,4341,"Concept"],[4343,4345,"Concept"],[4347,4350,"Concept"],[4352,4354,"Concept"],[4356,4358,"Concept"],[4360,4362,"Concept"],[4364,4366,"Concept"],[4368,4371,"Concept"],[4396,4398,"Concept"],[4427,4442,"Concept"],[4511,4517,"Concept"],[4524,4539,"Concept"],[4545,4551,"Concept"],[4584,4589,"Concept"],[4668,4670,"Concept"],[4672,4674,"Concept"],[4676,4678,"Concept"],[4680,4683,"Concept"],[4685,4687,"Concept"],[4689,4691,"Concept"],[4693,4695,"Concept"],[4718,4720,"Concept"],[4728,4731,"Concept"],[4733,4735,"Concept"],[4755,4760,"Concept"],[4806,4821,"Concept"],[4826,4847,"Concept"],[4897,4912,"Concept"],[4925,4930,"Concept"],[4937,4952,"Concept"],[4969,4972,"Concept"],[4978,4993,"Concept"],[5043,5058,"Concept"],[5101,5115,"Concept"],[5119,5125,"Concept"],[5154,5163,"Concept"],[5211,5214,"Concept"],[5222,5225,"Concept"],[5245,5251,"Concept"],[5316,5318,"Concept"],[5319,5324,"Concept"],[5361,5367,"Concept"],[5374,5379,"Concept"],[5393,5399,"Concept"],[5402,5417,"Concept"],[5464,5474,"Concept"],[5503,5520,"Concept"],[5587,5602,"Concept"],[5643,5649,"Concept"],[5653,5663,"Concept"],[6103,6113,"Concept"],[6201,6210,"Concept"],[6245,6256,"Concept"],[6273,6292,"Concept"],[6336,6344,"Concept"],[6359,6366,"Concept"],[6516,6527,"Concept"],[6544,6563,"Concept"],[6607,6615,"Concept"],[6630,6637,"Concept"],[6732,6734,"Concept"],[6736,6738,"Concept"],[6740,6742,"Concept"],[6744,6747,"Concept"],[6749,6751,"Concept"],[6753,6755,"Concept"],[6757,6759,"Concept"],[6761,6763,"Concept"],[6765,6768,"Concept"],[6770,6772,"Concept"],[6774,6776,"Concept"],[6778,6780,"Concept"],[6782,6784,"Concept"],[6786,6789,"Concept"],[6791,6793,"Concept"],[6795,6797,"Concept"],[6799,6801,"Concept"],[6803,6805,"Concept"],[6807,6810,"Concept"],[6861,6863,"Concept"],[6880,6897,"Concept"],[6900,6910,"Concept"],[6923,6931,"Concept"],[6942,6959,"Concept"],[6963,6980,"Concept"],[7074,7082,"Concept"],[7095,7098,"Concept"],[7160,7171,"Concept"],[7175,7192,"Concept"],[7489,7505,"Concept"],[7546,7564,"Concept"],[7585,7603,"Concept"],[7672,7689,"Concept"],[7792,7809,"Concept"],[7995,8005,"Concept"],[8045,8060,"Concept"],[8365,8373,"Concept"],[8374,8381,"Concept"],[8412,8420,"Concept"],[8429,8436,"Concept"],[8561,8563,"Concept"],[8565,8567,"Concept"],[8569,8571,"Concept"],[8573,8576,"Concept"],[8578,8580,"Concept"],[8582,8584,"Concept"],[8586,8588,"Concept"],[8590,8592,"Concept"],[8594,8596,"Concept"],[8607,8609,"Concept"],[8611,8614,"Concept"],[8616,8618,"Concept"],[8620,8622,"Concept"],[8653,8668,"Concept"],[8671,8680,"Concept"],[8684,8691,"Concept"],[8862,8867,"Concept"],[8879,8887,"Concept"],[8900,8907,"Concept"],[9097,9105,"Concept"],[9157,9171,"Concept"],[9218,9233,"Concept"],[9682,9688,"Concept"],[9698,9701,"Concept"],[9771,9785,"Concept"],[9794,9797,"Concept"],[9863,9867,"Concept"],[9905,9907,"Concept"],[9909,9911,"Concept"],[9913,9915,"Concept"],[9917,9920,"Concept"],[9922,9924,"Concept"],[9926,9932,"Concept"],[9934,9940,"Concept"],[9942,9948,"Concept"],[9950,9956,"Concept"],[9958,9964,"Concept"],[9966,9972,"Concept"],[9974,9980,"Concept"],[9982,9988,"Concept"],[9990,9996,"Concept"],[9998,10004,"Concept"],[10006,10008,"Concept"],[10010,10012,"Concept"],[10014,10016,"Concept"],[10018,10021,"Concept"],[10023,10026,"Concept"],[10028,10031,"Concept"],[10054,10056,"Concept"],[10090,10111,"Concept"],[10114,10117,"Concept"],[10147,10150,"Concept"],[10159,10173,"Concept"],[10241,10247,"Concept"],[10405,10411,"Concept"],[10545,10549,"Concept"],[10621,10632,"Concept"],[10654,10671,"Concept"],[10680,10686,"Concept"],[10736,10742,"Concept"],[10750,10762,"Concept"],[10766,10776,"Concept"],[11029,11040,"Concept"],[11129,11146,"Concept"],[11408,11418,"Concept"],[11533,11544,"Concept"],[11658,11669,"Concept"],[11772,11783,"Concept"],[11837,11848,"Concept"],[11937,11944,"Concept"],[11947,11959,"Concept"],[12095,12097,"Concept"],[12149,12151,"Concept"],[12163,12165,"Concept"],[12253,12255,"Concept"],[12257,12259,"Concept"],[12261,12263,"Concept"],[12265,12268,"Concept"],[12270,12272,"Concept"],[12274,12276,"Concept"],[12278,12280,"Concept"],[12282,12284,"Concept"],[12292,12295,"Concept"],[12297,12299,"Concept"],[12388,12398,"Concept"],[12406,12408,"Concept"],[12468,12478,"Concept"],[12587,12599,"Concept"],[12659,12661,"Concept"],[12663,12665,"Concept"],[12667,12669,"Concept"],[12671,12674,"Concept"],[12676,12678,"Concept"],[12680,12682,"Concept"],[12684,12686,"Concept"],[12688,12690,"Concept"],[12692,12695,"Concept"],[12730,12733,"Concept"],[12735,12737,"Concept"],[12739,12741,"Concept"],[12771,12777,"Concept"],[12788,12798,"Concept"],[12835,12837,"Concept"],[12839,12841,"Concept"],[12843,12845,"Concept"],[12847,12850,"Concept"],[12852,12854,"Concept"],[12856,12858,"Concept"],[12860,12862,"Concept"],[12870,12872,"Concept"],[12874,12876,"Concept"],[12945,12959,"Concept"],[13009,13011,"Concept"],[13013,13015,"Concept"],[13017,13019,"Concept"],[13021,13024,"Concept"],[13026,13028,"Concept"],[13030,13032,"Concept"],[13034,13036,"Concept"],[13044,13046,"Concept"],[13054,13056,"Concept"],[13082,13084,"Concept"],[13086,13089,"Concept"],[13091,13093,"Concept"],[13120,13127,"Concept"],[13182,13198,"Concept"],[13202,13204,"Concept"],[13207,13209,"Concept"],[13211,13214,"Concept"],[13217,13219,"Concept"],[13242,13247,"Concept"],[13263,13273,"Concept"],[13351,13356,"Concept"],[13361,13377,"Concept"],[13392,13395,"Concept"]],"Comments":[]}
{"id": 104, "segment": ["train_set", "labeled"],  "course": "cs1541", "lec": "lec2.2_pipelining", "text": "Processor Pipelining\nCS 1541\nWonsun Ahn\n\n\fPipelining Basics\n\n2\n\n\fImproving Washer / Dryer / Closet Utilization\n\n\u25cf If you work on loads of laundry one by one, you only get ~33% utilization\n\u25cf If you form an \u201cassembly line\u201d, you achieve ~100% utilization!\n\n3\n\n\fMulti-cycle instruction execution\n\u25cf Let's watch how an instruction flows through the datapath.\n\nadd\nMemory\n\nClock!\n\nID\nSet all control signals...\n\nIns. Decoder\n\nIF\n\nClock!\n\nRegister\nFile\n\nEX\n\nClock!\n\nMEM\n\nAdd...\n\nALU\n\nMemory\n\nClock!\nData flows back to registers...\n\nWB\n4\n\n\fPipelined instruction execution\n\u25cf Pipelining allows one instruction to be fetched each cycle!\n\nadd\nsub\nsw\nMemory\n\nID\nIns. Decoder\n\nIF\n\nRegister\nFile\n\nEX\n\nALU\n\nMEM\n\nMemory\n\nWB\n5\n\n\fPipelining Timeline\n\u25cf This type of parallelism is called pipelined parallelism.\nCycle\n\n1\n\n2\n\n3\n\n4\n\n5\n\nadd t0,t1,t2\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nadd t3,t4,t5\n\nadd s0,s1,s2\n\nadd s3,s4,s5\n\n6\n\n7\n\n8\n\nWB\n\n6\n\n\fA Pipelined Implementation is even Faster!\n\u25cf Again each instruction takes different number of cycles to complete\no lw takes 5 cycles: IF/ID/EX/MEM/WB\no add takes 4 cycles: IF/ID/EX/WB\n\u25cf If each stage takes 1 ns each:\no lw takes 5 ns and add takes 4 ns\nQ) The average instruction execution time (given 100 instructions)?\nA) (99 ns + 5 ns) / 100 = 1.04 ns\no Assuming last instruction is a lw (a 5-cycle instruction)\no A ~5X speed up from single cycle!\n\n7\n\n\fPipelined vs. Multi-cycle vs. Single-cycle\n\u25cf What happened to the three components of performance?\ninstructions\nX\nprogram\n\ncycles\ninstruction\n\nArchitecture\n\nInstructions\n\nCPI\n\nCycle Time\n(1/F)\n\nSingle-cycle\n\nSame\n\n1\n\n5 ns\n\nMulti-cycle\n\nSame\n\n4~5\n\n1 ns\n\nPipelined\n\nSame\n\n1\n\n1 ns\n\nX\n\nseconds\ncycle\n\n\u25cf Compared to single-cycle, pipelining improves clock cycle time\no Or in other words CPU clock frequency\no The deeper the pipeline, the higher the frequency will be\n* Caveat: latch delay and unbalanced stages can increase cycle time\n8\n\n\fHow about the control signals?\n\nMemory\n\nRegister\nFile\n\nALU\n\nMEM\n\nWB\n\nEX\n\nMEM/WB\n\nID\nIns. Decoder\n\nIF\n\nEX/MEM/WB\n\n\u25cf A new instruction is decoded at every cycle!\n\u25cf Control signals must be passed along with the data at each stage\n\nMemory\n\nWB\n9\n\n\fPipeline Hazards\n\n10\n\n\fPipeline Hazards\n\u25cf For pipelined CPUs, we said CPI is practically 1\no But that depends entirely on having the pipeline filled\no In real life, there are hazards that prevent 100% utilization\n\u25cf Pipeline Hazard\no When the next instruction cannot execute in the following cycle\no Hazards introduce bubbles (delays) into the pipeline timeline\n\u25cf Architects have some tricks up their sleeves to avoid hazards\n\u25cf But first let\u2019s briefly talk about the three types of hazards:\nStructural hazard, Data hazard, Control Hazard\n\n11\n\n\fStructural Hazards\n\u25cf Two instructions need to use the same hardware at the same time.\nCycle\n\n1\n\n2\n\n3\n\n4\n\n5\n\nlw t0,0($0)\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nlw t1,4($0)\n\nlw t2,8($0)\n\nlw t3,12($0)\n\n6\n\n7\n\n8\n\nWB\n\n12\n\n\fData Hazards\n\u25cf An instruction depends on the output of a previous one.\nCycle\n\n1\n\n2\n\n3\n\n4\n\n5\n\nadd t0,t1,t2\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nsub s0,t0,t1\n\n6\n\n7\n\n8\n\nWB\n\n\u25cf sub must wait until add's WB phase is over before doing its ID phase\nadd t0,t1,t2\n\nsub s0,t0,t1\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nbubble\n\nbubble\n\nbubble\n\nID\n\nEX\n\nMEM\n13\n\n\fControl Hazards\n\u25cf You don't know the outcome of a conditional branch.\nCycle\n\n1\n\n2\n\n3\n\n4\n\n5\n\nbeq t0,$0,end\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nadd t0,t1,t2\n\n6\n\n7\n\n8\n\nWB\n\n\u25cf add must wait until beq\u2019s EX phase is over before its IF phase\nbeq t0,$0,end\n\nadd t0,t1,t2\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nbubble\n\nbubble\n\nIF\n\nID\n\nEX\n\nWB\n14\n\n\fDealing with Hazards\n\u25cf Pipeline must be controlled so that hazards don\u2019t cause malfunction\n\u25cf Who is in charge of that? You have a choice.\n1. Compiler can avoid hazards by inserting nops\n\u00a7 Insert a nop where compiler thinks a hazard would happen\n2. CPU can internally avoid hazards using a hazard detection unit\n\u00a7 If structural/data hazard, pipeline stalled until resolved\n\u00a7 If control hazard, pipeline flushed of wrong path instructions\n\n15\n\n\fCompiler avoiding a data hazard\n\u25cf The nops flow through the pipeline not doing any work\nCycle\n\n1\n\n2\n\n3\n\n4\n\n5\n\nadd t0,t1,t2\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nIF\n\nID\n\nEX\n\nMEM\n\nnop\n\nnop\n\nnop\n\nsub s0,t0,t1\n\n6\n\n7\n\n8\n\n16\n\n\fCompiler avoiding a control hazard\n\u25cf The nops give time for condition to resolve before instruction fetch\nCycle\n\n1\n\n2\n\n3\n\n4\n\n5\n\nbeq t0,$0,end\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nbubble\n\nIF\n\nID\n\nEX\n\nMEM\n\nnop\n\nnop\n\nadd t0,t1,t2\n\n6\n\n7\n\n8\n\nWB\n\n17\n\n\fHazard Detection Unit\nCreates bubbles by zeroing all control signals,\nthereby creating a nop instruction\n\nFreezes IF and ID until\nhazard is resolved\n18\n\n\fHazard Detection Unit avoiding a data hazard\n\u25cf Suppose we have an add that depends on an lw.\n\nsub\nadd\nlw\n\nID\nIns. Decoder\n\nIF\n\nEX\n\nMEM\n\nWAIT!\n\nMemory\n\nRegister\nFile\n\nALU\n\nMemory\n\nWB\n19\n\n\fStructural / Data Hazards cause stalls\n\u25cf If HDU detects a structural or data hazard, it does the following:\no It stops fetching instructions (doesn't update the PC).\no It stops clocking the pipeline registers for the stalled stages.\no The stages after the stalled instructions are filled with nops.\n\u00a7 Change control signals to 0 using the mux!\no In this way, all following instructions will be stalled\n\u25cf When structural or data hazard is resolved\no HDU resumes instruction fetching and clocking of stalled stages\n\u25cf But what about control hazards?\no Instructions in wrong path are already in pipeline!\no Need to flush these instructions\n20\n\n\fControl Hazard Example\n\u25cf Supposed we had this for loop followed by printf(\u201cdone\u201d):\n\nfor(s0 = 0 .. 10)\nprint(s0);\nprintf(\"done\");\nBy the time s0, 10\nare compared at blt\nEX stage, the CPU\nwould have already\nfetched la and jal!\n\nli\n\ns0, 0\n\ntop:\nmove a0, s0\njal print\naddi s0, s0, 1\nblt s0, 10, top\nla\njal\n\na0, done_msg\nprintf\n\n21\n\n\fWhat's a flush?\n\u25cf A pipeline flush removes all wrong path instructions from pipeline\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\nblt s0,10,top\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nP OW\n\nIF\n\nBO\n\nla a0,done_msg\n\njal printf\ns0 < 10...\nOOPS!\nmove a0,s0\n\n5\n\n6\n\n7\n\nEX\n\nMEM\n\nWB\n\nOM\n\nIF\n\nID\n\n22\n\n\fHazard Detection Unit avoiding a control hazard\n\u25cf Let's watch the previous example.\n\nmove\nblt\njal\nla\nMemory\n\nID\nnop\n\nIns. Decoder\n\nIF\n\nEX\n\nMEM\n\nnop\nRegister\nFile\n\nALU\n\nMemory\n\nWB\n23\n\n\fControl Hazards cause flushes\n\u25cf If a control hazard is detected due to a branch instruction:\no Any \"newer\" instructions (those already in the pipeline)\n\u2192 transformed into nops.\no Any \"older\" instructions (those that came BEFORE the branch)\n\u2192 left alone to finish executing as normal.\n\n24\n\n\fPerformance penalty of pipeline stalls\n\u25cf Remember the three components of performance:\ninstructions\nX\nprogram\n\ncycles\ninstruction\n\nX\n\nseconds\ncycle\n\nArchitecture\n\nInstructions\n\nCPI\n\nCycle Time (1/F)\n\nSingle-cycle\n\nSame\n\n1\n\n5 ns\n\nIdeal 5-stage pipeline\n\nSame\n\n1\n\n1 ns\n\nPipeline w/ stalls\n\nSame\n\n2\n\n1 ns\n\n\u25cf Pipelining increases clock frequency proportionate to depth\n\u25cf But stalls increase CPI (cycles per instruction)\no If stalls prevent new instructions from being fetched half the time,\nthe CPU will have a CPI of 2 \u2192 Only 2.5X speed up (instead of 5X)\n\u25cf We\u2019d like to avoid this penalty if possible!\n25\n\n\fCompiler nops vs. CPU Hazard Detection Unit\n\u25cf Limitations of compiler nops\no Compiler must make assumptions about processor design\n\u00a7 That means processor design must become part of ISA\n\u00a7 What if that design is no longer ideal in future generations?\no Length of MEM stage is very hard to predict by the compiler\n\u00a7 Until now we assumed MEM takes a uniform one cycle\n\u00a7 But remember what we said about the Memory Wall?\n\u00a7 MEM isn\u2019t uniform really and sometimes hundreds of cycles\n\u25cf But compiler nops is very energy-efficient\no Hazard Detection Unit can be power hungry\n\u00a7 A lot of long wires controlling remote parts of the CPU\n\u00a7 Adds to the Power Wall problem\no Compiler scheduling via nops removes need for HDU\n26", "label": [[0, 20, "Concept"], [42, 52, "Concept"], [358, 364, "Concept"], [374, 376, "Concept"], [405, 417, "Concept"], [419, 421, "Concept"], [423, 428, "Concept"], [431, 444, "Concept"], [446, 448, "Concept"], [450, 455, "Concept"], [458, 461, "Concept"], [471, 474, "Concept"], [476, 482, "Concept"], [484, 489, "Concept"], [524, 526, "Concept"], [531, 540, "Concept"], [565, 575, "Concept"], [637, 643, "Concept"], [645, 647, "Concept"], [648, 660, "Concept"], [662, 664, "Concept"], [666, 679, "Concept"], [681, 683, "Concept"], [685, 688, "Concept"], [690, 693, "Concept"], [695, 701, "Concept"], [703, 705, "Concept"], [710, 720, "Concept"], [745, 756, "Concept"], [767, 788, "Concept"], [826, 828, "Concept"], [830, 832, "Concept"], [834, 836, "Concept"], [838, 841, "Concept"], [843, 845, "Concept"], [847, 849, "Concept"], [851, 853, "Concept"], [855, 857, "Concept"], [859, 862, "Concept"], [864, 866, "Concept"], [868, 870, "Concept"], [872, 874, "Concept"], [876, 878, "Concept"], [880, 883, "Concept"], [885, 887, "Concept"], [889, 891, "Concept"], [893, 895, "Concept"], [897, 899, "Concept"], [901, 904, "Concept"], [957, 959, "Concept"], [967, 976, "Concept"], [1059, 1065, "Concept"], [1091, 1097, "Concept"], [1099, 1101, "Concept"], [1102, 1104, "Concept"], [1105, 1107, "Concept"], [1108, 1111, "Concept"], [1112, 1114, "Concept"], [1129, 1135, "Concept"], [1137, 1139, "Concept"], [1140, 1142, "Concept"], [1143, 1145, "Concept"], [1146, 1148, "Concept"], [1420, 1429, "Concept"], [1434, 1445, "Concept"], [1450, 1462, "Concept"], [1506, 1517, "Concept"], [1591, 1594, "Concept"], [1596, 1606, "Concept"], [1614, 1626, "Concept"], [1643, 1654, "Concept"], [1673, 1682, "Concept"], [1731, 1743, "Concept"], [1745, 1755, "Concept"], [1765, 1781, "Concept"], [1806, 1821, "Concept"], [1839, 1847, "Concept"], [1864, 1873, "Concept"], [1968, 1983, "Concept"], [1986, 1992, "Concept"], [1994, 2007, "Concept"], [2009, 2012, "Concept"], [2014, 2017, "Concept"], [2019, 2021, "Concept"], [2023, 2025, "Concept"], [2027, 2030, "Concept"], [2031, 2033, "Concept"], [2035, 2037, "Concept"], [2038, 2050, "Concept"], [2052, 2054, "Concept"], [2056, 2058, "Concept"], [2059, 2062, "Concept"], [2063, 2065, "Concept"], [2090, 2097, "Concept"], [2107, 2112, "Concept"], [2116, 2131, "Concept"], [2182, 2188, "Concept"], [2190, 2192, "Concept"], [2197, 2213, "Concept"], [2220, 2236, "Concept"], [2243, 2252, "Concept"], [2330, 2338, "Concept"], [2372, 2379, "Concept"], [2412, 2427, "Concept"], [2488, 2493, "Concept"], [2496, 2503, "Concept"], [2514, 2521, "Concept"], [2523, 2529, "Concept"], [2540, 2548, "Concept"], [2614, 2621, "Concept"], [2678, 2685, "Concept"], [2687, 2704, "Concept"], [2706, 2717, "Concept"], [2719, 2733, "Concept"], [2740, 2758, "Concept"], [2826, 2831, "Concept"], [2861, 2863, "Concept"], [2865, 2867, "Concept"], [2869, 2871, "Concept"], [2873, 2876, "Concept"], [2878, 2880, "Concept"], [2882, 2884, "Concept"], [2886, 2888, "Concept"], [2890, 2892, "Concept"], [2894, 2897, "Concept"], [2899, 2901, "Concept"], [2903, 2905, "Concept"], [2907, 2909, "Concept"], [2911, 2913, "Concept"], [2915, 2918, "Concept"], [2920, 2922, "Concept"], [2924, 2926, "Concept"], [2928, 2930, "Concept"], [2932, 2934, "Concept"], [2936, 2939, "Concept"], [2990, 2992, "Concept"], [2999, 3011, "Concept"], [3070, 3075, "Concept"], [3106, 3108, "Concept"], [3110, 3112, "Concept"], [3114, 3116, "Concept"], [3118, 3121, "Concept"], [3123, 3125, "Concept"], [3127, 3129, "Concept"], [3131, 3133, "Concept"], [3135, 3137, "Concept"], [3139, 3142, "Concept"], [3167, 3169, "Concept"], [3199, 3201, "Concept"], [3233, 3235, "Concept"], [3270, 3272, "Concept"], [3274, 3276, "Concept"], [3278, 3280, "Concept"], [3282, 3285, "Concept"], [3287, 3289, "Concept"], [3291, 3293, "Concept"], [3295, 3301, "Concept"], [3303, 3309, "Concept"], [3311, 3317, "Concept"], [3319, 3321, "Concept"], [3323, 3325, "Concept"], [3327, 3330, "Concept"], [3336, 3351, "Concept"], [3406, 3411, "Concept"], [3443, 3445, "Concept"], [3447, 3449, "Concept"], [3451, 3453, "Concept"], [3455, 3458, "Concept"], [3460, 3462, "Concept"], [3464, 3466, "Concept"], [3468, 3470, "Concept"], [3472, 3474, "Concept"], [3476, 3479, "Concept"], [3504, 3506, "Concept"], [3536, 3538, "Concept"], [3564, 3566, "Concept"], [3602, 3604, "Concept"], [3606, 3608, "Concept"], [3610, 3612, "Concept"], [3614, 3617, "Concept"], [3619, 3621, "Concept"], [3623, 3629, "Concept"], [3631, 3637, "Concept"], [3639, 3641, "Concept"], [3643, 3645, "Concept"], [3647, 3649, "Concept"], [3651, 3653, "Concept"], [3672, 3679, "Concept"], [3682, 3690, "Concept"], [3718, 3725, "Concept"], [3800, 3808, "Concept"], [3819, 3826, "Concept"], [3840, 3844, "Concept"], [3856, 3859, "Concept"], [3884, 3890, "Concept"], [3932, 3939, "Concept"], [3948, 3969, "Concept"], [3975, 3985, "Concept"], [3986, 3997, "Concept"], [3999, 4007, "Concept"], [4008, 4015, "Concept"], [4036, 4050, "Concept"], [4052, 4060, "Concept"], [4061, 4068, "Concept"], [4122, 4133, "Concept"], [4140, 4144, "Concept"], [4162, 4170, "Concept"], [4190, 4195, "Concept"], [4226, 4228, "Concept"], [4230, 4232, "Concept"], [4234, 4236, "Concept"], [4238, 4241, "Concept"], [4243, 4245, "Concept"], [4247, 4253, "Concept"], [4255, 4261, "Concept"], [4263, 4269, "Concept"], [4271, 4277, "Concept"], [4279, 4285, "Concept"], [4287, 4293, "Concept"], [4295, 4301, "Concept"], [4303, 4309, "Concept"], [4311, 4317, "Concept"], [4319, 4325, "Concept"], [4327, 4333, "Concept"], [4335, 4341, "Concept"], [4343, 4349, "Concept"], [4351, 4357, "Concept"], [4359, 4365, "Concept"], [4367, 4369, "Concept"], [4371, 4373, "Concept"], [4375, 4377, "Concept"], [4379, 4382, "Concept"], [4384, 4387, "Concept"], [4389, 4392, "Concept"], [4394, 4397, "Concept"], [4447, 4461, "Concept"], [4468, 4472, "Concept"], [4515, 4532, "Concept"], [4533, 4538, "Concept"], [4570, 4572, "Concept"], [4574, 4576, "Concept"], [4578, 4580, "Concept"], [4582, 4585, "Concept"], [4587, 4589, "Concept"], [4591, 4597, "Concept"], [4599, 4605, "Concept"], [4607, 4613, "Concept"], [4615, 4621, "Concept"], [4623, 4629, "Concept"], [4631, 4637, "Concept"], [4639, 4645, "Concept"], [4647, 4653, "Concept"], [4655, 4661, "Concept"], [4663, 4669, "Concept"], [4671, 4673, "Concept"], [4675, 4677, "Concept"], [4679, 4681, "Concept"], [4683, 4686, "Concept"], [4688, 4691, "Concept"], [4693, 4696, "Concept"], [4721, 4723, "Concept"], [4730, 4751, "Concept"], [4760, 4767, "Concept"], [4783, 4798, "Concept"], [4819, 4822, "Concept"], [4844, 4846, "Concept"], [4851, 4853, "Concept"], [4860, 4866, "Concept"], [4884, 4905, "Concept"], [4917, 4928, "Concept"], [4990, 4992, "Concept"], [4993, 5005, "Concept"], [5007, 5009, "Concept"], [5011, 5013, "Concept"], [5015, 5018, "Concept"], [5027, 5033, "Concept"], [5035, 5048, "Concept"], [5050, 5053, "Concept"], [5055, 5061, "Concept"], [5063, 5065, "Concept"], [5071, 5096, "Concept"], [5103, 5109, "Concept"], [5115, 5118, "Concept"], [5129, 5154, "Concept"], [5190, 5198, "Concept"], [5232, 5234, "Concept"], [5248, 5256, "Concept"], [5261, 5269, "Concept"], [5288, 5295, "Concept"], [5327, 5334, "Concept"], [5364, 5368, "Concept"], [5379, 5394, "Concept"], [5465, 5472, "Concept"], [5480, 5505, "Concept"], [5520, 5523, "Concept"], [5544, 5552, "Concept"], [5557, 5565, "Concept"], [5569, 5576, "Concept"], [5601, 5616, "Concept"], [5662, 5670, "Concept"], [5682, 5687, "Concept"], [5712, 5726, "Concept"], [5880, 5882, "Concept"], [5917, 5924, "Concept"], [6050, 6055, "Concept"], [6061, 6075, "Concept"], [6117, 6125, "Concept"], [6162, 6164, "Concept"], [6166, 6168, "Concept"], [6170, 6172, "Concept"], [6174, 6177, "Concept"], [6179, 6181, "Concept"], [6183, 6185, "Concept"], [6187, 6189, "Concept"], [6197, 6199, "Concept"], [6270, 6272, "Concept"], [6274, 6277, "Concept"], [6279, 6281, "Concept"], [6287, 6289, "Concept"], [6291, 6293, "Concept"], [6300, 6321, "Concept"], [6333, 6347, "Concept"], [6401, 6407, "Concept"], [6409, 6411, "Concept"], [6412, 6415, "Concept"], [6417, 6429, "Concept"], [6431, 6433, "Concept"], [6435, 6437, "Concept"], [6439, 6442, "Concept"], [6444, 6447, "Concept"], [6448, 6461, "Concept"], [6463, 6466, "Concept"], [6468, 6474, "Concept"], [6476, 6478, "Concept"], [6483, 6499, "Concept"], [6506, 6513, "Concept"], [6521, 6535, "Concept"], [6626, 6634, "Concept"], [6655, 6659, "Concept"], [6773, 6812, "Concept"], [6885, 6891, "Concept"], [6951, 6954, "Concept"], [6974, 6986, "Concept"], [7003, 7025, "Concept"], [7042, 7050, "Concept"], [7054, 7060, "Concept"], [7079, 7089, "Concept"], [7100, 7115, "Concept"], [7145, 7151, "Concept"], [7161, 7164, "Concept"], [7166, 7188, "Concept"], [7195, 7201, "Concept"], [7238, 7245, "Concept"], [7281, 7284, "Concept"], [7388, 7392, "Concept"], [7401, 7422, "Concept"], [7449, 7453, "Concept"], [7640, 7643, "Concept"], [7713, 7716, "Concept"], [7737, 7742, "Concept"], [7781, 7792, "Concept"], [7796, 7799, "Concept"], [7847, 7853, "Concept"], [7869, 7873, "Concept"], [7901, 7922, "Concept"], [8015, 8025, "Concept"], [8060, 8064, "Concept"], [8082, 8085, "Concept"]], "Comments": []}
{"id": 105, "segment": ["train_set", "labeled"],  "course": "cs1541", "lec": "lec1.3_technology_constraints", "text": "CS 1541 Introduction\nTechnology Constraints\n\nWonsun Ahn\nDepartment of Computer Science\nSchool of Computing and Information\n\n\fTechnology Constraints\n\n\fTechnology Constraints\n\u25fc Constraints in technology push architecture too\nApp 1\n\nTechnology push\n\nApp 2\n\nApp 3\n\nOperating System\n\nSoftware Layer\n\nInstruction Set Architecture\nProcessor Organization\n\nComputer\nArchitecture\n\nTransistor Implementation\n\nPhysical Layer\n\n\u26ab Power Wall: Thermal Design Power (TDP) constraint\n\u26ab Memory Wall: Constraint in bandwidth to memory\n\u26ab Variability: Limits in the precision of manufacturing technology\n\n\u25fc Processor must be designed to meet all constraints\n\n\fPower Wall\n\u25fc PowerCPU = Powerdynamic + Powerleakage\nPowerdynamic \u221d A * N * CFV2\nPowerleakage \u221d f(N, V, Vth) \u221d N * V * e-Vth\n\u26ab Leakage power is also called static power\n\u26ab This total CPU power cannot exceed TDP\n\n\u25fc Moore\u2019s Law transistor scaling means two things:\n\u26ab N = Number of transistors (\u221d 1/transistor size2) \uf0f1 \uf0f1\n\u26ab C = Capacitance (\u221d transistor size) \uf0f2\n\u26ab Reductions in C does not compensate for increases in N\n\n\u25fc Architects must use tricks to keep power in check\n\u26ab To keep packing more transistors to increase performance\n\n\f1. Reducing Dynamic Power\n\u25fc Powerdynamic (\u221d A * N * CFV2) + Powerleakage (\u221d N * V * e-Vth)\n\u25fc Reducing A (Activity): Clock gating\n\u26ab Disables the clock signal to unused parts of the chip (idle cores)\n\u26ab Wake-up is instantaneous (the moment clock signal goes in)\n\n\u25fc Reducing F (Frequency) and V (Supply Voltage)\n\u26ab When F is reduced, V can also be reduced\n(Transistor 101 and water pressure, remember?)\n\u26ab Dynamic Voltage Frequency Scaling (DVFS) done on multi-cores\nSlow down low-priority cores, speed up high-priority cores\n\n\fDVFS and Transistor Speed\n\u25fc RC Charging Curve of VG\nVdd1\nVG1\nVG2\n\nVdd2\n\nVth\n\nT1 T2\n\u25fc Vdd1 \u2192 Vdd2 saves power, but slows down T1 \u2192 T2\n\u25fc Vdd2 \u2192 Vdd1 uses more power, but speeds up T2 \u2192 T1\n\u25fc Vdd \u221d 1/T \u221d F (Vdd is proportional to frequency)\n\n\f2. Reducing Leakage Power\n\u25fc Powerdynamic (\u221d A * N * CFV2) + Powerleakage (\u221d N * V * e-Vth)\n\u25fc Reducing N (Transistor Number): Power gating\n\u26ab Disables power to unused parts of the chip (unused cores)\n\u26ab Eliminates dynamic power and leakage power to those parts\n\u26ab Drawback: wake-up takes a much longer time than clock gating\nDelay for supply voltage to stabilize\nDelay to backup and restore CPU state to/from memory\n\n\u25fc Reducing V (Supply Voltage): DVFS also helps here\n\n\fOS Manages Power\n\u25fc Who decides which cores to clock gate and power gate?\n\u25fc Who decides how to apply DVFS to the cores?\n\u25fc ACPI (Advanced Configuration and Power Interface)\n\u26ab OS performs power management using this interface\nOS knows best which threads to prioritize for best user experience\n\n\u26ab Open standard interface to system firmware\nFirmware sends signals to processor cores to control them\n\nApp 1\n\nApp 2\n\nApp 3\n\nOS Power Management\n\nSoftware Layer\n\nSystem Firmware\n\nComputer\nArchitecture\n\nACPI\n\nProcessor Cores\n\n\f3. Simpler Processor Design\n\u25fc Plenty of transistors but not enough power\n\u26ab Power becomes the ultimate currency in processor design\n\n\u25fc Complex logic for performance is power hungry\n\u26ab Not easy to eke out the last bit of performance out of a program\n\u26ab Diminishing returns on performance for power investment\n\n\u25fc Push towards simpler architectures:\n\u26ab Multi-cores: Run multiple programs (threads) on simple cores\n\u26ab GPUs: Run each instruction on massively parallel compute units\n\u26ab Caches: Memory caches are power efficient (low dynamic power)\n\n\fMemory Wall\n\u25fc Refers to both latency (ns) and bandwidth (GB/s)\n\u26ab CPU frequency and overall performance increased dramatically\n\u26ab Memory (DRAM) latency and bandwidth have lagged far behind\n\n\u25fc Why?\n\u26ab Limit on the number of CPU / DRAM pins that can be soldered on\n\n\u26ab DRAM manufacturers have traditionally prioritized capacity\n\u26ab DDR1 (1998): 1.6 GB/s \u2192 DDR4 (2014): 25.6 GB/s\n(Impressive? Not so much compared to CPU performance)\n\n\fMemory Wall\n\nSource: SC16 Invited Talk \u201c\u201cMemory Bandwidth and System Balance in HPC Systems\u201d by John D. McCalpin\n\n\u25fc FLOPS = floating point operations per second (performance)\n\n\fMemory Wall\n\u25fc Where did the Memory Wall push architecture?\n\u25fc Caches: If hit in cache, no need to go to memory\n\u26ab Caching reduces both data access latency/bandwidth\n\n\u25fc 3D-Stacked Memory: Stack CPU on top of memory\n\u26ab Drill vias, or holes, through silicon to bond CPU with memory\n\u26ab Through silicon vias (TSVs) have low latency / high bandwidth\n\n\fVariability\n\u25fc Variability: differences in speed of individual transistors\n\u26ab If fab can\u2019t ensure uniformity of transistors, speeds will differ\n\u26ab Speed differences mostly come from variations in Vth:\nlow Vth \u2192 cycle time \uf0f2 but leakage power \uf0f1\nhigh Vth \u2192 cycle time \uf0f1 but leakage power \uf0f2\n\n\u25fc If unlucky and a logic path has lots of slow transistors\n\u2192 CPU may miss clock cycle time if path is exercised\n\u2192 CPU must be discarded, since it malfunctions\n\u25fc If unlucky and a region has too many fast transistors\n\u2192 Region may generate too much heat due to low Vth\n\u2192 CPU must be discarded, due to overheating\n\u25fc Leads to low chip yield\n\n\fWafer Yield\n\n\u25fc Lower yield leads to higher production cost\n\n\fVariability\n\u25fc Where did Variability push architecture?\n\u25fc Product binning: Sell slower CPUs at a cheaper \u201cbin\u201d\n\u26ab And rate slower CPUs at a lower CPU frequency\n\u26ab Instead of discarding them as \u201cmalfunctioning\u201d\n\n\u25fc Multi-cores: Easy to disable one or two buggy cores\n\u26ab Compared to single core where subcomponents must be disabled\n\u26ab Used when one or two cores are extremely slow\n\n\u25fc Limited pipelining: pipelining exacerbates variability\n\u26ab With long stages, many transistors so tend to even each other out\n\u26ab With short stages, few transistors so probable all are slow\n\n\fIntel i9 Product Binning\nWhy the close to\n4X difference?\nClock difference\nis just 2X!\n\nProduced from\none wafer\n\nSource: https://www.techspot.com/article/2039-chip-binning/\n* TDP is calculated using the Base Clock frequency at a nominal supply voltage\n\n\fOpportunities for Speed Improvement\n\u25fc So Dennard Scaling is dead\n\u26ab Free CPU frequency gains are no longer there\n\n\u25fc And we are walled in by technology constraints\n\u26ab Power wall\n\u26ab Memory wall\n\u26ab Variability\n\u26ab\u2026\n\n\u25fc Where do architects go look for performance?\n\n\fImproving Execution Time\ninstructions\n\u25fc Execution time = program X\n\n\u25fc Improving\n\nseconds\ncycle\n\ncycles\nseconds\nX\ncycle\ninstructions\n\n:\n\n\u26ab Pipelining can lead to higher frequencies\ncycles\n\u25fc Improving instructions :\n\n\u26ab Caching can reduce cycles for memory instructions\n\u26ab Superscalars can execute multiple instructions per cycle\n\u26ab Multi-cores execute multi-instructions from multi-threads\n\ninstructions\n\u25fc Improving program :\n\n\u26ab GPUs are SIMD (Single Instruction Multiple Data) processors\n\n\fWhat about Other Performance Goals?\n\u25fc We talked a lot about execution speed\n\u25fc But there are other performance goals such as:\n\u26ab Energy efficiency\n\u26ab Reliability\n\u26ab Security\n\u26ab\u2026\n\n\u25fc In this class, we will mainly focus on speed\n\u26ab Not that other goals are not important\n\u26ab We will touch upon other goals when relevant\n\u26ab Performance will be used synonymously with speed\n\n\fTextbook Chapters\n\u25fc Please review Chapter 1 of the textbook.\n\n\f", "label": [[21, 43, "Concept"], [125, 147, "Concept"], [150, 172, "Concept"], [190, 205, "Concept"], [206, 218, "Concept"], [230, 245, "Concept"], [295, 323, "Concept"], [324, 346, "Concept"], [348, 369, "Concept"], [416, 426, "Concept"], [428, 448, "Concept"], [450, 453, "Concept"], [468, 479, "Concept"], [495, 504, "Concept"], [508, 514, "Concept"], [517, 528, "Concept"], [638, 648, "Concept"], [662, 674, "Concept"], [677, 689, "Concept"], [690, 702, "Concept"], [718, 730, "Concept"], [764, 777, "Concept"], [793, 805, "Concept"], [823, 828, "Concept"], [843, 846, "Concept"], [850, 861, "Concept"], [960, 971, "Concept"], [1089, 1094, "Concept"], [1177, 1190, "Concept"], [1193, 1205, "Concept"], [1270, 1278, "Concept"], [1281, 1293, "Concept"], [1439, 1448, "Concept"], [1457, 1471, "Concept"], [1565, 1598, "Concept"], [1600, 1604, "Concept"], [1687, 1691, "Concept"], [1696, 1712, "Concept"], [1790, 1795, "Concept"], [1844, 1849, "Concept"], [1913, 1922, "Concept"], [1938, 1951, "Concept"], [1954, 1966, "Concept"], [1986, 1998, "Concept"], [2031, 2048, "Concept"], [2051, 2063, "Concept"], [2075, 2080, "Concept"], [2137, 2150, "Concept"], [2155, 2168, "Concept"], [2234, 2246, "Concept"], [2257, 2271, "Concept"], [2353, 2367, "Concept"], [2370, 2374, "Concept"], [2393, 2409, "Concept"], [2439, 2449, "Concept"], [2454, 2464, "Concept"], [2493, 2497, "Concept"], [2514, 2518, "Concept"], [2520, 2562, "Concept"], [2578, 2594, "Concept"], [2809, 2828, "Concept"], [2886, 2890, "Concept"], [2913, 2937, "Concept"], [2977, 2982, "Concept"], [2985, 2990, "Concept"], [3256, 3267, "Concept"], [3292, 3299, "Concept"], [3319, 3323, "Concept"], [3383, 3390, "Concept"], [3392, 3405, "Concept"], [3410, 3415, "Concept"], [3431, 3444, "Concept"], [3448, 3459, "Concept"], [3477, 3484, "Concept"], [3494, 3503, "Concept"], [3517, 3526, "Concept"], [3576, 3582, "Concept"], [3584, 3588, "Concept"], [3590, 3597, "Concept"], [3602, 3611, "Concept"], [3674, 3678, "Concept"], [3711, 3715, "Concept"], [3772, 3776, "Concept"], [3796, 3800, "Concept"], [3875, 3886, "Concept"], [3991, 3996, "Concept"], [3999, 4035, "Concept"], [4052, 4063, "Concept"], [4080, 4091, "Concept"], [4113, 4119, "Concept"], [4131, 4136, "Concept"], [4155, 4161, "Concept"], [4164, 4171, "Concept"], [4197, 4204, "Concept"], [4205, 4214, "Concept"], [4218, 4235, "Concept"], [4257, 4263, "Concept"], [4321, 4327, "Concept"], [4330, 4350, "Concept"], [4352, 4356, "Concept"], [4367, 4374, "Concept"], [4382, 4391, "Concept"], [4394, 4405, "Concept"], [4408, 4419, "Concept"], [5005, 5015, "Concept"], [5018, 5029, "Concept"], [5079, 5090, "Concept"], [5103, 5114, "Concept"], [5136, 5151, "Concept"], [5227, 5236, "Concept"], [5289, 5300, "Concept"], [5455, 5473, "Concept"], [5475, 5485, "Concept"], [5498, 5509, "Concept"], [5651, 5666, "Concept"], [5816, 5819, "Concept"], [5878, 5892, "Concept"], [5936, 5951, "Concept"], [5971, 5980, "Concept"], [6034, 6056, "Concept"], [6059, 6069, "Concept"], [6072, 6083, "Concept"], [6086, 6097, "Concept"], [6161, 6175, "Concept"], [6191, 6205, "Concept"], [6289, 6299, "Concept"], [6319, 6330, "Concept"], [6368, 6375, "Concept"], [6420, 6432, "Concept"], [6479, 6490, "Concept"], [6576, 6580, "Concept"], [6585, 6589, "Concept"], [6591, 6623, "Concept"], [6698, 6713, "Concept"], [6765, 6782, "Concept"], [6785, 6796, "Concept"], [6799, 6807, "Concept"]], "Comments": []}
