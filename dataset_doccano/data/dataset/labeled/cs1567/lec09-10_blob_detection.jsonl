{"id": 303, "segment": ["train_set", "labeled"], "course": "cs1567", "lec": "lec09-10_blob_detection", "text": "Blob Detection\nThumrongsak Kosiyatrakul\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fBlob\n\nA blob in computer vision is a region of image that some\nproperties is constant or approximately constant\nExample of properties:\nColor\nBrightness\n\nA robot can detect an object with a solid color by simply find\nblobs of that color\nA blob usually defined as a rectangular region with information:\nWidth and Height\nNumber of pixels\nCoordinate of the center of the region\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fHow to Detect a Blob?\nConsider the following image:\n\nHow to detect a red ball in the above image?\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fFilter Selected Color\n\nImage generally comes in RGB format\nEach pixel is represented by three values, red, green, and blue\nTo filter out a specific color, we simply define ranges for each\nvalue\nRed between 120 to 130,\nGreen between 78 to 90, and\nBlue between 100 to 110\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fHow to Detect a Blob\nFilter out every color but red\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fHow to Detect a Blob\nDetect connected regions\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fFilter Selected Color\n\nNote that an object generally stays in a foreground where\nenvironment is in the background\nForeground objects generally have more brightness\nIn computer vision, we prefer YUV format:\nY stands for the luminance component (the brightness)\nU and V are the chrominance (color) components\n\nConversion between RGB and YUV is straightforward:\n\ud835\udc4c = (0.299 \u00d7 \ud835\udc45) + (0.587 \u00d7 \ud835\udc3a) + (0.114 \u00d7 \ud835\udc35)\n\ud835\udc48 = (\u22120.168736 \u00d7 \ud835\udc45) + (\u22120.331264 \u00d7 \ud835\udc3a) + (0.5 \u00d7 \ud835\udc35)\n\ud835\udc49 = (0.5 \u00d7 \ud835\udc45) + (\u22120.418688 \u00d7 \ud835\udc3a) + (\u22120.081312 \u00d7 \ud835\udc35)\n\nwhere \ud835\udc45, \ud835\udc3a, and \ud835\udc35 have values between 0.0 and 1.0\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fProblems with Blob Detection\nIf we have two objects with the same color, at least two blobs\nwill be detected\nIf we have only one object, more than one blobs may be detected\nLighting effects color\nFiltered regions may not connect with each other\nTwo or more blobs but on the same object\nIf all blobs come from the same object, they will be close to each\nother\n\nSurrounding environment may have the same color\n\nSame object may not be detected if lighting change\nIncrease the range of color may result in detecting environment\ninstead of desire object\nOnly works in restricted lighting and surrounding environment\nhas small number of colors\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fApplications\n\nObject Recognition and Tracking:\nSoccer: Ball and goal posts\nNavigation: Follows a line\nObject avoidance\n\nRobot Location/Orientation:\nTwo colors on top of robot\nSigns (multi-colors) represent locations\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fIntegrated Web Camera\nTo detect blobs, we need an image or a series of images\nWe will use integrated Web camera of your given laptop\nTo access the web cam, we need another node called gscam\ngscam node communicate with integrated Web cam\nCapture video and turn them into series of images\nEach image will be published on the topic\n/v4l/camera/image_raw\n\nTo start gscam node, use the following command:\nroslaunch gscam v4l.launch\n\nA series of images can be viewed using image_view node as\nfollows:\nrosrun image_view image_view image:=/v4l/camera/image_raw\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fImage Message\nImages published by gscam node has type\nsensor_msg/Image.msgs\nIf you want to access images, add the following:\nfrom sensor_msg.msgs import Image\n\nThe Image message consists of the following components:\nheader: Information about message\nheight: Image height (number of rows)\nwidth: Image width (number of columns)\nencoding: Type of encoding\nis_bigendian: Is this data bigendian\nstep: How many bytes in a row\ndata: A one-dimensional array of data. The number of elements\nis step * rows ([B,G,R,B,G,R,...])\n\nLucky us, we do not have to process images directly.\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fView Image from Camera using OpenCV\nWe can create our own image viewer from camera using OpenCV\nFirst, we need to convert a color image message into OpenCV\nformat\nThen, simply display the image\nCode Example:\n#!/usr/bin/env python\nimport rospy\nimport cv2\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\ncolorImage = None\nisColorImageReady = False\ndef updateColorImage(data):\nglobal colorImage, isColorImageReady\ncolorImage = data\nisColorImageReady = True\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fView Image from Camera using OpenCV\nCode Example (continue):\ndef main():\nglobal colorImage, isColorImageReady\nrospy.init_node('myimageview', anonymous=True)\nrospy.Subscriber('/v4l/camera/image_raw', Image, updateColorImage)\nbridge = CvBridge()\ncv2.namedWindow('Image from Camera')\nwhile not rospy.is_shutdown() and not isColorImageReady:\npass\nwhile not rospy.is_shutdown():\ntry:\ncolor_image = bridge.imgmsg_to_cv2(colorImage, \"bgr8\")\nexcept CvBridgeError, e:\nprint e\ncv2.imshow('Image from Camera', color_image)\nkey = cv2.waitKey(1)\nif key == ord('q'):\nbreak\ncv2.destroyAllWindows()\nif __name__ == '__main__':\nmain()\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcmvision Node\n\ncmvision node detects blobs of colors from Image message\nSubscribes to a topic (of type Image) of your choice\nIn our case, the topic will be:\n/v4l/camera/image_raw\n\nObtains user defined color information about blobs to be detected\nPublishes information about detect blobs on the topic /blobs\n\ncmvision package also supplies a tool named colorgui\nAllows user to pick a range of colors of an object of interest\nShows visual image of detect blobs associated with picked color\nSupplies color information and threshold\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcolorgui\n\nBefore running colorgui node, make sure your roscore and\ngscam is running\nTo run colorgui, use the following command:\nrosrun cmvision colorgui image:=/v4l/camera/image_raw\n\nNote that the data in topic /v4l/camera/image_raw is\npublished by gscam node\nA windows will pop-up and shows the image from your camera\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcolorgui\n\nAfter clicking on the object in the image couple times, you may\nsee a set of rectangles\nEach rectangle represents a detected blob\nMove object around to see whether it can detect the object\nIf it cannot detect, click on the object couple more times to\nincrease the range of detecting color\nInformation at the bottom (YUV) will be use to set the color to\nbe detected\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcolorgui Example\nFirst couple clicks\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcolorgui Example\nCouple more clicks around the desired object\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcolorgui Example\nCouple more and take note about RGB and YUV\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcolors.txt\nFor cmvision node, color information should be stored in a\ntext file\nBy default, the name of the text file is colors.txt\nA color file consists of two parts [colors] and\n[thresholds] as shown below:\n[colors]\n(150, 166, 83) 0.000000 1 BrightGreen\n[thresholds]\n(151:163, 85:91, 121:126)\n\ncmvision node can be used to detect more than one color by\nadding more lines for [colors] and [thresholds]\n[colors]\n(150, 166, 83) 0.000000 1 BrightGreen\n(0, 255, 0) 0.000000 2 Green\n[thresholds]\n(151:163, 85:91, 121:126)\n(47:87, 148:162, 93:113)\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcolors.txt\nConsider the following color file:\n[colors]\n(150, 166, 83) 0.000000 1 BrightGreen\n(0, 255, 0) 0.000000 2 Green\n[thresholds]\n(151:163, 85:91, 121:126)\n(47:87, 148:162, 93:113)\n\nEach line under [colors] consists of the following:\n(R, G, B): The red, green, and blue values of rectangles that\nare used to blob region\n0.000000: Not being used any more (I guess)\n1: Not being used any more (I guess)\nBrightGreen: The name of the blob which can be used to\ndistinguish among multiple detected blobs\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcolors.txt\n\nConsider the following color file:\n[colors]\n(150, 166, 83) 0.000000 1 BrightGreen\n(0, 255, 0) 0.000000 2 Green\n[thresholds]\n(151:163, 85:91, 121:126)\n(47:87, 148:162, 93:113)\n\nEach line under [thresholds] consists of the following:\n(minY:maxY, minU:maxU, minV:maxV): The YUV\nthreshold from colorgui\n\nNote that the first line of colors is associated with the first line\nof thresholds, and so on\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcmvision.launch\nParameters of cmvision are needed to be set\nFirst, copy the default launch file:\n/home/student/cs1567/src/cmvision/cmvision.launch\n\nto your ../mypackage directory\nIn the copied file, change the followings:\nUnder param name=\"cmvision/color_file\", change\nits value to\nvalue=\"/home/student/cs1567/src/mypackage/colors.txt\"\n\nIf you put colors.txt in different directory, adjust it\naccordingly\nUnder param name=\"cmvision/debug_on\", change the\nvalue to\nvalue=\"true\" if you want to see image and detect blobs while\ncmvision is running\nvalue=\"false\" otherwise\n\nUnder node name=\"cmvision\" change the args to\nargs=\"image:=/v4l/camera/image_raw\"\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fcmvision.launch\nYour cmvision.launch should look like the following:\n<launch>\n<!-- Location of the cmvision color file -->\n<param name=\"cmvision/color_file\" type=\"string\"\nvalue=\"/home/student/cs1567/src/mypackage/colors.txt\" />\n<!-- Turn debug output on or off -->\n<param name=\"cmvision/debug_on\" type=\"bool\" value=\"true\"/>\n<!-- Turn color calibration on or off -->\n<param name=\"cmvision/color_cal_on\" type=\"bool\" value=\"false\"/>\n<!-- Enable Mean shift filtering -->\n<param name=\"cmvision/mean_shift_on\" type=\"bool\" value=\"false\"/>\n<!-- Spatial bandwidth: Bigger = smoother image -->\n<param name=\"cmvision/spatial_radius_pix\" type=\"double\" value=\"2.0\"/>\n<!-- Color bandwidth: Bigger = smoother image-->\n<param name=\"cmvision/color_radius_pix\" type=\"double\" value=\"40.0\"/>\n<node name=\"cmvision\" pkg=\"cmvision\" type=\"cmvision\" args=\"image:=/v4l/camera/image_raw\"\noutput=\"screen\" />\n</launch>\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fBlobs.msgs\n\ncmvision node publishes a message of type Blobs\nAgain, import it first:\nfrom cmvision.msg import Blobs\n\nA message of type Blobs consists of various components:\nheader: Message header\nimage_width: The width of the image in pixels\nimage_height: The height of the image in pixels\nblob_count: The number of detected blobs\nblobs: An array of data of type Blob\n\nNote: Blob (with out s) is another type of message\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fBlob.msgs\nBlob.msgs stores information about each blob detected by\ncmvision node\nMust be explicitly imported:\nfrom cmvision.msg import Blobs, Blob\n\nA message of type Blob consists of various components:\nname: The name of color/object specified in colors.txt\n(String)\nred: The value of red\ngreen: The value of green\nblue: The value of blue\narea: The area of the blob (number of pixels)\nx: The x coordinate of the center of the blob\ny: The y coordinate of the center of the blob\nleft: The x coordinate of the left side of the region\nright: The x coordinate of the right side of the region\ntop: The y coordinate of the top side of the region\nbottom: The y coordinate of the bottom side of the region\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fBlob.msgs\n(0,0)\n\nleft\n\nright\n\ntop\n\n(x,y)\n\nbottom\n\nblob\n\nimage\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fProblem Solving Ideas\n\nHow to filter out environment?\nHow do we know that two or more blobs are on the same object?\nFixed size objects\nVariable size objects\n\nIf we know that these 10 blobs are on the same object, how to\nfind the center of the object?\nHow do we know that there are two or more objects of the same\ncolor?\nHow to filter out noise from camera?\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fVisualize Blobs using OpenCV\n\nSometimes we need to process blobs:\nFilter out blobs that are too smalls\nFilter out blobs that are outside of region of interest\nMerge multiple blobs in to one\n\nWe may need to see a result in an image\nOpenCV provides libraries for Computer Vision:\nShow image/video on screen\nMouse and keyboard events\nDraw lines, rectangles, string on image\nForeground/background filtering\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fVisualize Blobs using OpenCV\n#!/usr/bin/env python\nimport roslib\nimport rospy\nimport cv2\nimport copy\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\nfrom cmvision.msg import Blobs, Blob\ncolorImage = Image()\nisColorImageReady = False\nblobsInfo = Blobs()\nisBlobsInfoReady = False\ndef updateColorImage(data):\nglobal colorImage, isColorImageReady\ncolorImage = data\nisColorImageReady = True\ndef updateBlobsInfo(data):\nglobal blobsInfo, isBlobsInfoReady\nblobsInfo = data\nisBlobsInfoReady = True\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fVisualize Blobs using OpenCV\n\ndef main():\nglobal colorImage, isColorImageReady, blobsInfo, isBlobsInfoReady\nrospy.init_node('showBlobs', anonymous=True)\nrospy.Subscriber(\"/blobs\", Blobs, updateBlobsInfo)\nrospy.Subscriber(\"/v4l/camera/image_raw\", Image, updateColorImage)\nbridge = CvBridge()\ncv2.namedWindow(\"Blob Location\")\nwhile not rospy.is_shutdown() and\n(not isBlobsInfoReady or not isColorImageReady):\npass\nwhile not rospy.is_shutdown():\n:\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fVisualize Blobs using OpenCV\ndef main():\n:\nwhile not rospy.is_shutdown():\ntry:\ncolor_image = bridge.imgmsg_to_cv2(colorImage, \"bgr8\")\nexcept CvBridgeError, e:\nprint e\nprint \"colorImage\"\nblobsCopy = copy.deepcopy(blobsInfo)\nfor b in blobsCopy.blobs:\ncv2.rectangle(color_image, (b.left, b.top),\n(b.right, b.bottom), (0,255,0), 2)\ncv2.imshow(\"Color Image\", color_image)\nkey = cv2.waitKey(1)\nif key == ord('q'):\nbreak\ncv2.destroyAllWindows()\nif __name__ == '__main__':\nmain()\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fBlob Detection Algorithm\n\nGiven an image, the following steps are generally used:\n1\n2\n3\n\nBlur the image to reduce noise\nFilter out all pixels that are out-of-range\nFind groups of pixels that are connected to each other\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fGaussian Blur\n\nOne of the most popular blur algorithm is called Gaussian blur\n\n3x3\n5x5\n7x7\n\nThe new RGB values of the pixel at center is an weight average\nof RGB of pixels around it\nThe weight of each pixel is based on the Gaussian normal\ndistribution\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fFilter\nFilter can be done based on RGB or YUV\nRecall that cmvision uses YUV\n\nOnce a filter is applied, we should get a one bit image (black and\nwhite)\nWe do not need information about color of each pixel anymore\nOnly need to know which pixels are in a given range\n\nExample:\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n1\n1\n1\n0\n0\n0\n1\n0\n\n0\n1\n1\n1\n1\n1\n1\n1\n0\n\n0\n1\n1\n1\n0\n0\n0\n1\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n1\n0\n0\n0\n0\n0\n\n0\n0\n0\n1\n1\n0\n0\n0\n0\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\nFor simplicity, assume that a blob is a 4-tuple\n(left, right, top, bottom)\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fA Blob Detection Algorithm\nFirst, we need to search for the first pixel that are non-zero\nScan left to right and top to bottom\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n1\n1\n1\n0\n0\n0\n1\n0\n\n0\n1\n1\n1\n1\n1\n1\n1\n0\n\n0\n1\n1\n1\n0\n0\n0\n1\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n1\n0\n0\n0\n0\n0\n\n0\n0\n0\n1\n1\n0\n0\n0\n0\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\nOnce the first pixel is found:\n1\n\n2\n3\n4\n5\n\nRecord this coordinate so that we can restart searching for the\nnext blob\nConstruct a new blob (data)\nLeft and right are 5\nTop and bottom are 1\nCenter, width, and height of the blob will be calculated later\n\nNow, our first blob is (5, 5, 1, 1)\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fA Blob Detection Algorithm\nNext, set the pixel to zero and scanning for non-zero neighbor\nIf a non-zero neighbor is found:\nAdjust the blob accordingly\nAdd coordinate (x,y) of the non-zero neighbor into a queue\nChange non-zero neighbors to 0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n1\n0\n0\n0\n1\n0\n\n0\n0\n0\n1\n1\n1\n1\n1\n0\n\n0\n1\n1\n1\n0\n0\n0\n1\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n1\n0\n0\n0\n0\n0\n\nCurrently\nBlob is (5, 6, 1, 2)\nQueue is [(6,1), (5,2), (6,2)]\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n0\n0\n0\n1\n1\n0\n0\n0\n0\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\fA Blob Detection Algorithm\nRepeat until the queue is empty:\n1\n2\n3\n4\n5\n\nDequeue the first coordinate\nScan for its non-zero neighbor\nAdd all coordinates (x,y) of the non-zero neighbor into a queue\nChange all non-zero neighbor to 0\nGo back to step 1\n\nOnce the queue is empty, we get the first blob (5, 7, 1, 7)\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\nThumrongsak Kosiyatrakul\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\nBlob Detection\n\n0\n0\n0\n1\n0\n0\n0\n0\n0\n\n0\n0\n0\n1\n1\n0\n0\n0\n0\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\fBlob Detection using OpenCV\nFirst, we need to blur an image using the GaussianBlur()\nfunction\nThe following code blurs an image and display:\nimport cv2\ndef main():\ncolor_image = cv2.imread('start_img.jpg', cv2.IMREAD_COLOR)\nblur_image = cv2.GaussianBlur(color_image, (5, 5), 0)\ncv2.imshow('Image', color_image)\ncv2.imshow('Blur Image', blur_image)\nwhile True:\nkey = cv2.waitKey(0) & 0xFF\nif key == ord('q'):\nbreak;\ncv2.destroyAllWindows()\nif __name__ == '__main__':\nmain()\n\nThe parameter (5, 5) specifies how many pixels to be used\n(must be odd numbers)\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fConvert RGB to YUV\nOpenCV supplies the cvtColor() function to convert one\ncolor spectrum to another\nimport cv2\ndef main():\ncolor_image = cv2.imread('../start_img.jpg', cv2.IMREAD_COLOR)\nblur_image = cv2.GaussianBlur(color_image, (5, 5), 0)\nyuv_image = cv2.cvtColor(blur_image, cv2.COLOR_BGR2YUV)\ny, u, v = cv2.split(yuv_image)\ncv2.imshow('Image', blur_image)\ncv2.imshow('Y', y)\ncv2.imshow('U', u)\ncv2.imshow('V', v)\nwhile True:\nkey = cv2.waitKey(0) & 0xFF\nif key == ord('q'):\nbreak;\ncv2.destroyAllWindows()\nif __name__ == '__main__':\nmain()\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fFilter Unwanted Pixels\n\nUnwanted pixels can be filtered out using the inRange()\nfunction:\ndef main():\ncolor_image = cv2.imread('../start_img.jpg', cv2.IMREAD_COLOR)\nblur_image = cv2.GaussianBlur(color_image, (5, 5), 0)\ncv2.namedWindow('Mask')\nmask_image = cv2.inRange(blur_image, lower_bound, upper_bound);\ncv2.imshow('Mask', mask_image)\ncv2.waitkey(0);\ncv2.destroyAllWindows()\nif __name__ == '__main__':\nmain()\n\nThe lower_bound and upper_bound are (B, G, R) in\nthis case\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fFilter Unwanted Pixels\nMasked Image:\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fSimpleBlobDetector()\n\nOpenCV supplies the SimpleBlobDetector() function\nwhich detects blobs based on a given parameter:\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fSimpleBlobDetector() Parameters\nFirst we need to set the parameter:\nparams = cv2.SimpleBlobDetector_Params()\nparams.minThreshold = 0\nparams.maxThreshold = 255\nparams.filterByArea = True\nparams.minArea = 50\nparams.maxArea = 256 * 256\nparams.filterByCircularity = False\nparams.minCircularity = 0.1\nparams.filterByConvexity = False\nparams.minConvexity = 0.9\nparams.filterByInertia = False\nparams.minInertiaRatio = 0.5\nver = (cv2.__version__).split('.')\nif int(ver[0]) < 3:\ndetector = cv2.SimpleBlobDetector(params)\nelse:\ndetector = cv2.SimpleBlobDetector_create(params)\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fSimpleBlobDetector()\n\nThen we can use the detector object to detect blobs from\nmasked image\nkeypoints = detector.detect(255 - mask_image)\nkp_image =\ncv2.drawKeypoints(blur_image,\nkeypoints,\nnp.array([]),\n(0, 255, 0),\ncv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\ncv2.imshow('Keypoints', kp_image)\n\nTo extract blobs information, simply look at the keypoints\nvariable\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fSimpleBlobDetector()\nResult from the drawKeypoints() function to the original\nimage:\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fSimpleBlobDetector()\n\nThe SimpleBlobDetector() function is good for round\nobject\nIt may not perform well for our application (high CPU utilization)\nWith a large blob, it only show a small keypoint\nParameters are hard to understand\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fBlob Detection using Contour\n\nAnother method is to detect contours of masked image\nA contour is a curve joining all the continuous points (along the\nboundary), having same color or intensity\nThe contours are a useful tool for shape analysis and object\ndetection and recognition\nIn OpenCV, the function findContours() is given\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\ffindContours()\n\nfindContours() example:\ndef main():\ncolor_image = cv2.imread('../start_img.jpg', cv2.IMREAD_COLOR)\nblur_image = cv2.GaussianBlur(color_image, (5, 5), 0)\ncv2.namedWindow('Contour Image')\n(cnts, _) = cv2.findContours(mask_image.copy(), cv2.RETR_TREE,\ncv2.CHAIN_APPROX_SIMPLE)\ncv2.drawContours(blur_image, cnts, -1, (0,255,0), 3)\ncv2.imshow('Contour Image', blur_image)\ncv2.waitKey(0);\ncv2.destroyAllWindows()\nif __name__ == '__main__':\nmain()\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fdrawContours()\nUse the drawContours() to draw all contours into the\noriginal image\n\nNote that there are contours inside other contours\nWe need bounding box for each contour and eliminate contours\nthat are inside another\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\ffindContours() with hierarchy\nFilter out some contours\ndef main():\ncolor_image = cv2.imread('../start_img.jpg', cv2.IMREAD_COLOR)\nblur_image = cv2.GaussianBlur(color_image, (5, 5), 0)\ncv2.namedWindow('Bounding')\n(cnts, hierarchy) = cv2.findContours(mask_image.copy(),\ncv2.RETR_TREE,\ncv2.CHAIN_APPROX_SIMPLE)\nfor i in range(0, len(cnts)):\nc = cnts[i]\nif cv2.contourArea(c) < 100:\ncontinue\nif not hierarchy[0][i][3] == -1:\ncontinue\nx,y,w,h = cv2.boundingRect(c)\ncv2.rectangle(blur_image, (x,y), (x + w, y + h),\n(0, 255, 0), 3);\ncv2.imshow('Bounding', blur_image)\ncv2.waitKey(0);\ncv2.destroyAllWindows()\nif __name__ == '__main__':\nmain()\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\fdrawContours()\nAfter filtering out small contours and those that are inside another\n\nThumrongsak Kosiyatrakul\n\nBlob Detection\n\n\f", "label": [[0, 14, "Concept"], [67, 81, "Concept"], [84, 88, "Concept"], [92, 96, "Concept"], [300, 305, "Concept"], [322, 326, "Concept"], [485, 499, "Concept"], [518, 522, "Concept"], [626, 640, "Concept"], [691, 694, "Concept"], [940, 954, "Concept"], [973, 977, "Concept"], [1036, 1050, "Concept"], [1069, 1073, "Concept"], [1126, 1140, "Concept"], [1337, 1340, "Concept"], [1349, 1350, "Concept"], [1366, 1375, "Concept"], [1403, 1404, "Concept"], [1409, 1410, "Concept"], [1419, 1430, "Concept"], [1470, 1473, "Concept"], [1478, 1481, "Concept"], [1515, 1516, "Concept"], [1529, 1530, "Concept"], [1543, 1544, "Concept"], [1563, 1564, "Concept"], [1581, 1582, "Concept"], [1593, 1594, "Concept"], [1607, 1608, "Concept"], [1625, 1626, "Concept"], [1643, 1644, "Concept"], [1653, 1654, "Concept"], [1656, 1657, "Concept"], [1663, 1664, "Concept"], [1755, 1769, "Concept"], [1827, 1832, "Concept"], [1892, 1897, "Concept"], [2406, 2420, "Concept"], [2666, 2680, "Concept"], [2715, 2720, "Concept"], [2867, 2872, "Concept"], [2873, 2878, "Concept"], [3044, 3054, "Concept"], [3150, 3165, "Concept"], [3263, 3277, "Concept"], [3280, 3293, "Concept"], [3314, 3324, "Concept"], [3444, 3457, "Concept"], [3496, 3502, "Concept"], [3530, 3536, "Concept"], [3568, 3573, "Concept"], [3607, 3615, "Concept"], [3634, 3646, "Concept"], [3671, 3675, "Concept"], [3701, 3705, "Concept"], [3780, 3781, "Concept"], [3782, 3783, "Concept"], [3784, 3785, "Concept"], [3786, 3787, "Concept"], [3788, 3789, "Concept"], [3790, 3791, "Concept"], [3879, 3893, "Concept"], [3925, 3931, "Concept"], [3985, 3991, "Concept"], [4045, 4058, "Concept"], [4455, 4461, "Concept"], [5070, 5084, "Concept"], [5087, 5100, "Concept"], [5102, 5115, "Concept"], [5124, 5129, "Concept"], [5145, 5158, "Concept"], [5312, 5317, "Concept"], [5368, 5373, "Concept"], [5388, 5393, "Concept"], [5395, 5403, "Concept"], [5439, 5447, "Concept"], [5540, 5545, "Concept"], [5643, 5657, "Concept"], [5660, 5668, "Concept"], [5685, 5698, "Concept"], [5715, 5722, "Concept"], [5727, 5732, "Concept"], [5751, 5759, "Concept"], [5871, 5892, "Concept"], [5909, 5919, "Concept"], [6006, 6020, "Concept"], [6023, 6031, "Concept"], [6158, 6162, "Concept"], [6349, 6352, "Concept"], [6425, 6439, "Concept"], [6442, 6450, "Concept"], [6506, 6520, "Concept"], [6523, 6531, "Concept"], [6612, 6626, "Concept"], [6629, 6637, "Concept"], [6678, 6681, "Concept"], [6686, 6689, "Concept"], [6717, 6731, "Concept"], [6734, 6744, "Concept"], [6749, 6762, "Concept"], [6855, 6865, "Concept"], [6902, 6908, "Concept"], [6915, 6925, "Concept"], [7030, 7043, "Concept"], [7112, 7118, "Concept"], [7125, 7135, "Concept"], [7524, 7530, "Concept"], [7559, 7568, "Concept"], [7633, 7637, "Concept"], [7645, 7653, "Concept"], [7689, 7690, "Concept"], [7726, 7737, "Concept"], [7817, 7822, "Concept"], [7850, 7864, "Concept"], [7867, 7877, "Concept"], [8072, 8082, "Concept"], [8111, 8144, "Concept"], [8150, 8153, "Concept"], [8169, 8177, "Concept"], [8207, 8213, "Concept"], [8251, 8261, "Concept"], [8300, 8314, "Concept"], [8317, 8332, "Concept"], [8347, 8355, "Concept"], [8473, 8495, "Concept"], [8545, 8576, "Concept"], [8665, 8675, "Concept"], [8728, 8758, "Concept"], [8829, 8834, "Concept"], [8841, 8849, "Concept"], [8892, 8912, "Concept"], [9011, 9026, "Concept"], [9032, 9047, "Concept"], [9928, 9942, "Concept"], [9945, 9955, "Concept"], [9957, 9970, "Concept"], [9999, 10004, "Concept"], [10079, 10084, "Concept"], [10117, 10123, "Concept"], [10140, 10151, "Concept"], [10186, 10198, "Concept"], [10234, 10244, "Concept"], [10269, 10274, "Concept"], [10275, 10280, "Concept"], [10307, 10311, "Concept"], [10319, 10323, "Concept"], [10334, 10335, "Concept"], [10391, 10405, "Concept"], [10408, 10417, "Concept"], [10418, 10427, "Concept"], [10475, 10488, "Concept"], [10574, 10578, "Concept"], [10655, 10665, "Concept"], [10675, 10678, "Concept"], [10697, 10702, "Concept"], [10723, 10727, "Concept"], [10747, 10751, "Concept"], [10769, 10773, "Concept"], [10793, 10794, "Concept"], [10834, 10838, "Concept"], [10839, 10840, "Concept"], [10880, 10884, "Concept"], [10885, 10889, "Concept"], [10939, 10944, "Concept"], [10995, 10998, "Concept"], [11047, 11053, "Concept"], [11131, 11145, "Concept"], [11148, 11157, "Concept"], [11237, 11251, "Concept"], [11340, 11345, "Concept"], [11437, 11442, "Concept"], [11638, 11652, "Concept"], [11665, 11670, "Concept"], [11677, 11683, "Concept"], [11714, 11719, "Concept"], [11732, 11737, "Concept"], [11769, 11774, "Concept"], [11829, 11834, "Concept"], [11886, 11892, "Concept"], [12085, 12099, "Concept"], [12112, 12117, "Concept"], [12124, 12130, "Concept"], [12649, 12663, "Concept"], [12676, 12681, "Concept"], [12688, 12694, "Concept"], [13138, 13152, "Concept"], [13165, 13170, "Concept"], [13177, 13183, "Concept"], [13654, 13668, "Concept"], [13671, 13685, "Concept"], [13917, 13931, "Concept"], [13934, 13947, "Concept"], [13998, 14011, "Concept"], [14034, 14037, "Concept"], [14092, 14095, "Concept"], [14213, 14227, "Concept"], [14265, 14268, "Concept"], [14272, 14275, "Concept"], [14288, 14296, "Concept"], [14302, 14305, "Concept"], [14818, 14844, "Concept"], [14871, 14885, "Concept"], [14890, 14904, "Concept"], [15393, 15397, "Concept"], [15414, 15418, "Concept"], [15501, 15505, "Concept"], [15547, 15551, "Concept"], [15594, 15608, "Concept"], [15613, 15617, "Concept"], [15745, 15749, "Concept"], [16071, 16075, "Concept"], [16163, 16166, "Concept"], [16225, 16239, "Concept"], [16513, 16517, "Concept"], [16747, 16761, "Concept"], [16840, 16854, "Concept"], [16861, 16867, "Concept"], [16910, 16924, "Concept"], [17420, 17434, "Concept"], [17445, 17448, "Concept"], [17452, 17455, "Concept"], [17456, 17462, "Concept"], [17476, 17486, "Concept"], [18005, 18019, "Concept"], [18092, 18101, "Concept"], [18439, 18450, "Concept"], [18455, 18466, "Concept"], [18471, 18480, "Concept"], [18521, 18535, "Concept"], [18561, 18573, "Concept"], [18602, 18616, "Concept"], [18619, 18639, "Concept"], [18641, 18647, "Concept"], [18661, 18681, "Concept"], [18766, 18780, "Concept"], [18783, 18803, "Concept"], [19377, 19391, "Concept"], [19394, 19414, "Concept"], [19436, 19444, "Concept"], [19473, 19485, "Concept"], [19701, 19706, "Concept"], [19739, 19748, "Concept"], [19785, 19799, "Concept"], [19802, 19822, "Concept"], [19839, 19854, "Concept"], [19914, 19928, "Concept"], [19931, 19951, "Concept"], [19957, 19977, "Concept"], [20092, 20096, "Concept"], [20189, 20203, "Concept"], [20206, 20220, "Concept"], [20227, 20234, "Concept"], [20276, 20288, "Concept"], [20291, 20298, "Concept"], [20387, 20396, "Concept"], [20401, 20409, "Concept"], [20487, 20493, "Concept"], [20508, 20522, "Concept"], [20559, 20573, "Concept"], [20576, 20590, "Concept"], [20592, 20606, "Concept"], [21060, 21074, "Concept"], [21077, 21091, "Concept"], [21100, 21114, "Concept"], [21127, 21135, "Concept"], [21181, 21189, "Concept"], [21203, 21211, "Concept"], [21242, 21249, "Concept"], [21264, 21272, "Concept"], [21323, 21337, "Concept"], [21340, 21354, "Concept"], [21360, 21369, "Concept"], [21386, 21394, "Concept"], [22002, 22016, "Concept"], [22019, 22033, "Concept"], [22060, 22068, "Concept"], [22130, 22144, "Concept"]], "Comments": []}