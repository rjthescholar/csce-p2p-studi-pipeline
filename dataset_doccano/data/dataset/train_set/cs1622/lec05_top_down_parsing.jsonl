{"id": 109, "segment": ["train_set", "labeled"], "course": "cs1622", "lec": "lec05_top_down_parsing", "text": "Top-down Parsing\nCS 1622\nJarrett Billingsley\n\n\fClass Announcements\n\u25cf how was your weekeeeeend\n\u25cf project 2 will come out this weekend so you\u2019ll have 2 weeks for it\n\n2\n\n\fParsing\n\n3\n\n\fA generative view\n\u25cf one way to use a grammar is to produce sentences in the language.\nExp:\nId | Num | Parens\nParens: '(' Exp+ ')'\nId:\n<id token>\nNum:\n<int literal token>\n\nwe can produce valid\nsentences by starting at the\nroot rule and repeatedly\nreplacing nonterminals with\ntheir right-hand sides.\n\nExp\n=> Parens\n=> '(' Exp+ ')'\n=> '(' Exp Exp Exp ')'\n\n=> '(' Id Id Num ')'\n=> '(' 'add' Id Num ')'\n=> '(' 'add' 'x' Num ')'\n=> '(' 'add' 'x' '3' ')'\n\nthis sequence is called a derivation.\n\nnow suppose we were given (add x 3) as our input. could\nwe work backwards to figure out how to get to Exp?\n\n4\n\n\fThat's what parsing is.\n\u25cf given a grammar and an input string\u2026\n\u25cf parsing is figuring out the derivation that was needed to produce\nthe input string. (and if there is no such derivation, it's an error!)\n\u25cf we represent the derivation as... an abstract syntax tree!\nExp: Id | Num | Parens\nParens: '(' Exp+ ')'\nId:\n<id token>\nNum:\n<int token>\n\nInput\ne\n(e)\n(1 2)\n(e\ne)\n()\n\nOutput AST\nId(\"e\")\nParens(Id(\"e\"))\nParens(Num(1), Num(2))\nerror!\nerror!\nerror!\n\nthe last three would benefit from some\nerror messages that help the programmer.\n\n5\n\n\fOkay what is this language?\n\u25cf this is a variety of Lisp, a language family that started in 1958.\n\u25cf we're not going to get into what it means, but it's a very easy-toparse example language.\n()\n\n(defun fact (x)\n(if (eq x 0)\ndefun\n1\n(mul x (fact (sub x 1)))))\n\nfact\n\nLisp code is basically an AST already;\nparentheses group children.\n\n()\nx\n\n()\nif\neq\n\n()\nx\n\n0\n\nthis is going to make our job of\nparsing much easier.\n\n1\n\n()\nmul\n\nx\n\n()\n\nfact ()\nsub\n\nx\n\n1\n6\n\n\fSo how do we do it?\n\u25cf well it's a bit like lexing:\no we start at the beginning, looking at tokens one-by-one.\no based on the token, we decide which rule we should use.\no if none of the rules apply, or if we see something that we don't\nexpect, we can give an error.\n\u25cf speaking of which\u2026\n\n7\n\n\fError Handling in Rust\ntime check: \u2264 17\n\n8\n\n\fThe Result type\n\u25cf Rust doesn't have exceptions like Java does.\n\u25cf if your function needs to indicate failure, it returns a Result.\n\nResult<T, E>\nT is the type of value\nreturned on success.\n\nif the function doesn't return\nany value on success, you can\nuse () \u2013 this is Rust's void.\n\nE is the type of value\nreturned for errors.\nany type can be used for errors,\nbut typically it's an enum.\n\nResult<Box<AstNode>, ParseError>\nthis is a bit unwieldy, so we can use a type alias to shorten it:\ntype ParseResult = Result<Box<AstNode>, ParseError>;\n9\n\n\fErr, ok\u2026\n\u25cf you create Results with the Ok() and Err() constructors.\nif thing.is_bad() {\n// common to use 'return' to immediately\n// leave the function. kinda like throwing\nreturn Err(ParseError::whatever());\n}\nyou can match on a Result using Ok() and Err():\nmatch parse_thing(input) {\nOk(ast) => { println!(\"{:?}\", ast); }\nErr(e) => { println!(\"o no: {}\", e); }\n}\nmatch patterns declare local variables usable in\ntheir code blocks, if that was unclear before.\n10\n\n\f???????\n\u25cf when using Result-returning functions, a really ugly pattern appears:\nmatch step_one(input) {\nOk(a) => {\nmatch step_two(a) {\nOk(b) => {\nmatch step_three(b) {\nOk(c) => {\nreturn Ok(c.to_string());\n}\nErr(e) => { return Err(e); }\n}\n}\nErr(e) => { return Err(e); }\n}\n}\nErr(e) => { return Err(e); }\n}\n\nthis is terrible. instead:\nlet a = step_one(input)?;\nlet b = step_two(a)?;\nlet c = step_three(b)?;\nOk(c.to_string())\n\nx? means, \"if x is an error,\nreturn it; otherwise, give\nme the success value.\nwe'll be seeing this a lot\nin parsing code!\n11\n\n\fRecursive Descent\ntime check: \u2264 34\n\n12\n\n\fCan we intuit our way through this?\n\u25cf with this grammar, and this sequence of tokens as our input\u2026\n\n'(', '(', 'hi', '5', ')', ')'\n\nExp:\nId | Num | Parens\nParens: '(' Exp+ ')'\nId:\n<id token>\nNum:\n<int literal token>\n\nwe are here. our ultimate goal is to build an Exp. this token is\na left-paren, so which rule do we think applies here?\nParens!\nafter the left-paren, we should see one or\nmore Exps, followed by a right-paren.\n\nbut we're already trying to parse an Exp. how do\nwe parse a new Exp without finishing this one?\n13\n\n\fThe rules are recursive, so\u2026\n\u25cf recall that all CFGs have this recursive rule structure.\n\u25cf well if the dependencies between the rules are recursive\u2026\no why not use recursive functions to model the rules?\nExp: Id | Num | Parens\nParens: '(' Exp+ ')'\nId:\n<id token>\nNum:\n<int token>\n\nlet's write some pseudocode to\nget our thoughts down.\n\nfn parse_exp() {\nmatch self.cur() {\nId\n=> parse_id(),\nIntLit => parse_num(),\nLParen => parse_parens(),\n}\n}\n\nfn parse_parens() {\neat_an_lparen();\nlet exps = \u2026parse_exp()\u2026\neat_an_rparen();\nreturn Parens(exps);\n}\n(looping happens here)\n\n14\n\n\fBelieve it or not, that's pretty much right!\n\u25cf what we've just (pseudo-)written is a recursive descent parser:\no recursive, because uh, it is!\no and descent, because we start at the root rule, and descend into\nthe other rules until we get to the terminals.\n\u25cf the issue with \"trying to parse an Exp while parsing an Exp\" is solved\nby using recursion\no when you recurse, the caller rule's execution is paused, and it\nremembers its place in the rule.\no it can then resume parsing after the callee rule has done its work.\n\u25cf so how can we be a little less \"pseudo\" about this code?\n\n15\n\n\fFrom Rules to Rust\n\u25cf each grammar rule is really a list of steps, and translating them to\nreal code is relatively straightforward:\n\nParens: '(' Exp+ ')'\nthis says that to parse a Parens:\n1. expect a '(' token and skip it.\n2. parse one Exp, since that's the minimum number.\n3. while we don't see a ')' token,\n\u2022 keep parsing Exps and put them into a list.\n4. expect a ')' token and skip it.\n\nif all of these steps succeed, we can create an\nParens AST node and return it!\n16\n\n\fOther metalanguage rule correspondences\n\u25cf there's a nice correspondence between the things we see in the\ngrammar metalanguage and the patterns we use in our code.\n\nA B\nA | B\n\nsequencing: parse an A; if that succeeds, then parse a B.\nalternation: an if-else (or a match); either parse\nan A or parse a B.\n\nA*\n\n0+ repetition: while the next token looks like an A,\nkeep parsing As.\n\nA+\n\n1+ repetition: parse an A, then do a while loop\nlike for 0+.\n\nA?\n\noptional: if the next token looks like an A, parse it.\n17\n\n\fFrom rules to AST nodes\n\u25cf similarly, when we design our AST nodes, these metalanguage rules\nimply different data structures:\n\nA B\nA | B\n\na struct, with an A field and a B field.\nan enum, where A and B are two variants.\n\nA*\nA+\n\nan array/vector, whose length is the number of\nrepetitions.\n\nA?\n\nan Option<A> field, since it might not exist.\n18\n\n\fThe example\n\u25cf now let's have a look at the new parsing_lisp example I added.\no src/lib.rs is where all the goodies are.\no the Token and AstNode types are familiar to you by now.\n\u25aa there's an extra Program rule in the grammar though.\no ParseError is an example of an error enum.\no Parser looks a lot like Lexer from your project\u2026\n\u25aa except it iterates over Tokens, not chars.\no and there are three parsing methods for the three main rules.\n\u25cf this real parser handles errors, too.\no the expect_blah methods and the match in parse_exp deal with\nunexpected terminals (tokens) in various positions.\n\u25aa they also give customized errors for each of these possibilities.\n\u25aa there's no location info, because it's an example. :B\n\n19\n\n\fLimits of Recursive\nDescent\ntime check: \u2264 68\n\n20\n\n\fIf it works so well, why not use it for everything?\n\u25cf there are lots of cases where recursive descent works great!\no import java.util.Arrays;\no use std::blah;\no fn name() { \u2026 }\no class A { \u2026 }\no if x == y { \u2026 }\no match value { \u2026 }\n\u25cf but there's something all of these things have in common:\no they all start with a token that unambiguously indicates which\nrule should be used to parse them.\no if you don't have that, recursive descent gets a lot harder to use.\n\u25cf but, what kind of code looks like that?\n\n21\n\n\fExpressions!\n\u25cf we want to be able to write expressions like we do in math.\no that is, we want 4 + 5, not (add 4 5).\n\u25cf but this presents a few problems.\n\nInput\n\nOutput\n\nx + y + z\n\n(x + y) + z or either is fine..? what\nx + (y + z) ? if it were *, -, or / ?\n\nx + 4 * y\n\n(x + 4) * y or\nx + (4 * y) ?\n\nthe second\none is right.\n\nand if we allow ** for exponents, like Python:\n\n2 ** x ** 2\n\n(2 ** x) ** 2 or\n2 ** (x ** 2) ?\n\nthe second\none is right.\n22\n\n\fEven worse\u2026\n\u25cf how do we know what kind of expression we're looking at?\n\n(3 + x + y * 2) / 50\nlet's say our parser is\nlooking at this token\u2026.\n\n\u2026how will it know it's a\ndivision until it gets here?\n\nso what do we do? look ahead? how\nmany tokens? 5? 10? is there a limit?\nwhat we would have to do here is try each\npossible parse, and backtrack if we mess up.\n23\n\n\fOH NO, BACKTRACKING\n\u25cf this is an exponential time (O(2n)) algorithm! just awful!\no and from an intuitive sense, it feels kind of silly to commit to\nparsing something when you don't actually have enough\ninformation yet to parse it.\n\u25cf so for these (and other similar) situations, there is another way to\nparse that's a little more mind-bending, but more powerful.\no that's for next time!\n\n24\n\n\fError Reporting\ntime check: \u2264 85\n\n25\n\n\fCompilers have a bit of a reputation\n\u25cf how many times have you gotten compiler errors that:\no seemed totally confused by very simple/common typos, like\nmissing a semicolon or comma or closing brace?\no pointed 100 lines after where the actual error was?\no used weird terminology, like \"specifier-qualifier-list\"?\no gave almost no information, like \"syntax error\"?\n\u25cf is it because the compiler writers suck?\no no\no good error reporting is really hard to do right, okay,\n\n26\n\n\fWho are error messages for?\n\u25cf I've said it many times: programming languages exist for humans.\n\u25cf so when a compiler gives errors, they should be\u2026 for humans!\n\u25cf but there are two things working against us here.\nthe compiler is a dumb\nalgorithm that doesn't\nunderstand our human\nmistakes\n\nf(3 4)\n----^\nexpected `)' or `,' in\nargument-list, not `4'\n\npeople who write\ncompilers tend to forget\nthat other people don't\nknow how they work\n\n(substitution of deduced\ntemplate arguments resulted\nin errors seen above)\n27\n\n\fCarry on, my wayward son\n\u25cf you know how you sometimes get like 1000 error messages?\no and it's all because you forgot ONE closing brace?\n\u25cf this is error recovery: instead of stopping at the first error, the\ncompiler tries to keep going.\nenum E {\nX,\nY\n// uh oh.\n\nbut how would you algorithmically determine\nwhere the closing brace should go?\n\nfn func() {\nlet x = E::X // oops\n(blah).y();\n}\n\nthis could even parse differently\ndepending on where we infer\nthe semicolon \"should\" be.\n28\n\n\fTo recover or not?\n\u25cf in the past, languages were simpler, and so was error recovery.\no compilers also ran on huge computers in batch jobs.\no since a compile might take hours, it was useful to report as many\nerrors as possible.\n\u25cf but now, a really, really common thing to do is:\no compile, fix the first error, repeat\n\u25aa (I really recommend you do this if you don't already)\n\n\u25cf so maybe stopping at the first error is fine?\no but what about IDEs?\no they can show multiple errors inline with the code\no so maybe there's still some use to it?\n\u25aa or does it just make using an IDE more annoying? :^)\n\n\u25cf personally I think lexing/parsing error recovery is pointless, but\ngiving multiple semantic errors can still be useful. sometimes.\n29\n\n\fA philosophy for good errors\n\u25cf there are three ways to improve error messages.\n1. say where it is\ntest.foo(9:17)\n\nbare minimum\u2026\n\ntest.foo(9:17):\nfor num in 10 {\n^ here\nbetter!\n\n2. give a unique message for that particular error\nexpected ',', not '{'\nehh\u2026\n\nfor-loop missing upper bound\nbetter!\n\n3. extra credit: tell the user how they might fix it\n\nhelp: maybe you meant \"for num in 10, something\"?\n^^^^^^^^^^^\n30\n\n\fFirst: location information\n\u25cf the lexer can associate a line and column with each token.\no well, some tokens span more than one column\u2026\no or even more than one line, if you allow multi-line strings!\no so maybe each token should have a range of locations? hmm\n\u25cf when parsing, that info can be carried from the tokens into the AST.\no that way, we can report errors during semantic analysis.\no or maybe we want to refer back to the token list somehow\u2026?\n\u25aa there are lots of ways to implement this!\n\n31\n\n\fSecond: accurate error messages\n\u25cf it's really easy to make unhelpful, uninformative messages, sadly!\n\u25cf giving accurate errors is largely about customizing the error\nmessages for each place an error could happen.\no looking through the parser code, every ? is a potential error spot.\no in parse_paren_exp, there are several of these.\n\u25cf matches are another place ripe for better errors:\no in parse_exp, there are a number of possible options, so we\nshould list the options in the error message, like \"expected\nidentifier, integer, or parenthesized expression, not blah blah\"\n\u25cf one possibility is to pass some kind of \"error context\" to the parsing\nfunctions which can be used to tailor the messages better\no since parse_exp is called from multiple places, the error message\nmight be different depending on who calls it.\n32\n\n\fThird: giving help\n\u25cf this is extremely broad and it's up to you what to say.\no it's really kind of an extension of the previous rule.\n\u25cf have a look at the error messages Rust gives.\no sometimes it's as simple as \"remove this semicolon.\"\no sometimes it links to the appropriate part of the docs.\no sometimes it even detects common mistakes and explains why\nthey won't work. it's amazing!\n\n33\n\n\f", "label": [[0, 16, "Concept"], [168, 175, "Concept"], [218, 225, "Concept"], [232, 239, "Concept"], [240, 249, "Concept"], [373, 382, "Concept"], [402, 411, "Concept"], [437, 449, "Concept"], [656, 666, "Concept"], [793, 800, "Concept"], [815, 822, "Concept"], [846, 853, "Concept"], [874, 884, "Concept"], [955, 965, "Concept"], [1002, 1012, "Concept"], [1022, 1042, "Concept"], [1156, 1159, "Concept"], [1207, 1212, "Concept"], [1214, 1219, "Concept"], [1221, 1226, "Concept"], [1268, 1282, "Concept"], [1365, 1369, "Concept"], [1479, 1484, "Concept"], [1604, 1607, "Concept"], [1704, 1711, "Concept"], [1809, 1815, "Concept"], [1857, 1863, "Concept"], [1891, 1896, "Concept"], [1914, 1918, "Concept"], [1951, 1956, "Concept"], [2024, 2029, "Concept"], [2057, 2071, "Concept"], [2106, 2112, "Concept"], [2120, 2124, "Concept"], [2224, 2230, "Concept"], [2233, 2239, "Concept"], [2369, 2375, "Concept"], [2419, 2425, "Concept"], [2452, 2458, "Concept"], [2489, 2495, "Concept"], [2607, 2613, "Concept"], [2645, 2648, "Concept"], [2667, 2674, "Concept"], [2684, 2686, "Concept"], [2693, 2696, "Concept"], [2824, 2827, "Concept"], [2863, 2868, "Concept"], [2874, 2880, "Concept"], [2887, 2889, "Concept"], [2896, 2899, "Concept"], [2903, 2908, "Concept"], [2909, 2914, "Concept"], [2930, 2932, "Concept"], [2933, 2936, "Concept"], [2960, 2963, "Concept"], [2968, 2971, "Concept"], [3009, 3014, "Concept"], [3131, 3137, "Concept"], [3190, 3195, "Concept"], [3214, 3216, "Concept"], [3225, 3230, "Concept"], [3245, 3247, "Concept"], [3256, 3261, "Concept"], [3278, 3280, "Concept"], [3296, 3298, "Concept"], [3317, 3320, "Concept"], [3336, 3339, "Concept"], [3350, 3353, "Concept"], [3369, 3372, "Concept"], [3383, 3386, "Concept"], [3402, 3405, "Concept"], [3514, 3516, "Concept"], [3533, 3535, "Concept"], [3660, 3677, "Concept"], [3749, 3756, "Concept"], [3779, 3785, "Concept"], [4005, 4009, "Concept"], [4241, 4250, "Concept"], [4274, 4278, "Concept"], [4289, 4298, "Concept"], [4299, 4303, "Concept"], [4354, 4359, "Concept"], [4364, 4373, "Concept"], [4389, 4398, "Concept"], [4885, 4909, "Concept"], [4913, 4922, "Concept"], [4981, 4991, "Concept"], [5020, 5025, "Concept"], [5046, 5055, "Concept"], [5139, 5148, "Concept"], [5160, 5167, "Concept"], [5242, 5246, "Concept"], [5269, 5276, "Concept"], [5388, 5393, "Concept"], [5409, 5421, "Concept"], [5828, 5831, "Concept"], [5876, 5880, "Concept"], [5962, 5969, "Concept"], [6032, 6042, "Concept"], [6044, 6049, "Concept"], [6079, 6084, "Concept"], [6090, 6101, "Concept"], [6135, 6140, "Concept"], [6149, 6154, "Concept"], [6165, 6178, "Concept"], [6223, 6230, "Concept"], [6240, 6253, "Concept"], [6255, 6260, "Concept"], [6306, 6314, "Concept"], [6328, 6333, "Concept"], [6351, 6356, "Concept"], [6371, 6376, "Concept"], [6380, 6389, "Concept"], [6422, 6431, "Concept"], [6452, 6457, "Concept"], [6505, 6511, "Concept"], [6547, 6551, "Concept"], [6593, 6608, "Concept"], [6661, 6670, "Concept"], [6835, 6840, "Concept"], [6845, 6852, "Concept"], [6944, 6954, "Concept"], [6989, 6995, "Concept"], [7013, 7018, "Concept"], [7064, 7070, "Concept"], [7105, 7112, "Concept"], [7159, 7165, "Concept"], [7174, 7180, "Concept"], [7261, 7270, "Concept"], [7272, 7278, "Concept"], [7330, 7336, "Concept"], [7432, 7459, "Concept"], [7567, 7584, "Concept"], [7798, 7803, "Concept"], [7809, 7822, "Concept"], [7839, 7843, "Concept"], [7862, 7867, "Concept"], [7900, 7917, "Concept"], [7992, 8003, "Concept"], [8035, 8046, "Concept"], [8482, 8492, "Concept"], [8547, 8553, "Concept"], [8573, 8578, "Concept"], [8760, 8765, "Concept"], [8771, 8780, "Concept"], [8808, 8820, "Concept"], [8834, 8850, "Concept"], [8949, 8956, "Concept"], [9022, 9027, "Concept"], [9193, 9208, "Concept"], [9232, 9241, "Concept"], [9302, 9317, "Concept"], [9580, 9592, "Concept"], [9650, 9665, "Concept"], [9714, 9728, "Concept"], [9813, 9821, "Concept"], [9828, 9834, "Concept"], [9920, 9928, "Concept"], [10070, 10079, "Concept"], [10287, 10301, "Concept"], [10366, 10380, "Concept"], [10426, 10434, "Concept"], [10625, 10630, "Concept"], [10706, 10713, "Concept"], [10772, 10786, "Concept"], [10790, 10799, "Concept"], [10852, 10859, "Concept"], [10983, 10990, "Concept"], [11006, 11011, "Concept"], [11110, 11115, "Concept"], [11173, 11179, "Concept"], [11319, 11325, "Concept"], [11326, 11333, "Concept"], [11334, 11348, "Concept"], [11383, 11398, "Concept"], [11499, 11513, "Concept"], [11858, 11878, "Concept"], [11885, 11890, "Concept"], [11907, 11911, "Concept"], [11916, 11922, "Concept"], [11933, 11938, "Concept"], [11953, 11959, "Concept"], [11979, 11985, "Concept"], [12011, 12015, "Concept"], [12066, 12071, "Concept"], [12117, 12124, "Concept"], [12160, 12166, "Concept"], [12176, 12179, "Concept"], [12207, 12213, "Concept"], [12221, 12238, "Concept"], [12280, 12285, "Concept"], [12359, 12382, "Concept"], [12461, 12476, "Concept"], [12510, 12524, "Concept"], [12543, 12548, "Concept"], [12585, 12591, "Concept"], [12621, 12626, "Concept"], [12685, 12692, "Concept"], [12727, 12733, "Concept"], [12740, 12745, "Concept"], [12828, 12841, "Concept"], [12988, 12995, "Concept"], [13062, 13067, "Concept"], [13108, 13121, "Concept"], [13328, 13342, "Concept"], [13343, 13347, "Concept"]], "Comments": []}