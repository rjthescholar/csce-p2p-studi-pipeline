{"id": 107, "segment": ["train_set", "labeled"], "course": "cs1622", "lec": "lec16_CFGs_and_IR", "text": "Control Flow Graphs and\nIR\nCS 1622\nJarrett Billingsley\n\n\fClass Announcements\n\u25cf today: a second definition for CFG in the same course\no naming is hard, ok\no at least IR is new ;O\n\n2\n\n\fWe have a problem\n\n3\n\n\fOur compiler is producing terrible code. Oh no!\n\u25cf this is what my code generator produces for this tiny function.\nfn main() {\nprintln_i(5);\n}\nmain:\nsw\nfp, -4(sp)\nsw\nra, -8(sp)\nmove fp, sp\naddi sp, sp, -12\nsw\ns0, -12(fp)\naddi sp, sp, -4\nli\ns0, 5\nsw\ns0, 0(sp)\njal println_i\nlw\ns0, -12(fp)\nlw\nra, -8(fp)\nlw\nfp, -4(fp)\naddi sp, sp, 12\njr\nra\n\nit's a little excessive. a better compiler might\nproduce this (using the real MIPS ABI):\nmain:\naddi sp, sp, -4\nsw\nra, 0(sp)\nli\na0, 5\njal println_i\nlw\nra, 0(sp)\naddi sp, sp, 4\njr\nra\n\nso\u2026 how do we get closer to that?\n4\n\n\fSomething is holding us back\n\u25cf there's a limit on the quality of code we can produce by going\ndirectly from the AST to machine/assembly code.\no we could tweak and bodge and kludge improvements on what we\nhave, and we'll asymptotically approach \"good code\" without ever\nreally getting there.\n\u25cf generating good code requires certain kinds of analyses to extract\nmore information about the program being compiled.\no control flow analysis determines the sequence in which pieces of\ncode are run (i.e. \"this runs before that; this may run before that\").\no data flow analysis determines how values are computed, copied,\nmoved, reused, saved in variables, passed to functions, and so on.\n\u25cf unfortunately, the AST is not a good fit for doing these analyses.\n\n5\n\n\fWhat's the S in AST stand for, again?\n\u25cf consider these pieces of code and their ASTs.\nlet x = 0;\nif x < 10 {\nprintln_s(\"hi!\");\n}\nprintln_s(\"done.\");\nLet\n\nId(x)\nIntLit(0)\n<\n\n{}\n\nIf\nCall\nCall\n\nId(x)\nIntLit(10)\n\ndo these two\npieces of code\nbehave similarly?\nnot at all. is it\neasy to tell that by\nlooking at the AST?\n\nId(println_s)\n[StrLit(\"hi\")]\n\nId(println_s)\n[StrLit(\"done.\")]\n\nnot really\u2026 {}\n\nlet x = 0;\nwhile x < 10 {\nprintln_s(\"hi!\");\n}\nprintln_s(\"done.\");\nLet\n\nId(x)\nIntLit(0)\n<\n\nWhile\nCall\nCall\n\nId(x)\nIntLit(10)\nId(println_s)\n[StrLit(\"hi\")]\n\nId(println_s)\n[StrLit(\"done.\")]\n\n6\n\n\fSufficiently Smart Compilers\n\u25cf there's a (possible) mistake in this code that we humans can see easily.\nlet x = 0;\nwhile x < 10 {\nprintln_s(\"hi!\");\n}\nprintln_s(\"done.\");\n\nthis loop never terminates, does it?\n\nthink about how you determined that.\n\n1. x is assigned a constant 0.\n2. x is never assigned anywhere else, not even in the loop.\n3. so, x can only be 0 in the loop condition\u2026\n4. and 0 < 10, meaning the condition is tautologically true.\njust looking at the AST, how would you prove these things?\nwhat if the control flow were a lot more complex?\n7\n\n\fProgram execution is not a tree.\n\u25cf the AST models what the programmer typed. there's another way\nof representing programs that models how the program executes.\nlet x = 0;\nif x < 10 {\nprintln_s(\"hi!\");\n}\nprintln_s(\"done.\");\nx = 0\n\nx < 10?\n\np(\"done.\")\n\nflowcharts make it\nimmediately obvious\nthat the structure of\nthese two programs\nis different.\n\np(\"hi!\")\n\nlet x = 0;\nwhile x < 10 {\nprintln_s(\"hi!\");\n}\nprintln_s(\"done.\");\nx = 0\n\nx < 10?\n\np(\"hi!\")\n\np(\"done.\")\n8\n\n\fSufficiently Simple Algorithms\n\u25cf a flowchart makes it easier to detect the problem here.\nif we consider all possible paths\nthat take us to the condition\u2026\n\nx = 0\n\nx < 10?\n\np(\"done.\")\n\np(\"hi!\")\n\nthen we can see that the only possible\nvalue for x is the constant 0.\n\nwe could give an error (or warning)\nabout the condition, or tell them that\nthis last piece of code is unreachable.\n\nthis sort of algorithm is crucial for detecting subtle bugs, doing\ncertain kinds of semantic analysis, and generating better code.\n9\n\n\fIntermediate\nRepresentation (IR)\n\n10\n\n\fReal languages are a lot bigger.\n\u25cf the AST is an abstract representation of the source language.\n\u25cf but the source language can be\u2026 complicated.\n\nshhhHHHHHHHHHH\n\nthere are so many pieces of syntax! so\nmany kinds of AST nodes! aaaHHH\n11\n\n\fTight coupling is bad.\n\u25cf a codegen algorithm that goes directly from source AST to target\nmachine code is also not very flexible.\n\nTruss AST\n\nCodegen\n\nwhat if you want to modify the\nsource language? or change the\nAST representation?\n\nMIPS Code\nwhat if you want to output a\ndifferent target language?\n\nthis algorithm tightly couples the input and output: if you want\nto change either of them, you have to change the algorithm.\n12\n\n\fHidden complexity\n\u25cf the AST can also hide operations and control flow that we have to\nknow about to be able to analyze the code properly.\nif cond { code }\n\nwhile cond { code }\n\nfor i in lo, hi { code }\n\nif !<cond> goto end\n<code>\nend:\ntop: if !<cond> goto end\n<code>\ngoto top\nend:\ni = <lo>\ntop: if i >= <hi> goto end\n<code>\ni += 1\ngoto top\nend:\n\n13\n\n\fSo instead\u2026\n\nFrontend\n\nSemantic\n\nAST\n\nLowering\n\n\u25cf an intermediate representation (IR) is essentially a third language\nthat acts as a bridge between the source and target languages.\nMIPS Backend\n\nCodegen\n\nMIPS code\n\nIR\nx86 Backend\n\nCodegen\n\nx86 code\n\nnow we can work on the frontend and backend parts in\nisolation, swap out the backend, change the AST\nwithout having to change the codegen, etc\u2026\n\n14\n\n\fIR Goals\n\u25cf we want a language with a small number of simple operations\no \u2026which can be efficiently implemented on most/all targets\n\u25cf so, something similar to assembly language\u2026\no but without being tied to a particular ISA.\n\u25cf a representation amenable to optimization would also be nice\u2026\no optimization rewrites code to do the same thing, but faster.\no simple code is easier to optimize, so we've got that covered.\n\u25cf finally, we'll want to represent control flow as a graph,\no as this enables lots of analyses for optimization and codegen that a\nlinear or tree structure would not.\n\u25cf the IR we'll be discussing is based on rustc's MIR,\no but lots of IRs are similar in their goals and structure.\n\n15\n\n\fOur IR\n\n16\n\n\fThe big picture\n\u25cf each function in the source language will be represented by a CFG.\no this is a control flow graph: essentially, a flowchart.\nfn main() {\nprintln_i(5);\n}\n\nfn test(x: bool) {\nif x {\nprintln_s(\"y\");\n} else {\nprintln_s(\"n\");\n}\n}\n\neach node in the CFG is\ncalled a basic block. this\nfunction only has one.\nbasic blocks can have 0, 1, or 2\nsuccessors: what will be run\nafter the basic block completes.\nblocks with 2 successors are\nclearly making decisions\u2026\n\n17\n\n\fThe little picture\n\u25cf each basic block will contain instructions in a simple language.\no basically, each line only does one thing.\n\nd = (x + y) * (-z / w)\nif this reminds you of asm, good.\n\n$t1 = x + y\n$t2 = -z\n$t3 = $t2 / w\nd\n= $t1 * $t3\ndestination,\nsource, operation\n\nadd\nneg\ndiv\nmul\n\n$t1, x, y\n$t2, z\n$t3, $t2, w\nd,\n$t1, $t3\n\nit's kind of like asm without loads/stores,\nand with infinite temporary registers.\n18\n\n\fLocals/temporaries\n\u25cf each function has a list of locals: places where values can be stored.\n\u25cf some of these are local variables that the user declared; others are\ntemporaries created by the code generation.\nfn func(a: int, b: int) {\nlet x = (a + b) * 3;\nprintln_i(x);\n}\n\neach local has a type and\noptionally a name (from the code).\n\nLocals\n\nCode\n\nIdx Name Type\n\n$t3 = a + b\nx = $t3 * 3\nprintln_i(x)\nreturn\n\n0\n\n()\n\n1\n\na\n\nint\n\n2\n\nb\n\nint\n\n3\n4\n\nif a local has no name, it's\nreferred to by its index in\nthe code (like $t3).\nwe'll come back to\n$t0 shortly\u2026\n\nint\nx\n\nint\n\n19\n\n\fPlaces, Constants, and Sources\n\u25cf the operands of instructions are a little freer than in assembly.\n\nSources\nPlaces\nLocals (x, $t1)\nGlobal variables\nFields (x.y)\n\na place is what can appear on\nthe LHS of an assignment.\n\nConstants\nInt Literals\nString Literals\nBool Literals\nFunction Addresses\n\na constant is just what it sounds\nlike. function addresses are\nused in function calls.\n\nboth places and constants can be used as sources, which are the\noperands on the RHS of assignments, arguments, etc.\n20\n\n\fInstruction examples\n\u25cf here are some examples of valid instructions in this IR language.\nx = 1\n\nsimple assignment of a constant to a local.\n\n$t5.y = x.y\n\nfield access can happen on either (or both)\nside(s) of an assignment.\n\nx.y = a.b.c + 1 this is still just one instruction. field access\ndoesn't count as an \"operation;\" + does.\n\n$t0 = f(1, $t1) function calls can take any number of\narguments, which are all sources.\np = &println_s\n\na function's address can be put in a place\u2026\n\np(\"hi\")\n\n\u2026and then that place can be called.\n21\n\n\fTerminators\n\u25cf a basic block (BB) contains 0 or more regular instructions, and ends\nwith a terminator, which is a control flow instruction.\na return terminator\nreturns from the function.\n\na goto terminator\nunconditionally goes to\nanother BB.\n\n...\nreturn\n\n...\ngoto bb7\n\nand a conditional terminator goes to one of\ntwo BBs, based on the condition.\n...\nif $t4 bb9 else bb12\n22\n\n\fOne way in, one way out\n\u25cf every function has at least one BB, its entry point. it's named bb0.\n\u25cf we will also ensure every function has exactly one BB with a return.\no all return statements will jump (goto) to it.\nfn f(x: bool, y: bool) {\nif x {\nif y {\nreturn;\n}\nprintln_s(\"just x\");\n} else {\nprintln_s(\"not x\");\nreturn;\n}\nprintln_s(\"done\");\n}\n\nnotice how both returns\nbecome arrows to the\nred BB (which has a\nreturn terminator).\n\nbb0\nnot x\n\njust x\ndone\n\nthis is going to make\ncertain analyses much\neasier, since some of\nthem start at the end\nand go backwards.\n23\n\n\fReturn values\n\u25cf there is a special temporary, $t0, which is used for the return value.\n\u25cf similar to the $v0 register in MIPS, a value is returned by assigning\nsomething into it before you get to the return terminator.\nfn ret(x: bool): int {\nif x {\nreturn 5;\n} else {\nreturn 10;\n}\n}\n\nLocals\n\nIdx Name Type\n0\n1\n\nint\nx\n\nbool\n\nbb0: if x bb1 else bb2\n\nbb1: $t0 = 5\ngoto bb3\n\nbb2: $t0 = 10\ngoto bb3\nbb3:\nreturn\n\nthe special parsing rule about returning\nstatements (remember that?) along with the\ntypechecking pass will ensure that this\nlocation is always assigned a value.\n24\n\n\fCodegen, but different\n\n25\n\n\fLowering\n\u25cf lowering is the process of converting the high-level, abstract syntax\ntree into the mid-level IR that we just looked at.\n\u25cf it's a kind of code generation, so there are some similarities with\nwhat we talked about before. but in many ways it's a lot simpler:\no there are infinite temporary locations, so there's no need for\ncomplex register allocation algorithms.\no it also means there's no need for stack frames, loads, stores etc.\no all locations are typed, so some implementation details are left out\n(e.g. a + b can mean addition or string concatenation, like in the\nsource language)\n\u25cf so all we have to do is:\no convert complex operations into sequences of simpler ones\no build the CFG according to the control flow statements\n26\n\n\fBuilding the CFG: straight-line code (animated)\n\u25cf if a function has no control flow, it's super simple.\nfn do_gravity(vy: int): int\nyou start with an empty BB, and\nlet ret = min(vy + 98, 800); generate IR instructions into it.\nprintln_i(ret);\nbb0: $t2 = vy + 98\nreturn ret;\nret = min($t2, 800)\n}\nLocals\nprintln_i(ret)\n$t0 = ret\nIdx Name Type\ngoto bb1\n0\nint\n1\n\nvy\n\n2\n\n3\n\nint\nint\n\nret\n\nint\n\nbb1: return\n\nwe can make a new BB for the return like here,\nor special-case it if we want a simpler CFG.\n27\n\n\fBuilding the CFG: a while loop (animated)\n\u25cf control flow structures tell us exactly where BBs need to begin/end.\nprintln_s(\"nums:\");\nlet i = 10;\nwhile i > 0 {\nprintln_i(i);\ni = i \u2013 2;\n}\n\nthe loop needs a new BB.\nwhen we start a new BB,\nthe previous one must\ngoto the new one.\ndone with the body;\nmake a new BB after it.\n\nbb0: println_s(\"nums:\")\ni = 10\ngoto bb1\nbb1: $t2 = i > 0\nif $t2 then bb2 else bb_\n3\n\nbb2: println_i(i)\ni = i - 2\ngoto bb1\nbb3:\n28\n\n\fThe shape of control flow\n\u25cf what kind of control flow statement would make each CFG?\n\nwhile true\n\nif\n\nif \u2026 else if \u2026 else\nfor(i=a; i<b; i++){\u2026}\nwhile\n29\n\n\fSome graph-related stuff\n\n30\n\n\fHow they connect (animated)\n\u25cf graphs always have all sorts of vocabulary, huh?\na BB's predecessors are all\nthe BBs that point to it.\n\na BB's successors are the\nBBs which it points to.\n\na BB can be its own\nsuccessor, in which case it is\nalso its own predecessor!\n\na back edge is one that\ngoes back to an earlier BB.\nremember: whenever you\nsee cyclic graphs, things\nare gonna get weird. 31\n\n\fVisiting arbitrary graphs\n\u25cf visiting a tree is easy: just recurse for each child node.\n\u25cf but doing that for an arbitrary graph will get you into trouble.\n1\n2\n3\n\nfn visit_node(n) {\nprint(n's number);\nfor s in n.successors() {\nvisit_node(s);\n}\n}\n\nif we run this code\non this graph,\nwhat happens?\n\nwe'll visit node 1\u2026 then 2\u2026 then 1\u2026 then 2\u2026 then 1\u2026\nclearly this isn't sufficient. when visiting an\narbitrary graph, you must manually keep track\nof which nodes have already been visited.\n32\n\n\fPostorder using depth-first traversal\n\u25cf a really common way to visit CFGs is using postorder: each node is\nvisited after all its successors have been visited.\nfn visit_node(n, visited) {\nif visited[n] { return; }\nvisited[n] = true;\nfor s in n.successors() {\nvisit_node(s, visited);\n}\nactually \"visit\" n here!\n}\n\nthis bit is what prevents us\nfrom looping infinitely.\n\nand this is where we do whatever\nwork is needed to \"visit\" n, after\nwe've visited its successors.\n\nif we say, printed out the node's name/number there,\nthis would print out the postorder of the graph.\n33\n\n\f", "label": [[0, 19, "Concept"], [24, 26, "Concept"], [110, 113, "Concept"], [165, 167, "Concept"], [210, 218, "Concept"], [272, 286, "Concept"], [578, 586, "Concept"], [627, 630, "Concept"], [876, 879, "Concept"], [883, 904, "Concept"], [1177, 1198, "Concept"], [1315, 1333, "Concept"], [1466, 1469, "Concept"], [1535, 1538, "Concept"], [1599, 1603, "Concept"], [1828, 1831, "Concept"], [2123, 2132, "Concept"], [2569, 2572, "Concept"], [2620, 2632, "Concept"], [2701, 2704, "Concept"], [2913, 2923, "Concept"], [2961, 2970, "Concept"], [3160, 3169, "Concept"], [3589, 3606, "Concept"], [3640, 3667, "Concept"], [3669, 3671, "Concept"], [3718, 3721, "Concept"], [3786, 3801, "Concept"], [3893, 3896, "Concept"], [3943, 3950, "Concept"], [3992, 3995, "Concept"], [4006, 4018, "Concept"], [4047, 4052, "Concept"], [4053, 4056, "Concept"], [4058, 4065, "Concept"], [4098, 4113, "Concept"], [4129, 4132, "Concept"], [4199, 4214, "Concept"], [4371, 4374, "Concept"], [4404, 4416, "Concept"], [4711, 4719, "Concept"], [4721, 4729, "Concept"], [4731, 4734, "Concept"], [4736, 4744, "Concept"], [4752, 4778, "Concept"], [4780, 4782, "Concept"], [4850, 4856, "Concept"], [4861, 4877, "Concept"], [4884, 4891, "Concept"], [4893, 4900, "Concept"], [4913, 4915, "Concept"], [4929, 4936, "Concept"], [4971, 4979, "Concept"], [4984, 4991, "Concept"], [5025, 5032, "Concept"], [5045, 5048, "Concept"], [5078, 5085, "Concept"], [5098, 5100, "Concept"], [5256, 5273, "Concept"], [5316, 5319, "Concept"], [5352, 5364, "Concept"], [5387, 5399, "Concept"], [5475, 5483, "Concept"], [5547, 5559, "Concept"], [5565, 5570, "Concept"], [5611, 5623, "Concept"], [5628, 5635, "Concept"], [5685, 5687, "Concept"], [5747, 5750, "Concept"], [5803, 5805, "Concept"], [5892, 5895, "Concept"], [5909, 5927, "Concept"], [5944, 5953, "Concept"], [6061, 6065, "Concept"], [6073, 6076, "Concept"], [6089, 6100, "Concept"], [6130, 6142, "Concept"], [6163, 6173, "Concept"], [6202, 6213, "Concept"], [6225, 6231, "Concept"], [6239, 6249, "Concept"], [6312, 6323, "Concept"], [6337, 6349, "Concept"], [6703, 6709, "Concept"], [6710, 6721, "Concept"], [6752, 6758, "Concept"], [6815, 6830, "Concept"], [6866, 6877, "Concept"], [6893, 6908, "Concept"], [6979, 6984, "Concept"], [6991, 6995, "Concept"], [7036, 7042, "Concept"], [7149, 7154, "Concept"], [7272, 7278, "Concept"], [7280, 7289, "Concept"], [7295, 7302, "Concept"], [7309, 7317, "Concept"], [7372, 7379, "Concept"], [7380, 7386, "Concept"], [7387, 7393, "Concept"], [7436, 7441, "Concept"], [7491, 7500, "Concept"], [7544, 7562, "Concept"], [7566, 7574, "Concept"], [7605, 7622, "Concept"], [7657, 7663, "Concept"], [7668, 7677, "Concept"], [7693, 7700, "Concept"], [7716, 7724, "Concept"], [7849, 7851, "Concept"], [7892, 7900, "Concept"], [7906, 7911, "Concept"], [8121, 8135, "Concept"], [8159, 8168, "Concept"], [8184, 8191, "Concept"], [8211, 8229, "Concept"], [8246, 8251, "Concept"], [8278, 8283, "Concept"], [8304, 8315, "Concept"], [8320, 8331, "Concept"], [8333, 8335, "Concept"], [8394, 8404, "Concept"], [8417, 8429, "Concept"], [8445, 8462, "Concept"], [8493, 8508, "Concept"], [8541, 8543, "Concept"], [8550, 8556, "Concept"], [8562, 8566, "Concept"], [8578, 8600, "Concept"], [8620, 8623, "Concept"], [8737, 8739, "Concept"], [8745, 8756, "Concept"], [8827, 8829, "Concept"], [8837, 8843, "Concept"], [8851, 8857, "Concept"], [8880, 8884, "Concept"], [8932, 8938, "Concept"], [8992, 8998, "Concept"], [9040, 9047, "Concept"], [9073, 9075, "Concept"], [9089, 9106, "Concept"], [9245, 9258, "Concept"], [9318, 9330, "Concept"], [9444, 9460, "Concept"], [9528, 9534, "Concept"], [9605, 9609, "Concept"], [9629, 9633, "Concept"], [9643, 9649, "Concept"], [9663, 9670, "Concept"], [9682, 9702, "Concept"], [9817, 9824, "Concept"], [9846, 9854, "Concept"], [9857, 9865, "Concept"], [9911, 9931, "Concept"], [9951, 9953, "Concept"], [9995, 10010, "Concept"], [10187, 10217, "Concept"], [10255, 10267, "Concept"], [10308, 10313, "Concept"], [10542, 10545, "Concept"], [10563, 10575, "Concept"], [10605, 10608, "Concept"], [10663, 10675, "Concept"], [10748, 10750, "Concept"], [10794, 10796, "Concept"], [10854, 10860, "Concept"], [10888, 10894, "Concept"], [10986, 10992, "Concept"], [11012, 11014, "Concept"], [11023, 11029, "Concept"], [11081, 11084, "Concept"], [11104, 11107, "Concept"], [11135, 11147, "Concept"], [11181, 11184, "Concept"], [11299, 11301, "Concept"], [11323, 11325, "Concept"], [11349, 11353, "Concept"], [11398, 11400, "Concept"], [11443, 11447, "Concept"], [11525, 11529, "Concept"], [11557, 11569, "Concept"], [11585, 11597, "Concept"], [11624, 11627, "Concept"], [11760, 11766, "Concept"], [11811, 11815, "Concept"], [11816, 11828, "Concept"], [11841, 11844, "Concept"], [11866, 11870, "Concept"], [11871, 11881, "Concept"], [11890, 11893, "Concept"], [11917, 11919, "Concept"], [11935, 11944, "Concept"], [11979, 11990, "Concept"], [11995, 12004, "Concept"], [12041, 12043, "Concept"], [12079, 12085, "Concept"], [12120, 12145, "Concept"], [12148, 12156, "Concept"], [12159, 12163, "Concept"], [12241, 12246, "Concept"], [12284, 12289, "Concept"], [12290, 12294, "Concept"], [12345, 12350, "Concept"], [12351, 12355, "Concept"], [12393, 12398, "Concept"], [12427, 12431, "Concept"], [12503, 12511, "Concept"], [12525, 12530, "Concept"], [12570, 12575, "Concept"], [12608, 12617, "Concept"], [12624, 12645, "Concept"], [12671, 12676, "Concept"], [12677, 12681, "Concept"], [12691, 12700, "Concept"], [12715, 12722, "Concept"], [12737, 12747, "Concept"], [12758, 12765, "Concept"], [12770, 12775, "Concept"], [12776, 12780, "Concept"], [12798, 12805, "Concept"], [12821, 12828, "Concept"], [12866, 12871, "Concept"], [12902, 12907, "Concept"], [13027, 13032, "Concept"], [13061, 13071, "Concept"], [13101, 13107, "Concept"], [13152, 13161, "Concept"], [13169, 13174, "Concept"]], "Comments": []}