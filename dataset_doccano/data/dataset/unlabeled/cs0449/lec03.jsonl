{"id": 160, "segment": "unlabeled", "course": "cs0449", "lec": "lec03", "text": "2\n\nData\n\nRepresentation\nII\n\nCS/COE 0449\nIntroduction to\nSystems Software\n\nLuis Oliveira\n(with content borrowed from wilkie and Vinicius Petrucci)\n\n\fBit Manipulation\nFlippin\u2019 Switches\n\nCS/COE 0449 \u2013 Spring 2019/2020\n\n2\n\n\fWhat are \"bitwise\" operations?\n\u2022 The \"numbers\" we use on computers aren't really numbers right?\n\u2022 It's often useful to treat them instead as a pattern of bits.\n\u2022 Bitwise operations treat a value as a pattern of bits.\n\n0\n1\n\n0\n\n0\n\n0\n3\n\n\fThe simplest operation: NOT (logical negation)\n\u2022 If the light is off, turn it on.\n\n\u2022 If the light is on, turn it off.\n\nA\n\nQ\n\n0\n\n1\n\n1\n\n0\n\n\u2022 We can summarize this in a truth table.\n\u0d25\n\u2022 We write NOT as ~A, or \u00acA, or A\n\u2022 In C, the NOT operation is the \u201c!\u201d operator\n4\n\n\fApplying NOT to a whole bunch of bits\n\u2022 If we use the not instruction (~ in C), this is what happens:\n\n~ 0 0 1 1 1 0 1 0\n\n= 1 1 0 0 0 1 0 1\nwe did 8 independent NOT operations\nThat's it.\n\nonly 8 bits shown cause 32 bits on a slide is too much\n\n5\n\n\fLet's add some switches\n\u2022 There are two switches in a row connecting the light to the battery.\n\u2022 How do we make it light up?\n\n6\n\n\fAND (Logical product)\n\u2022 AND is a binary (two-operand) operation.\n\u2022 It can be written a number of ways:\n\nA&B\n\nA\u2227B\n\nA\u22c5B\n\nAB\n\n\u2022 If we use the and instruction (& in C):\n\n1 1 1 1 0 0 0 0\n& 0 0 1 1 1 0 1 0\n= 0 0 1 1 0 0 0 0\n\nA B Q\n0 0 0\n0 1 0\n1 0 0\n\n1 1 1\n\nwe did 8 independent AND operations\n7\n\n\f\"Switching\" things up ;))))))))))))))))))))))\n\u2022 NOW how can we make it light up?\n\n8\n\n\fOR (Logical sum\u2026?)\n\u2022 we might say \"and/or\" in English\n\u2022 it can be written a number of ways:\n\n\u2022 A|B\n\nA\u2228B\n\nA+B\n\n\u2022 if we use the or instruction (or | in C/Java):\n\nA B Q\n0 0 0\n\n1 1 1 1 0 0 0 0\n| 0 0 1 1 1 0 1 0\n\n0 1 1\n\n= 1 1 1 1 1 0 1 0\n\n1 1 1\n\n1 0 1\n\nWe did 8 independent OR operations.\n9\n\n\fXOR (\u201cLogical\u201d difference?)\n\u2022 We might say \"or\" in English.\n\u2022 It can be written a number of ways:\n\nA^B\n\nA\u2295B\n\n\u2022 If we use the xor instruction (^ in C):\n\n1 1 1 1 0 0 0 0\n| 0 0 1 1 1 0 1 0\n= 1 1 0 0 1 0 1 0\n\nA B Q\n0 0 0\n\n0 1 1\n1 0 1\n1 1 0\n\nWe did 8 independent XOR operations.\n10\n\n\fBit shifting\n\u2022 Besides AND, OR, and NOT, we can move bits around, too.\n\n1 1 0 0 1 1 1 1 if we shift these bits left\nby 1\u2026\n\n1 1 0 0 1 1 1 1 0 we stick a 0 at the bottom\n1 1 0 0 1 1 1 1 0 0 again!\n1 1 0 0 1 1 1 1 0 0 0 AGAIN!\n1 1 0 0 1 1 1 1 0 0 0 0 AGAIN!!!!\n11\n\n\fLeft-shifting in C/Java\n\n(animated)\n\n\u2022 C (and Java) use the << operator for left shift\n\nB = A << 4; // B = A shifted left 4 bits\nIf the bottom 4 bits of the result are now 0s\u2026\n\u2022 \u2026what happened to the top 4 bits?\n\n0011 0000 0000 1111 1100 1101 1100 1111\nthe bit bucket is not a real place\nit's a programmer joke ok\nBit Bucket\n\nin the UK they might say the \u201cBit Bin\u201d\nbc that\u2019s their word for trash\n\n12\n\n\f>_> >_> >_> \u263a\n\u2022 We can shift right, too\n0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1\n0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1\n0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1\n0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1\n0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0\n\n\u25cf C/Java use >>, this in MIPS is the srl (Shift Right Logical) instruction\n\nsee what I mean about 32 bits on a slide\n\nQ: What happens when we shift a negative number to the right?\n\n13\n\n\fShift Right (Logical)\n\u2022 We can shift right, too (srl in MIPS)\n\n1 1 0 0 1 1 1 1\n\nif we shift these bits right\nby 1\u2026\n\n0 1 1 0 0 1 1 1 1\n\nwe stick a 0 at the top\n\n0 0 1 1 0 0 1 1 1\n\nagain!\n\n0 0 0 1 1 0 0 1 1\n\nAGAIN!\n\n0 0 0 0 1 1 0 0 1\n\nWait\u2026 what if this was a\nnegative number?\n14\n\n\fShift Right (Arithmetic)\n\u2022 We can shift right with sign-extension, too (MIPS: sra)\n\n1 1 0 0 1 1 1 1\n\nif we shift these bits right\nby 1\u2026\n\n1 1 1 0 0 1 1 1 1\n\nwe copy the 1 at the top (or 0,\nif MSB was a 0)\n\n1 1 1 1 0 0 1 1 1\n\nagain!\n\n1 1 1 1 1 0 0 1 1\n\nAGAIN!\n\n1 1 1 1 1 1 0 0 1\n\nAGAIN!!!!!! (It\u2019s still\nnegative!)\n15\n\n\fHuh\u2026 that's weird\n\u2022 Let's start with a value like 5 and shift left and see what happens:\n\nBinary\n101\n1010\n10100\n101000\n1010000\n\nDecimal\n5\n10\n20\n40\n80\n\nWhy is this happening\nWell uh... what if I gave you\n\n49018853\nHow do you multiply that by 10?\n\nby 100?\nby 100000?\nSomething very similar is\nhappening here\n16\n\n\fa << n == a * 2n\n\u2022 Shifting left by n is the same as multiplying by 2n\n\u2022 You probably learned this as \"moving the decimal point\"\n\u2022 And moving the decimal point right is like shifting the digits left\n\n\u2022 Shifting is fast and easy on most CPUs.\n\u2022 Way faster than multiplication in any case.\n\u2022 (It\u2019s not a great reason to do it when you\u2019re using C though)\n\n\u2022 Hey\u2026 if shifting left is the same as multiplying\u2026\n\n17\n\n\fa >> n == a / 2n, ish\n\u2022 You got it\n\u2022 Shifting right by n is like dividing by 2n\n\u2022 sort of.\n\n\u2022 What's 1012 shifted right by 1?\n\u2022 102, which is 2\u2026\n\n\u2022 It's like doing integer (or flooring) division\n\n\u2022 Generally, compilers are smart enough that you just multiply/divide\n\u2022 It\u2019s confusing to shift just to optimize performance.\n\u2022 It\u2019s good to not be clever until it is proven that you need to be.\n\n18\n\n\fC Bitwise Operations: Summary\nC code\n\nDescription\n\nMIPS instruction\n\nWhen x is signed (most of the time\u2026):\n19\n\n\fFractional Encoding\nEvery Time I Teach Floats I Want Some Root Beer\n\n20\n\n\fFractional numbers\n\u2022 Up to this point we have been working with integer numbers.\n\n2019\n2 0 1 9.320\n\n\u2022 Unsigned and signed!\n\n\u2022 However, Real world numbers are\u2026 Real numbers. Like so:\n\n\u2022 That create new challenges!\n\n\u2022 Let\u2019s start by taking a look at them.\n21\n\n\fJust a fraction of a number\n\u2022 The numbers we use are written positionally: the position of a digit within the\nnumber has a meaning.\n\u2022 What about when the numbers go over the decimal point?\n\n?\n2 0 1 9. 3 2 0\n\n1000s\n\n100s\n\n10s\n\n1s\n\n10ths 100ths 1000ths\n\n103\n\n102\n\n101\n\n100\n\n10-1\n\n10-2\n\n10-3\n\n22\n\n\fA fraction of a bit?\n\u2022 Binary is the same!\n\u2022 Just replace 10s with 2s.\n\n0 1 1 0 .1 1 0 1\n23\n8s\n\n22\n4s\n\n21\n2s\n\n20\n1s\n\n2-1\n2ths\n\n?\n\n2-2\n4ths\n\n2-3\n8ths\n\n2-4\n16ths\n\n23\n\n\fTo convert into decimal, just add stuff\n\n0 1 1 0 .1 1 0 1=\n23\n\n22\n\n21\n\n20\n0\u00d78+\n1\u00d74+\n1\u00d72+\n0\u00d71+\n1 \u00d7 .5 +\n1 \u00d7 .25 +\n0 \u00d7 .125 +\n1 \u00d7 .0625\n\n2-1\n\n2-2\n\n2-3\n\n2-4\n\n= 6.812510\n24\n\n\fFrom decimal to binary? Tricky?\n\n6.8125 10\n6\u00f7210 = 3R0\n3\u00f7210 = 1R1\n\n1 1 0.1101\n\n0.812510\nx\n2\n1.6250\n\nMSB\n\n0.625010\nx\n2\n1.2500\n0.250010\nx\n2\n0.5000\n0.500010\nx\n2\n1.0000\n\nLSB\n\n25\n\n\fSo, it\u2019s easy right? Well\u2026\n\nWhat about: 0.1 10\n\n0.110\nx 2\n0.2\n0.210\nx2\n0.4\n\n0.0001\n\n0.410\nx 2\n0.8\n\n0.810\nx 2\n1.6\n\n26\n\n\fSo, it\u2019s easy right? Well\u2026\u2026\n\nWhat about: 0.1 10\n\n0.0001\n1001\n\n0.610\nx 2\n1.2\n\n0.110\nx 2\n0.2\n\n0.210\nx2\n0.4\n\n0.210\nx2\n0.4\n\n0.410\nx 2\n0.8\n\n0.410\nx 2\n0.8\n\n0.810\nx 2\n1.6\n\n0.810\nx 2\n1.6\n\n27\n\n\fSo, it\u2019s easy right? Well\u2026\u2026\u2026\n\nWhat about: 0.1 10\n\n0.0001\n1001\n10\n0\n1\n...\n\n0.610\nx 2\n1.2\n\n0.610\nx 2\n1.2\n\n0.110\nx 2\n0.2\n\n0.210\nx2\n0.4\n\n0.210\nx2\n0.4\n\n0.210\nx2\n0.4\n\n0.410\nx 2\n0.8\n\n0.410\nx 2\n0.8\n\n0.410\nx 2\n0.8\n\n0.810\nx 2\n1.6\n\n0.810\nx 2\n1.6\n\n0.810\nx 2\n1.6\n\n28\n\n\fWELL\u2026\n0.00011001100110011001100110011001100110011001100110\n0110011001100110011001100110011001100110011001100110\n0110011100110011001100110011001100110011001100110011\n0100110011001100110011001100110011001100110011001100\n10\n1100110100110011001100110011001100110011001100110011\n0011001100110100110011001100110011001100110011001100\n1100110011001100110011001100110011001100110011001100110011001100110011001100110\n0110011001100110011001100110011001100110011001100110011001100110011001100110011\n0011001100110011001100110011001100110011001100110011001100110011001100110011001\n1001100110011001100110011001100110011001100110011001100110011001100110011001100\n1100110011001100110011001100110011001100110011001100110011001100110011001100110\n0110011001100110011001100110011001100110011001100110011001100110011001100110011\n0011001100110011001100110011001100110011001100110011001100110011001100110011001\n1001100110011001100110011001100110011001100110011001100110011001100110011001100\n1100110011001100110011001100110011001100110011001100110011001100110011001100110\n0110011001100110011001100110011001100110011001100110011001100110011001100110011\n0011001100110011001100110011001100110011001100110011001100110011001100110011001\n1001100110011001100110011001100110011001100110011001100110011001100110011001100\n1100110011001100110011001100110011001100110011001100110011001100110011001100110\n0110011001100110011001100110011001100110011001100110011001100110011001100110011\n0011001100110011001100110011001100110011001100110011001100110011001100110011001\n1001100110011001100110011001100110011001100110011001100110011001100110011001100\n1100110011001100110011001100110011001100110011001100110011001100110011001100110\n0110011001100110011001100110011001100110011001100110011001100110011001100110011\n0011001100110011001100110011001100110011001100110011001100110011001100110011001\n1001100110011001\u2026\n\n0. 1\n\n=\n\nCS/COE 0449 \u2013 Spring 2019/2020\n\n29\n\n\fHow much is it worth?\n\n\u2022Well, it depends on where you stop!\n\n0.0001 2\n\n= 0.0625\n\n0.00011001 2\n\n= 0.0976\u2026\n\n0.000110011001 2 = 0.0998\u2026\n30\n\n\fMind the point\n\u2022 In this representation we assume that the lowest n digits are the decimal places.\n\n$12.34\n+$10.81\n$23.15\nfp_add:\nadd v0, a0, a1\njr ra\n\n1234\n+1081\n2315\n\nthis is called fixed-point\nrepresentation\nAnd it\u2019s a bitfield :D\n\nfp_mult:\nmult\na0, a1\nmflo\nt0\nsrl t0, t0, N_BITS_FRAC\nmfhi\nt1\nsll t1, t1, N_BITS_INT\nor v0, t0, t1\njr ra\n\n31\nhttps://www.youtube.com/watch?v=GwmrIcn9Hw\n\n\fFixing the point\n\u2022 If we want to represent decimal places, one way of doing so is by assuming that\nthe lowest n digits are the decimal places.\n\n$12.34\n+$10.81\n$23.15\n\n1234\n+1081\n2315\n\nthis is called fixed-point\nrepresentation\n\n32\n\n\fA rising tide\n\u2022 Maybe half-and-half? 16.16 number looks like this:\n\n0011 0000 0101 1010.1000 0000 1111 1111\nbinary point\nthe largest (signed) value we can the smallest fraction we can\nrepresent is +32767.9999ish\nrepresent is 1/65536\nWhat if we place the binary point to the left\u2026\n\n0011.0000 0101 1010 1000 0000 1111 1111\n\u2026we can get much higher accuracy near 0\u2026\n\n\u2026but if we place the binary point to the right\u2026\n\n0011 0000 0101 1010 1000 0000.1111 1111\n\u2026then we trade off accuracy for range further away from 0.\n\n33\n\n\fMove the point\n\u2022 What if we could float the point around?\n\u2022 Enter scientific notation: The number -0.0039 can be represented:\n\n-0.39\n-3.9\n\n\u00d7 10-2\n\u00d7 10-3\n\n\u2022 These both represent the same number, but we need to move the decimal point\naccording to the power of ten represented.\n\u2022 The bottom example is in normalized scientific notation.\n\u2022 There is only one non-zero digit to the left of the point.\n\n\u2022 Because the decimal point can be moved, we call this representation:\n\nFloating point\n\n34\n\n\fFloating-point number\nrepresentation\nSeven-five-four!\n\n35\n\n\fIEEE 754\n\n\u2022 Established in 1985, updated as recently as 2008.\n\u2022 Standard for floating-point representation and arithmetic that virtually every\nCPU now uses.\n\u2022 Floating-point representation is based around scientific notation:\n\n1348 = +1.348 \u00d7 10+3\n-0.0039 = -3.9\n\u00d7 10-3\n-1440000 = -1.44 \u00d7 10+6\nsign significand\n\nexponent\n36\n\n\fBinary Scientific Notation\n\u2022 Scientific notation works equally well in any other base!\n\u2022 (below uses base-10 exponents for clarity)\n\n+1001 0101 = +1.001 0101 \u00d7 2+7\n-0.001 010 = -1.010\n\u00d7 2-3\n-1001 0000 0000 0000 = -1.001\n\u00d7 2+15\nWhat do you notice\nabout the digit before\nthe binary point?\n\n(+/-)1.f \u00d7 2exp\n\nf \u2013 fraction\n1.f \u2013 significand\nexp \u2013 exponent\n\n37\n\n\fIEEE 754 Single-precision\n\u2022 Known as float in C/C++/Java etc., 32-bit float format\n\u2022 1 bit for sign, 8 bits for the exponent, 23 bits for the fraction\n\n\u2022 Tradeoff:\n\u25aa More accuracy = More fraction bits\n\u25aa More range = More exponent bits\n\n\u2022 Every design has tradeoffs \u00af\\_(\u30c4)_/\u00af\n\u25aa Welcome to Systems!\nillustration from user Stannered on Wikimedia Commons\n\n38\n\n\fIEEE 754 Single-precision\n\u2022 Known as float in C/C++/Java etc., 32-bit float format\n\u2022 1 bit for sign, 8 bits for the exponent, 23 bits for the fraction\n\n\u2022 The fraction field only stores the digits after the binary point\n\u2022 The 1 before the binary point is implicit!\n\u25aa This is called normalized representation\n\u25aa In effect this gives us a 24-bit significand\n\u25aa The only number with a 0 before the binary point is 0!\n\n\u2022 The significand of floating-point numbers is in sign-magnitude!\n\u25aa Do you remember the downside(s)?\nillustration from user Stannered on Wikimedia Commons\n\n39\n\n\fThe exponent field\n\u2022 the exponent field is 8 bits, and can hold positive or negative exponents, but... it\ndoesn't use S-M, 1's, or 2's complement.\n\u2022 it uses something called biased notation.\n\u2022 biased representation = exponent + bias constant\n\u2022 single-precision floats use a bias constant of 127\n\nexp + 127 => Biased\n\n-127 + 127 => 0\n-10 + 127 => 117\n34 + 127 => 161\n\n\u25cf the exponent can range from -126 to +127 (1 to 254 biased)\no 0 and 255 are reserved!\n\u25cf why'd they do this?\no You can sort floats with integer comparisons!\n40\n\n\fBinary Scientific Notation (revisited)\n\u2022 Our previous numbers are actually\n\n+1.001 0101 \u00d7 2+7 = (-1)0 x 1.001 0101 \u00d7 2134-127\n-1.010\n\u00d7 2-3 = (-1)1 x 1.010\n\u00d7 2124-127\n-1.001\n\u00d7 2+15= (-1)1 x 1.001\n\u00d7 2142-127\n(-1)s x1.f \u00d7 2exp-127\n\ns \u2013 sign\nf \u2013 fraction\nexp \u2013 biased exponent\n41\n\n\fBinary Scientific Notation (revisited)\nbias = 127\n\n+1.001 0101 \u00d7 2+7\n\nsign = 0 (positive number!)\nBiased exponent = exp + 127 = 7 + 127 = 134\n= 10000110\nfraction = 0010101 (ignore the \u201c1.\u201d)\ns\n\nE\n\nf\n\n0 10000110 00101010000000000\u2026000\n(-1)0 x 1.001 0101 \u00d7 2134-127\n\n42\n\n\fBinary Scientific Notation (revisited)\nbias = 127\n\n-1.010 \u00d7 2-3 =\n\nsign = 1 (negative number!)\nBiased exponent = exp + 127 = -3 + 127 = 124\n= 01111100\nfraction = 010 (ignore the \u201c1.\u201d)\ns\n\nE\n\nf\n\n1 01111100 01000000000000000\u2026000\n(-1)1 x 1.010\n\n\u00d7 2124-127\n\n43\n\n\fEncoding an integer as a float\n\u2022 You have an integer, like 2471 = 0000 1001 1010 01112\n1.\n\nput it in scientific notation\n\n\u2022 1.001 1010 01112 \u00d7 2+11\n2.\n\nget the exponent field by adding the bias constant\n\n\u2022 11 + 127 = 138 = 100010102\n3.\n\ns\n\ncopy the bits after the binary point into the fraction field\n\nexponent\n\nfraction\n\n0 10001010 00110100111000000\u2026000\npositive\n\nstart at the left side!\n\n44\n\n\fEncoding a number as a float\nYou have a number, like -12.5937510\n1. Convert to binary:\n\nInteger part: 11002 Fractional part: 0.100112\n\n2. Write it in scientific notation:\n\n1100.100112 x 20\n\n3. Normalize it:\n\n1.100100112 x 23\n\n4. Calculate biased exponent\n\ns\n\nexponent\n\n+3 + 127 = 13010 = 100000102\n\nfraction\n\n1 10000010 10010011000000000\u2026000\n45\n\n\fwhile ( computers don\u2019t do real math ) { \u2026 }\n\nQ: Consider and/or review the IEEE 754 standard. What is happening here?\n\n46\n\n\fOther formats\n\u2022 The most common other format is double-precision (C/C++/Java double),\nwhich uses an 11-bit exponent and 52-bit fraction\n\n\u2022 GPUs have driven the creation of a half-precision\n16-bit floating-point format. it's adorable\nHow much is\nthe bias?\n\nHow much\nis the bias?\n\nboth illustrations from user Codekaizen on Wikimedia Commons\n\n47\n\n\fThis could be a whole unit itself...\n\u2022 Floating-point arithmetic is COMPLEX STUFF.\n\u2022 But it's not super useful to know unless you're either:\n\u2022 Doing lots of high-precision numerical programming, or\n\u2022 Implementing floating-point arithmetic yourself.\n\n\u2022 However...\n\u2022 It's good to have an understanding of why limitations exist.\n\u2022 It's good to have an appreciation of how complex this is... and how much better things are\nnow than they were in the 1970s and 1980s!\n\u2022 It\u2019s good to know things do not behave as expected when using float and double!!\n\n48\n\n\f", "label": [[-2, -1, "Concept"]], "Comments": []}