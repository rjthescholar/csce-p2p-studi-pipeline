{"id": 217, "segment": "unlabeled", "course": "cs1541", "lec": "lec2.4_branch_prediction", "text": "Branch Prediction and\nPredication\nCS 1541\nWonsun Ahn\n\n\fBranch Prediction\n\n2\n\n\fSolution 3: Branch Prediction\n\u25cf Comparator at ID stage is not completely satisfactory\no Still creates one bubble on a taken branch\no Also extra bubbles due to data hazards at the ID stage\n\u25cf What if \u2026\no We were able to predict the branch outcome?\no But without comparing registers?\n\n\u25cf What would that get us?\n1. We could make the prediction at the IF stage\n\u25aa We can start fetching on the correct path at very next cycle!\n2. No extra data hazard bubbles\n\u25aa We are not even reading register values, remember?\n3\n\n\fWhat if branch is mispredicted?\n\u25cf HDU can flush pipeline of wrong path instructions, just like before\no Misprediction becomes a performance, not a correctness issue\nTime\n\nblt s0,10,top\n\nla a0,done_msg\n\njal printf\ns0 < 10...\nOOPS!\nmove a0,s0\n\n0\n\n1\n\n2\n\n3\n\n4\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nIF\n\nID\n\n5\n\n6\n\n7\n\nEX\n\nMEM\n\nWB\n\nIF\n\n4\n\n\fTaken / Not Taken Branch Prediction\n\u25cf We have been doing a form of branch prediction all along!\no We assumed that all branches will be not taken\n\u25cf Two simple policies:\no Predict not taken: continue fetching PC + 4, flush if taken\nPro: Can start fetching the next instruction immediately\nCon: ~67% of branches are taken (due to loops) \u2192 many flushes\no Predict taken: fetch branch target, flush if not taken\nPro: ~67% of branches are taken (due to loops) \u2192 less flushes\nCon: ID stage must decode branch target before fetch \u2192 bubble\n\n\u25cf Both are non-ideal: there are better ways to predict!\n\n5\n\n\fTypes of Branch Prediction\n\u25cf Static Branch Prediction\no Predicting branch behavior based on code analysis\no Compiler gives hints about branch direction through ISA\no Not used nowadays due to inaccuracy of compiler predictions\n\n\u25cf Dynamic Branch Prediction\no Predicting branch behavior based on (dynamic) branch history\no Typically using hardware that tracks history information\no Premise: history repeats itself\n\u25aa Branches not taken in the past \u2192 likely not taken in the future\n(e.g. branches to error handling code)\n\u25aa Branches taken in the past \u2192 likely taken in the future\n(e.g. branch back to the next iteration of the loop)\n6\n\n\fThe Branch History Table (BHT)\n\u25cf BHT stores Taken (T) or Not Taken (NT) history info for each branch\no If branch was taken most recently, T is recorded\no If branch was not taken most recently, NT is recorded\n\u25cf BHT is indexed using PC (Program Counter)\no Each branch has a unique PC, so a unique entry per branch\n\u25cf BHT, being hardware, is limited in capacity\no Cannot have a huge table with all PCs possible in a program\no Besides, not every PC address contains a branch\no Best to use hash table to map branch PCs to (limited) entries\n\n7\n\n\fThe Branch History Table (BHT)\nHash\nPC:\n0x007FA004\n\n0\n\n==?\n\nentry = Hash(PC)\nif(entry.PC == PC\n&& entry.pred == T)\nNextPC = inst.target\nelse\nNextPC = PC+4\n\n#\n\nBranch PC\n\nPred.\n\n0 0x007FA004\n\nT\n\n1 0x007FC60C\n\nNT\n\n2 0x007FA058\n\nT\n\n3\n\nNT\n\n...\n\n4 0x007FC380\n\nT\n\n5\n\n...\n\nT\n\n6\n\n...\n\nNT\n\n7\n\n...\n\nNT\n\nT?\n\nTo filter out conflicts in hash function\n8\n\n\fLimitations of Branch History Table (BHT)\n\u25cf Ideally, we would like know what next to fetch at the IF stage\no So that correct instruction is immediately fetched in next cycle\n\u25cf BHT can give us branch direction IF stage\no All the information needed is the PC (which is available at IF)\n\u25cf But also need the branch target to know what to fetch\no Must wait until the ID stage for branch target to be decoded\no If NT in BHT: no need to wait (branch target is irrelevant)\nBut if T in BHT: need to wait until ID stage\n\n\u25cf That introduces a bubble for taken branches\n\n9\n\n\fThe Branch Target Buffer (BTB)\n\u25cf BTB stores branch target for each branch\n\n\u25cf BTB is also indexed using PC of branch using a hash table\n\u25cf BTB allows branch target to be known at the IF stage\no No need to wait until ID stage for branch target to be decoded\n\n10\n\n\fThe Branch Target Buffer (BTB)\nHash\nPC:\n0x007FA004\n\n0\n\n==?\n\nentry = Hash(PC)\nif(entry.PC == PC)\nNextPC = entry.target\nelse\nNextPC = PC+4\n\n#\n\nBranch PC\n\nBranch Target\n\n0 0x007FA004\n\n0x007FA03C\n\n1 0x007FC60C\n\n0x007FC704\n\n2 0x007FA058\n\n0x007FA040\n\n3\n\n...\n\n4 0x007FC380\n\n...\n0x007FC398\n\n5\n\n...\n\n...\n\n6\n\n...\n\n...\n\n7\n\n...\n\n...\n\n11\n\n\fBHT + BTB Combined Branch Predictor\nHash\nPC:\n0x007FA004\n\n0\n\n==?\n\nentry = Hash(PC)\nif(entry.PC == PC\n&& entry.pred == T)\nNextPC = entry.target\nelse\nNextPC = PC+4\n\n#\n\nBranch PC\n\nPred.\n\nBranch Target\n\n0 0x007FA004\n\nNT\n\n0x007FA03C\n\n1 0x007FC60C\n\nNT\n\n0x007FC704\n\n2 0x007FA058\n\nT\n\n0x007FA040\n\n3\n\nNT\n\n...\n\n4 0x007FC380\n\nT\n\n0x007FC398\n\n5\n\n...\n\nT\n\n...\n\n6\n\n...\n\nNT\n\n...\n\n7\n\n...\n\nNT\n\n...\n\n...\n\n12\n\n\fBranch Prediction Decision Tree\nAssuming that branch condition and target are resolved in ID stage\nSend PC to\nInstruction memory\nand BTB\n\nIF\n\nno\nID\n\nno\n\nSet PC =\nPC+4\n\nIs\ninstruction\na branch?\n\nNormal\ninstruction\nexecution\n\nEntry\nfound in\nBTB?\n\nyes\nBranch\ntaken?\n\nno\nRecord the\nentry in BTB\n\nyes\n\nno\nyes\n\nBranch\npredictor\n\nSet PC =\npredicted target\nor PC+4\n\nPrediction\nwas\ncorrect?\n\n1. PC = correct target PC\n2. Kill instruction in IF\n3. Add/correct the entry in BTB\n\ncondition\ntarget\nIF.Flush\n\nM\nu\nx\n\nPC + 4\n\n4\n\nyes\nNormal\ninstruction\nexecution\n\nP\nC\n\n+\n\nRegisters\n\nInstruction\nmemory\n\nIF/ID\n\nImmediate\nconstant\n\nID/EX\n\n13\n\n\fLimitations of 1-bit BHT Predictor\n\u25cf Is 1-bit (T / NT) enough history to make a good decision?\n\n\u25cf Take a look at this example:\nfor (j=0; j<100; j++) {\nfor (i=0; i< 5; i++) {\nA[i] = B[i] * C[i];\nD[i] = E[i] / F[i];\n}\n}\n\nPredicted\n\n-\n\nT\n\nT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nActual\n\nT\n\nT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nT\n\nthis branch is predicted wrong\ntwice every inner loop\ninvocation (every 5 branches)\n\n\u25cf It would have been better to stay with T than flip back and forth!\n\u25cf Idea behind the 2-bit predictor: make predictions more stable\no So that predictions don\u2019t flip immediately\n\n14\n\n\f2-bit BHT Predictor\n\u25cf State transition diagram of 2-bit predictor:\n\nchange in prediction\n\n\u25cf Can be implemented using a 2-bit saturating counter\no Strongly not taken: 00\no Weakly not taken: 01\no Weakly taken: 10\no Strongly taken: 11\n15\n\n\f2-bit BHT Predictor\n\u25cf How well does the 2-bit predictor do with our previous example?\n\n\u25cf Our previous example:\nfor (j=0; j<100; j++) {\nfor (i=0; i< 5; i++) {\nA[i] = B[i] * C[i];\nD[i] = E[i] / F[i];\n}\n}\n\nPredicted\n\n-\n\nT\n\nT\n\nT\n\nT\n\nT\n\nT\n\nT\n\nT\n\nT\n\nT\n\nT\n\nT\n\nActual\n\nT\n\nT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nT\n\nthis branch is predicted wrong\nonly once every inner loop\ninvocation (every 5 branches)\n\n\u25cf Does it help beyond 2 bits? (e.g. 3-bit predictor, or 4-bit predictor)\no Empirically, no. 2 bits already cover loop which is most common.\no 2 bits + large BHT gets you ~93% accuracy\n\u25cf We need other tricks to improve accuracy!\n16\n\n\fLimitations of 2-bit BHT Predictor\n\u25cf Here is an example where 1-bit BHT predictor fails miserably\nfor (j=0; j<100; j++) {\nif (j % 2) {\n}\n}\n\nYou get the prediction wrong every single time!\nPredicted\n\n-\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nActual\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\n\u25cf And a 2-bit predictor doesn\u2019t do very well either\nfor (j=0; j<100; j++) {\nif (j % 2) {\n}\n}\n\nYou get the prediction wrong every other time!\nPredicted\n\n-\n\nNT NT NT NT NT NT NT NT NT NT NT NT\n\nActual\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\no Would a 3-bit predictor do any better?\n\u25cf Idea: Base prediction on a pattern found in history of branches!\no Rather than relying on a single prediction for a branch\no If History: T \u2192 predict NT, if History: NT \u2192 predict T\n17\n\n\fCorrelating Predictors leverage patterns\n\u25cf Correlating Predictor: Uses patterns in past branches for prediction\no Often branch behavior more complex than just taken or not taken\no Often correlates to a pattern of past branches\n\u25cf Pattern may exist in two ways:\no Pattern in local branch history (history of only current branch)\no Pattern in global branch history (history of all branches)\n\n\u25cf Maintaining longer history allows detection of longer patterns\no Local branch history for each branch maintained at all times\no One global branch history maintained at all times\n\n18\n\n\fLocal Branch History Correlating Predictor\n\u25cf With a local branch history of 1, can predict perfectly!\nfor (j=0; j<100; j++) {\nif (j % 2) {\n}\n}\n\nPredict with branch PC + 1 local branch history\nPredicted\n\n-\n\n-\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nActual\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\nT\n\nNT\n\n\u25cf Local branch history changes as such:\no NT \u2192 T \u2192 NT \u2192 T \u2192 NT \u2192 T \u2192 NT \u2192 T \u2192 NT \u2192 T \u2192 \u2026\n\u25cf Prediction based on branch PC and local branch history:\no PC: if (j % 2) + History: NT\n\u2192 Prediction: T\no PC: if (j % 2) + History: T\n\u2192 Prediction: NT\n\n19\n\n\fLocal Branch History Correlating Predictor\n\u25cf You need a local branch history of 2 for this one.\nfor (j=0; j<100; j++) {\nif (j % 3) {\n}\n}\n\nPredict with branch PC + 2 local branch history\nPredicted\n\n-\n\n-\n\n-\n\n-\n\n-\n\nT\n\nNT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nNT\n\nActual\n\nNT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nNT\n\nT\n\nT\n\nNT\n\n\u25cf Local branch history changes as such:\no NT, T \u2192 T, T \u2192 T, NT \u2192 NT, T \u2192 T, T \u2192 T, NT \u2192 NT, T \u2192 \u2026\n\u25cf Prediction based on branch PC and local branch history:\no PC: if (j % 3) + History: NT, T\n\u2192 Prediction: T\no PC: if (j % 3) + History: T, T\n\u2192 Prediction: NT\no PC: if (j % 3) + History: T, NT\n\u2192 Prediction: T\no PC: if (j % 3) + History: NT, NT\n\u2192 No prediction\n20\n\n\fGlobal Branch History Correlating Predictor\n\u25cf Knowing the result of other branches in your history also helps\nIf (j == 0) {\n}\n\u2026\nIf (j != 0) {\n}\n\ncurrent\n\nKnowing result of a previous different branch in\nyour history helps in predicting current branch!\n\n\u25cf This is called global branch history (involves all branches).\n\n\u25cf Can be helpful when local branch history can\u2019t capture pattern.\n\n21\n\n\fUnified Correlating Predictor\n\u25cf Correlates prediction with branch history as well as branch PC\no Local branch history + Global branch history\no An entry with matching history gives more precise prediction!\n\u25cf Now, instead of indexing into BHT by branch PC only\no Use hash(PC, Local branch history, Global branch history)\n\u25cf History is stored in register called Branch History Shift Register (BHR)\no T/NT bit is shifted on to BHR whenever branch is encountered\n1. One Global BHR (there is just one global history)\n2. Multiple Local BHRs (local histories for each branch PC)\n\n22\n\n\fCorrelating Predictors\nHash\n\n0\n\nPC\n# Tags Local BHRs\n0 PC T, NT, NT, T, \u2026\n1 PC T, T, NT, T, \u2026\n2 PC\nT, T, T, T, \u2026\n3 ...\n...\n\nGlobal BHR\nT, NT, NT, T, T, NT, \u2026\n\n#\n\nTags\n\nPred.\n\nBranch Target\n\n0\n\nPC+History\n\n01\n\n0x007FA03C\n\n1\n\nPC+History\n\n00\n\n0x007FC704\n\n2\n\nPC+History\n\n11\n\n0x007FA040\n\n3\n\n...\n\n01\n\n...\n\n4\n\nPC+History\n\n10\n\n0x007FC398\n\n5\n\n...\n\n00\n\n...\n\n6\n\n...\n\n10\n\n...\n\n7\n\n...\n\n11\n\n...\n\n\u25cf Can reach up to 97% accuracy!\n23\n\n\fHow about jr $ra?\n\u25cf jr $ra: Jump return to address stored in $ra\no When a function is called, the caller stores return address to $ra\n(jal funcAddr stores PC of next instruction to $ra)\no When a function returns, jr $ra jumps to return address in $ra\n\n\u25cf Why is this a problem?\no Unlike other branches, branch target is not an immediate value!\n(Jumping to a variable target is called an indirect branch)\no Target can change for same jr depending on who caller is\no Makes life difficult for BTB which relies on target being constant\n\u25cf Target of jr is predicted using the Return Stack Buffer\no Not the Branch Target Buffer (BTB)\n24\n\n\fThe Return Stack Buffer\n\u25cf Since functions return to where they were called every time,\nit makes sense to cache the return addresses (in a stack)\nWhen we encounter\n4AB33C jal someFunc\nthe jal, push the\n4AB340 beq v0, $0, blah return address.\n...\nWhen we encounter\nthe jr $ra, pop the\nsomeFunc:\nreturn address. Easy!\n...\njr $ra\n\n\u25cf On misprediction or stack overflow, empty stack\no Not a problem since this is for prediction anyway\n\n40CC00\n46280C\n4AB108\n000000\n4AB340\n000000\n000000\n000000\n000000\n\n25\n\n\fPerformance Impact with Branch Prediction\n\u25cf Now, CPI = CPInch + a * p * K\n\no CPInch : CPI with no control hazard\no a : fraction of branch instructions in the instruction mix\no p : probability a branch is mispredicted\no K : penalty per pipeline flush\n\n\u25cf With deep pipelines, mispredictions can have outsize impact\nExample: If 20% of instructions are branches and the misprediction rate is\n5%, and pipeline flush penalty 20 cycles, then:\nCPI = CPInch + 0.2 * 0.05 * 20 = CPInch + 0.2 cycles per instruction\n\n\u25cf If, CPInch is 0.5, then that is 40% added to execution time!\n\u25cf Problem is a small percentage of hard to predict branches\no How do we deal with these?\n26\n\n\fPredication\n\n27\n\n\fBranch Mispredictions have Outsize Impact\n\u25cf Assume a deep pipeline and if(s1 >= 0) is hard to predict\n\nif(s1 >= 0)\ns2 = 0;\nfor(s0 = 0 .. 10)\ns3 = s3 + s0;\n\nblt\nli\n\ns1, 0, top\ns2, 0\n\ntop:\nadd s3, s3, s0\naddi s0, s0, 1\nblt s0, 10, top\n\nMispredict\n\nFlush!\n\n\u25cf On a misprediction, every following instruction is flushed\no Not only the control dependent instructions (li s2, 0)\no But also multiple iterations of the \u201cbystander\u201d loop that were fetched\n28\n\n\fSolution 4: Predication\n\u25cf Predicate: a Boolean value used for conditional execution\no Instructions that use predicates are said to be predicated\no A predicated instruction will modify state only if predicate is true\no ISA is modified to add predicated versions for all instructions\n\n\u25cf Example of code generation using predication:\npge p1, s1, 0\n# Store boolean s1 >= 0 to predicate p1\nli.p s2, 0, p1\n# Assign 0 to s2 if p1 is true\nsw.p s3, 0(s4), p1 # Store s3 to address 0(s4) if p1 is true\n\n\u25cf Now there is no branch. It is just straight-line code!\no Control dependencies have been converted to data dependencies\n\n29\n\n\fCode with predication\n\u25cf Now there are no branches!\n\nif(s1 >= 0)\ns2 = 0;\nfor(s0 = 0 .. 10)\ns3 = s3 + s0;\n\npge p1, 0, s1\nli.p s2, 0, p1\ntop:\nadd s3, s3, s0\naddi s0, s0, 1\nblt s0, 10, top\n\n\u25cf Drawback: even if branch not taken, li.p fetched (acts like a bubble)\no But often worth it for hard to predict branches!\no For easy to predict branches, often not worth it.\n30\n\n\fWhat does predication mean for the pipeline?\n\u25cf Again, predicates are registers just like any other register\n\u25cf Predicate dependencies work just like other data dependencies\nTime\n\n0\n\n1\n\n2\n\n3\n\n4\n\npge p1, 0, s1\n\nIF\n\nID\n\nEX\n\nMEM\n\nWB\n\nIF\n\nID\n\nEX\n\nMEM\n\nli.p s2, 0, p1\n\n5\n\n6\n\n7\n\nWB\n\n\u25cf With data forwarding, no stalls required!\no Predicate forwarded to li.p EX stage\no Later predicate enables/disables regwrite control in li.p WB stage\n31\n\n\fWhat does predication mean for the compiler?\n\u25cf Compiler can schedule instruction more freely!\n\nif(s1 >= 0)\ns2 = 0;\nfor(s0 = 0 .. 10)\ns3 = s3 + s0;\n\npge\n\np1, 0, s1\n\ntop:\nadd s3, s3, s0\naddi s0, s0, 1\nblt s0, 10, top\nli.p s2, 0, p1\n\n\u25cf Low-power compiler-scheduled processors often support predicates\n32\n\n\fPredication in the Real World\n\u25cf Predication is only beneficial for hard to predict branches\n\n\u25cf So how does the compiler figure out the hard to predict branches?\no Through code analysis\no Through software profiling (model a branch predictor)\n\u25cf Supported in various ISAs\no ARM allows most instructions to be predicated\no Intel x86 has conditional move instructions (cmov)\no SIMD architectures use predication in the form of a logical mask\n\u25aa Only data items that are not masked are updated\n\u25aa Intel AVX vector instructions\n\u25aa GPU instructions (e.g. CUDA)\n33\n\n\f", "label": [[-2, -1, "Concept"]], "Comments": []}