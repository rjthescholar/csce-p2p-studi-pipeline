{"id": 232, "segment": "unlabeled", "course": "cs1541", "lec": "lec3.4_virtual_memory", "text": "Virtual Memory\nand Caching\nCS 1541\nWonsun Ahn\n\n\fVirtual Memory and Caching\n\u25cf So what does virtual memory have to do with caching?\n\u25cf A lot actually.\n\u25cf But first let\u2019s do a quick review of virtual memory\no To warm up your cache with CS 449 info\n\n2\n\n\fVirtual Memory Review\n\n3\n\n\fVirtual Memory: Type of Virtualization\n\u25cf Virtualization: hiding the complexities of hardware to software\n\u25cf Virtual Memory: hides the fact that physical memory (DRAM) is\nlimited and shared by multiple processes\nPhysical Memory\nProcess 1\n0xFFFF\n\n0xFFFF\n\nMemory\n\n0x8000\n\nCode\n\n...\n\nProcess 2\n0xFFFF\n\nProcess 1\u2019s\nand\nProcess 2\u2019s\nmemory?\n\nMemory\n\n0x8000\n\nCode\n\nClearly this is impossible.\nBut programs see this view of memory.\n\n0x8000\n...\n\n4\n\n\fVirtual Memory: Behind the Scenes\n\u25cf Pages of memory are mapped to either physical memory or disk\no Look familiar? Physical memory acts as a cache for disk storage\n\nValid\n1\n0\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n\nPage table\n\nPhysical memory\n\nVirtual memory\nDisk storage\n(swap space)\n\n5\n\n\fHow virtual to physical address translation happens\n1. CPU extracts virtual page number from virtual address\n2. CPU locates page table pointed to by page table register\n3. Page table is indexed using virtual page number\nPage table register\nVirtual address\n\n31 30 29 28 27\n\n15 14 13 12 11 10 9 8\n\nVirtual page number\nVirtual address\n31 30 29 28 27\n\n15 14 13 12 11 10 9 8\n\nVirtual page number\n\npage offset\n\n20\n\n3210\n\nValid\n\npage offset\n\n3 2 1 0\n\n12\n\nPhysical page number\n\nPage table\n29 28 27\n\n15 14 13 12 11 10 9 8\n\nPhysical page number\nPhysical address\n\n3210\n\npage table\n\npage offset\nIf 0 then page is\nnot in memory\n29 28 27\n\n18\n\n15 14 13 12 11 10 9 8\n\nPhysical page number\n\n3 2 1 0\n\npage offset\n\nPhysical address\n\n6\n\n\fDRAM as Cache\n\n7\n\n\fPhysical Memory as a Cache\n\u25cf Relationship between DRAM \u00ab Disk is same as Cache \u00ab DRAM\no DRAM is fast but small and expensive\no Disk is slow but big and cheap\n\u25cf If you view DRAM as cache, some design decisions become obvious\no Size of block: 4 KB pages. Why?\n\u00a7 For spatial locality. Capacity is less of a problem for DRAM.\no Associativity: Fully-associative (can map page anywhere). Why?\n\u00a7 A miss (page fault) is expensive. You need to read from disk!\n\u00a7 But now page hits become expensive due to lookup cost\no Block replacement scheme: LRU, or some approximation. Why?\n\u00a7 Did I say a page fault is expensive?\no Write policy: Write-back (a.k.a. page swapping). Why?\n\u00a7 Bandwidth for write-through to disk is too much for I/O bus\n8\n\n\fPhysical Memory as a Cache\n\u25cf If you treated each page as a cache block, what would be the tag?\nPage offset (12 bits)\no 32-bit address: Tag (20 bits): page number\no Fully-associative, so row bits and 4 KB pages, so 12 bits for offset\n\u25cf How would the page table for searching physical memory look?\n\nCPU\n(PID 1)\nCPU\n(PID 2)\n.\n.\n.\n\nAccess\n\nPID\n\n20-bit tag\n(page number)\n\n1\n\n10110\u2026111\n\n2\n\n10010\u2026001\n\n1\n\n01010\u2026100\n\n\u2026\n\n\u2026\n\n[Page Table]\n\nPhysical\nMemory\n[Pages]\n\nMiss\nDisk storage\n(swap space)\n\n[Disk]\n9\n\n\fInverted Page Table: tags for physical pages\n\u25cf This type of page table is called an inverted page table.\nAssociative search\n\nVirtual Page\nNumber\n\nPID\n\n20-bit tag\n(page number)\n\n1\n\nVirtual Page 42\n\n2\n\nVirtual Page 100\n\n1\n\nVirtual Page 123\n\n\u2026\n\n\u2026\n\n[Page Table]\n\nPhysical\nMemory\n[Pages]\n\nMiss\nDisk storage\n(swap space)\n\n[Disk]\n\n\u25cf Called inverted because table contains virtual page numbers\n(Unlike regular page tables which contains physical page numbers)\n\u25cf Pro: Page table only as big as physical mem (low space complexity)\n\u25cf Con: Associative search of page table (high time complexity)\n\u2192 Often hashing used to direct map pages. Causes conflict misses.\n10\n\n\fHow Often do Lookups Happen?\n\u25cf Programs use virtual addresses to refer to code and data\no E.g. If program has jump to method address, it\u2019s a virtual address\n\u25cf DRAM and Caches use physical addresses\n\u25cf At every lw or sw MEM stage a lookup needs to happen\n\u25cf At FETCH stage of every instruction a lookup needs to happen!\nProcess\n\nVirtual\nMemory\nCode\n\nVirtual\nAddresses\n\n?\nCPU ? Cache\n?\n\nPhysical\nAddresses\n\nPhysical\nMemory\n\n11\n\n\fAddress Lookup Using (Regular) Page Table\n\u25cf Lookup is done by indexing page table using virtual page number.\n\u25cf Every memory access requires one extra access to read page table.\nNow table must cover entire virtual memory!\nVirtual\nAddress\n\nCPU\n\nValid\n\nPhysical Page\nNumber (20 bits)\n\n1\n\nPhysical Page 42\n\n0\n\nPhysical Page 10\n\n0\n\nPhysical Page 7\n\n1\n\nPhysical Page 1337\n\n\u2026\n\n\u2026\n\nPhysical\nAddress\n\nDRAM\n\n12\n\n\fHow big is the Page Table?\n\u25cf 32-bit addresses with 4KiB (212 B) pages means 220 (1M) PTEs.\n\u25cf 64-bit addresses with 4KiB pages means 252 (4 quadrillion) PTEs.\n\u25cf We can use hierarchical page tables as a sparse data structure.\nAddress\n\nPTR\n\n10 bits (\u201cdirectory\u201d)\n\n10 bits (\u201ctable\u201d)\n\n12 bits (\u201coffset\u201d)\n\n00 0010 11\n\n10 0011 00\n\n0010 0001 0000\n\nindex...\n\nindex...\n\nV Table Addr\n\nV D R Page Addr\n\nP\n\n\u2026\n\n...\n\n\u2026\u2026 \u2026\n\n...\n\n...\n\n1\n\n0004C000\n\n10 1\n\n03BFA000\n\nRX\n\n\u2026\n\n...\n\n\u2026\u2026 \u2026\n\n...\n\n...\n\nPA!\n\n13\n\n\fPage Table Lookup Cost\n\u25cf Let\u2019s say we have a lw $t0, 16($s0)\n\nPTR\n\nCPU\n\nV Table Addr\n\nV D R Page Addr\n\nP\n\n\u2026\n\n...\n\n\u2026\u2026 \u2026\n\n...\n\n...\n\n1\n\n0004C000\n\n10 1\n\n03BFA000\n\nRX\n\n\u2026\n\n...\n\n\u2026\u2026 \u2026\n\n...\n\n...\n\nhit!\n\nPA!\n\nCache\n\n\u25cf Must perform two memory accesses to hierarchical page table\no May miss in cache and even cause page faults themselves!\n14\n\n\fThe real picture looks more like this\n\u25cf Alpha 21264 CPU with 3-level page table:\n\nIn the end, the PTE (Page Table Entry)\nis all you need for a translation.\n\nPtr to level 2\nPtr to level 3\n\nHow can I make access to it faster?\nWhere have I heard that before...\nmaking accesses faster\u2026 I wonder\u2026\n\n15\n\n\fThe TLB:\nA Cache for Page Tables\n\n\fTLB (Translation Lookaside Buffer\n\u25cf TLB: A cache that contains frequently accessed page table entries\n\u25cf TLB just like other caches\nresides within the CPU\n\u25cf On a TLB hit:\no No need to access page\ntable in memory\n\u25cf On a TBL miss:\no Load PTE from page table\no That means \u201cwalking\u201d the\nhierarchical page table\n\n17\n\n\fPage Table Walking\n\u25cf On a TLB miss, the CPU must \u201cwalk\u201d the page table:\n\u25cf Two options:\n1. Software option\no Miss raises OS exception\no OS exception handler\nfills the TLB with PTE\n\nPtr to level 2\nPtr to level 3\n\n2. Hardware option\no CPU has special circuitry\nto walk page table\n(the page table walker)\n\u2192 Faster than SW option\n18\n\n\fMemory Access Flowchart\nVirtual page\nnumber\n\nPage offset\n\nTLB\n\n\u2022 Page table walk to get the PT\nentry into the TLB (SW or HW)\n\u2022 If PT walk indicates page is\nnot in memory, then service\npage fault (OS handler)\n\nPhysical\naddress\n\nCache\nTo memory\n\nNote that there cannot be a\npage fault in case of a TLB hit\n\u2013 when page is swapped to\ndisk, the TLB is flushed\n\nMay need to write\nback a dirty block\n\nor,\ndepending\non being\nwrite back\nor write\nthrough\n\n19\n\n\fClose-up on the TLB\n\u25cf The TLB holds PTEs \u2013 mappings from VAs to PAs, along with other\ninfo used for protection and paging.\n\nVA\n\nVA Page (Tag)\n\nV\n\nD\n\nPres Ref Prot PA Page\n\n00008\n\n1\n\n0\n\n0\n\n1\n\nRX\n\n03BFA\n\nFFFF3\n\n1\n\n1\n\n1\n\n1\n\nRW\n\n19400\n\n\u2026\n\n\u2026\n\n\u2026\n\n\u2026\n\n\u2026\n\n\u2026\n\n\u2026\n\nPA\n\n0 valid bit triggers TLB Miss.\n0 present bit triggers Page Fault.\nD-Read, D-Write, or I-Fetch? Exception if invalid!\n20\n\n\fTLBs in Real Processors\n\n21\n\n\fCaching Makes Everything Faster\nCPU\nVirtual address from lw/sw instructions or\nfrom program counter (PC)\n\nVA Page#\n\npage\npage\n\nPage offset\n\npage\nBlock of a page\n\nTLB\n\nPhysical\naddress\n\nPhysical\nMemory\n\nCache\n\nPTE\n\nTLB miss\nPT walker\n\nPage fault\n\nPTE into TLB\n\nVirtual\nAddress\nspace\n\nHDD/SSD\n\nPage\ntable\n\nOh no!\n\nOS Page Fault Handler\n\n22\n\n\fOverall Memory System Design\n\u25cf Fast memory access is possible through SW / HW collaboration:\n\nAddress\nTranslation\n(HW / SW)\n\nVA\n\nTLB\n\nCaching\n(HW)\n\nPA\n\nDatapath\n\nPA\nCaches\n\nWords\n/bytes\n\nPaging\n(SW)\n\nDRAM\n\nBlocks\n\nPT\n\nPages\n\nHDD/SSD\n\n23\n\n\f", "label": [[-2, -1, "Concept"]], "Comments": []}