{"id": 228, "segment": "unlabeled", "course": "cs1622", "lec": "lec11", "text": "Backend and Runtime\nCS 1622\nJarrett Billingsley\n\n\fClass Announcements\n\u25cf today is kind of an intro to the second half of the course\n\u25cf how was the exaaaaaaaam?\n\u25cf also I\u2019m realizing that there are actually way more minutes of lecture\nin the summer term than in spring/fall so I shouldn\u2019t feel pressured\nto make every lecture take all 105 minutes\n\n2\n\n\fWelcome to the Backend!\n\n3\n\n\fThrough the looking glass\n\u25cf a compiler translates from a source language to a target language.\no well, now we're done with the source language.\n\u25cf once the AST has been constructed and semantically analyzed\u2026\no we have a \"correct\" program!\n\u25cf from here on out, we're assuming that we're working with an AST\nthat represents a correct program.\no later we'll come back and look at intermediate representation\n(IR), which lets us abstract away even the AST itself.\n\n4\n\n\fWhat is the backend responsible for?\n\u25cf a compiler translates from the source language to the target.\n\u25cf so far, all we've done is validate the source code.\n\u25cf that means the backend does the actual translation!\nit maps each part of the source language into some target language\ninstructions that do the same thing as what the programmer wrote.\nf();\n\njal\n\nf\n\nx = 5;\n\nli\nsw\n\nt0, 5\nt0, x\n\nf(x + 3);\n\nlw\nadd\njal\n\na0, x\na0, a0, 3\nf\n5\n\n\fCorrectness\n\u25cf the goal of an HLL is to provide a solid base of abstractions on which\nyou can build software better than you could do in assembly.\n\u25cf above all, a compiler's number one priority is to produce a correct\ntranslation of the source code.\no if a compiler mistranslates code, you've lost all the supposed\nguarantees that the HLL provides.\n\u25cf bugs in compilers can be incredibly serious.\no a compiler that fails to catch certain mistakes, or which produces\nincorrect code, can produce executables which leave millions of\ncomputers vulnerable to attacks, in the worst cases.\n\u25cf so, what does \"correct\" code look like?\n\n6\n\n\fIt doesn't have to look pretty\n\u25cf think back to 447. I want to do x++ for some global variable x.\n# x++\nlw\nt0, x\naddi t0, t0, 1\nsw\nt0, x\n\nadd_ints:\nadd v0, a0, a1\njr\nra\nmain:\n# x++\nlw\na0, x\nli\na1, 1\njal add_ints\nsw\nv0, x\n\nthese all have the same effect: x's value is\nincremented by 1. so, they are all correct.\nwhat varies between them is the code quality.\n\n# push 1\nli\nt0, 1\naddi sp, sp, -4\nsw\nt0, 0(sp)\n# push x\nlw\nt0, x\naddi sp, sp, -4\nsw\nt0, 0(sp)\n# pop 2, add, push sum\nlw\nt0, 0(sp)\nlw\nt1, 4(sp)\naddi sp, sp, 8\nadd t0, t0, t1\naddi sp, sp, -4\nsw\nt0, 0(sp)\n# pop x\nlw\nt0, 0(sp)\naddi sp, sp, 4\nsw\nt0, x\n\n7\n\n\fOutput code quality\n\u25cf the code our compiler outputs can be measured in a few ways:\no speed: how fast the output code runs\n\u25aa in the same span of time, a fast program can do more useful\nwork than a slow program can.\no size: how many bytes the output code takes up\n\u25aa if e.g. your target is a microcontroller with 4 KiB of ROM\u2026\n\u25aa your output code has to be as small as possible to fit.\n\u25cf despite the last slide, smaller code is not necessarily faster code\u2026\no so compilers often give you the choice of which to optimize for.\no but optimizing code to be faster or smaller is an optional task, and\nis not required for correct output.\n\n8\n\n\fGoals and non-goals\n\u25cf in the old days, the code quality of most compilers was\u2026 lacking.\no much more like the third example on that slide than like the first.\n\u25cf higher code quality requires a more sophisticated backend.\no these algorithms were impractical on the slow computers those\nearly compilers ran on, or literally hadn't been invented yet.\n\u25cf but more complex algorithms means a higher chance of messing\nthem up and making a compiler that produces incorrect code!\n\u25cf so our goal in this class will be to make a correct compiler.\no the code it produces may be big, slow, and ugly, but it's okay for\nteaching purposes.\n\u25cf towards the end we'll start to look at improving code quality\u2026\no but you won't be implementing that. it's some heavy stuff.\n\n9\n\n\fRuntime\n\n10\n\n\fFrom compile-time to runtime\n\u25cf the compiler is just the first part of enforcing the HLL's abstractions.\n\u25cf depending on how well the source language's semantics match the\ntarget's, we can have a little or a lot to do at runtime.\n\nC \u2245\ndynamic dispatch\n\nJava\n\nreflection\n\nclass loading\n\nCPU\n\ngarbage collection\nexceptions\n\n11\n\n\fDoes that mean we need a VM?\n\u25cf well, not necessarily\u2026\n\u25cf there can be many source language features which the target\nlanguage does not support, which can be even small things.\no think about it: does MIPS have an if-else instruction?\n\u25aa no. so those have to be built out of simpler instructions.\n\u25cf if the target language is a CPU, chances are all it can do is:\no move numbers around\no do arithmetic and logical operations on numbers\no choose which steps to go to\no uhhhhhhhhhhhhhhhhhhh that's it!\n\u25cf so there are like, three parts to this?\no the code generation\no the ABI (application binary interface)\no and the runtime library\n12\n\n\fCode generation (codegen)\n\u25cf we saw this: codegen is where each operation in the source\nlanguage is mapped to the target language.\n\nx = y\n\nlw\nsw\n\nf(x)\n\nlw a0, x\njal f\n\nwhile(x != 10)\n\nt0, y\nt0, x\n\n_top:\nlw t0, x\nbeq t0, 10, _end\n13\n\n\fThe ABI\n\u25cf most programs run on computers with operating systems.\no even those that don't, have to interact with the hardware and\nthemselves (e.g. one function calling another).\n\u25cf the Application Binary Interface (ABI) defines several things:\no the target language \u2013 which in our case is a CPU ISA\no the calling convention(s), which dictate how function calls work\no the way values are represented in memory\no how system calls work, for interacting with the OS\no where things are located in memory (stack, heap, globals, etc.)\no how the code is packaged into an executable file\no and much more!\n\n14\n\n\fThe runtime library\n\u25cf also called \"the runtime,\" confusingly\n\u25cf it comes with your language; either statically or dynamically linked\no for real why is 449 not a prereq for this course\n\nStandard\nLibrary (stdlib)\n\nRuntime\n\nthe standard library (stdlib) has a set of\nuseful, but non-critical functionality.\n\nthe runtime library is essential to make\nlanguage features work at run-time.\nin Rust, the runtime is called \"core\",\nand the standard library is \"std\".\n\nin a lot of languages, the line is\u2026 blurrier.\n15\n\n\fPutting it all together\n\u25cf to sum up:\n\nCompiler\n\n(the runtime library might piggy-back on it.)\n\nAST\nBackend\n\nthe backend generates\nmachine code and puts it\nin an executable which\nconforms to the ABI.\n\nRuntime\nLibrary\nExecutable\nProgram\n\nwhen executed, the runtime\nlibrary handles the sourcelanguage features which\ndon't exist on the target.\n\nuhh\u2026 so how is this code\ngenerated, anyway?\n16\n\n\fCodegen\n\n17\n\n\fHow do you eat an elephant?\n\u25cf codegen seems like a giant problem with no easy place to start.\n\u25cf but any problem can be broken down into smaller ones.\na lot of it is filling in templates,\nlike mad libs for code.\nwhile cond {\ncode\n}\n\n_top:\nb__ __, __, _end\ncode\n_end:\n\nother parts are allocation, deciding\nwhat lives where, and when.\n\nVariables\n\nRegisters\n\nx\ni\nret\nnum_cats\n\ns0\ns1\nt0\nt1\n\njust keep in mind that our goal is to\ngenerate correct code, not great code.\n18\n\n\fGetting a flavor of it: codegen for a function\n\u25cf as you (hopefully) learned before, every function gets a stack frame.\no this is where it stores saved registers and local variables.\nthe template for a function's\ncode is something like\u2026\nname:\nset up stack\nfunction body\nclean up stack\nreturn\n\nhow big does the stack\nframe have to be?\nfn main() {\nlet x = 0;\nfor i in 0, 10 {\nx += i;\n}\nlet y = g(x);\nprintln(y);\n}\n\nthe symbol table can tell us how\nmany local variables we have.\n\n19\n\n\fCodegen for expressions\n\u25cf expressions calculate values, and in a CPU values go in registers.\n\u25cf an expression in isolation doesn't really tell you what to do though.\nf(16)\n\nli a0, 16\njal f\n\nreturn 16;\n\nli v0, 16\nj _return\n\nx = 16;\n\nli t0, 16\nsw t0, 4(sp)\nif it's a local, or\u2026\n\nli t0, 16\nsw t0, x\nif it's a global!\n\nthe same expression 16 is\ntranslated into different code\ndepending on how it's used.\nif this seems complicated,\nyeah, it is\nbut we'll come back to this\nand solve it by being lazy!\n20\n\n\fCodegen for statements\n\u25cf lots of statements do control flow, meaning the output code is\ngonna have labels and jumps and branches (ew).\no fortunately, the templates for these are pretty straightforward and\nset in stone \u2013 there's only one real \"right\" way to do an if-else.\n\u25cf sequential statements (like { blocks }) are no problem.\no you just translate each statement one after another, and\nconcatenate the code together. (yes, seriously!)\n\u25cf even nested statements are simple thanks to the AST.\no with the power of recursion, it all works out. trust recursion.\n\u25cf but I think that's enough of an introduction to codegen.\n\u25cf let's assume we have it working. does that mean we now have a\nworking program? are we done with compiler??\no well\u2026\n21\n\n\fLinking and Executables\n\n22\n\n\fAbunchafunctions\n\u25cf a simple program might be one main() function and nothing else.\n\u25cf if we have more functions, we can concatenate their code.\nfn main() {\nf(10);\n}\nfn g(x) {\nprintln(x);\n}\nfn f(x) {\ng(x + 5);\n}\n\n00: li\na0, 10\n04: jal f\n08: li\nv0, 10\n0C: syscall\n10: li\nv0, 1\n14: syscall\n18: jr\nra\n1C: sub sp, sp, 4\n20: sw\nra, 0(sp)\n24: add a0, a0, 5\n28: jal g\n2C: lw\nra, 0(sp)\n30: add sp, sp, 4\n34: jr\nra\n\nwhat addresses should\nthe jals jump to?\nbut when do we know the\naddresses of the functions?\n\nwhat if I define the functions\nin a different order?\nwhat if I call functions\nfrom the stdlib?\n23\n\n\fTrying to do too much at once\n\u25cf really, we're moving past what the compiler should be doing\u2026\na program's call graph can be complex,\nwith cycles, multiple dependencies, etc.\n\nmain\n\nf\ng\n\nprint_list\n\nwe have to serialize this graph when\nconverting it to an executable form.\nthis process is called linking.\n\nrather than the compiler producing a whole program, we have it\nproduce incomplete fragments, and let the linker finish the job.\n\n24\n\n\fSymbolic linking\n\u25cf the dependencies between fragments are indicated symbolically:\n\u25cf instead of referring to them by address, we do it by name.\nmain\nf blah\n\nprintln\n\nprint_list\n\nf\n\ncode g\nmore stuff\n\neach fragment has \"blanks\" to\nindicate what it references.\n\ng\nblah blah\n\nprint_list\nif { }\nelse\nprint_list\n\n;\n\nthe linker serializes the fragments\nand \"fills in the blanks.\"\n\nit can also include fragments from\nother parts of the program or from\nlibraries (like the stdlib).\n\n25\n\n\fRelocations\n\u25cf for a number of reasons, the addresses that your code and data end\nup at may not be known until right before it's executed!\n\u25cf an executable file can have relocations: \"blanks\" where absolute\naddresses are needed, which are filled in at load-time.\nIn the executable\n00: li a0, 10\n04: jal 0\n08: li v0, 10\n0C: syscall\n10: li v0, 1\n14: syscall\n18: jr ra\n\nReloc { addr: 0x0004,\nkind: Jump26,\ntarget: \"g\", }\nSymbol { addr: 0x0010,\nkind: Func,\nname: \"g\", }\n\nAfter loading\n8000: li a0, 10\n8004: jal 0x8010\n8008: li v0, 10\n800C: syscall\n8010: li v0, 1\n8014: syscall\n8018: jr ra\n\nif this code is loaded at address 0x8000\u2026\n26\n\n\fPosition-independent code\n\u25cf compilers often have a flag to output position-independent code,\nwhich uses different instructions to never use absolute addresses.\no this avoids relocations entirely, making things faster to load, and it\navoids duplicating shared libraries in RAM.\n\u25cf to do this, the target ISA must be able to calculate addresses of code\nand data based on the PC (\"PC-relative addressing\"):\nlike a branch-and-link instruction:\n\nbal func\n\nand load/store instructions which\nuse the pc as the base register:\n\nlw t0, 0x38C(pc)\n\n27\n\n\fDebugging info\n\u25cf converting to the target language is a lossy operation.\no a bunch of info about the source program is lost!\n\u25cf to make debugging possible, the compiler can also output info like:\no what source file and line each instruction corresponds to\no the names and locations of functions, globals, and locals\no the types of storage locations\no the structure of custom types (structs/classes)\no the arrangement of stack frames for each function\n\u25cf this way, when you run your program in a debugger, you can:\no step through it line-by-line\no inspect the contents of variables, arrays, etc.\no have the debugger display that stuff in a human-readable way\n\u25cf this info is usually HUGE, so it's optional and typically removed in\n\"release\" versions.\n28\n\n\fExecutable formats\n\u25cf we can't dump a bunch of instructions out and expect them to run.\n\u25cf an executable format is like a seed, or an\u2026\u2026\u2026\u2026. egg\no it has the code and all the metadata needed to support it.\n\u25cf the OS ABIs define these formats, but they basically all look like this:\nheader\n\na header that identifies the type of the file\n\nsymbols\n\na symbol table (names, kinds, addresses)\n\nrelocs\n\nrelocation records\n\n.text\n\nand then multiple sections for things like code\n(.text), globals (.data), constants (.rodata), etc.\n\n.data\n.debug\n\nand optional debug info sections\n29\n\n\fObject files, executables, and libraries\n\u25cf typically this format is used to represent three kinds of files:\n\nhello.exe\n\nobject files: incomplete\npieces which might\ncorrespond to a single\nsource file or module.\nlinking them together\ncan produce\u2026\n\nan executable, which\nhas an entry point\n(the first function to be\nrun when loaded), or\u2026\n\na library (either static\nor dynamically linked),\nwhich\u2026 doesn't have an\nentry point.\nhello.dll\n\ninstead, it exports\nfunctions to be used\nby other files.\n\n30\n\n\fSo what will we do??\n\u25cf well, this is a compilers course, not a linkers course\u2026\n\u25cf rather than output machine code, our compiler will output assembly\nlanguage code. you know, just text.\no see, MARS \u2013 the MIPS emulator \u2013 has a linker built into it.\no so we'll let it \"finish the job\" and do the linking for us.\n\u25cf this might sound like a cop-out, but lots of compilers work this way!\no not just toy compilers. gcc does this, if you ask it to.\n\u25cf many compilers output object files full of machine code so they can\nskip the assembly step and just go straight to linking\u2026\no but that's a compilation speed optimization, not a requirement.\n\n31\n\n\f", "label": [[-2, -1, "Concept"]], "Comments": []}