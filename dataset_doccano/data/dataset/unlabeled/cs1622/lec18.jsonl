{"id": 216, "segment": "unlabeled", "course": "cs1622", "lec": "lec18", "text": "Global Optimization\nCS 1622\nJarrett Billingsley\n\n\fClass Announcements\n\u25cf exam 1 grades were posted on Monday, if you missed that\no if you have questions about it, please ask me in private\n\u25cf don\u2019t forget project 4 is due on Saturday (or late Sunday)!\n\n2\n\n\fFrom Local to Global\n\n3\n\n\fLocal optimization only gets you so far\n\u25cf last time we saw that optimizations like copy propagation and dead\nstore elimination could greatly simplify our code.\nlet x = 5 * 5;\nreturn x;\n\nx = 5 * 5\n$t0 = x\nreturn\n\nx = 25\n$t0 = x\nreturn\n\n$t0 = 25\nreturn\n\nbut local optimizations only work on a single basic block,\nwhich means they have two significant weaknesses:\n1. real functions can have many BBs, and they\nconnect to and affect each other in nontrivial ways.\n2. many of those BBs are short, only a few instructions long,\nmeaning there just isn't much opportunity for optimization.\n4\n\n\fStumbling block\nbasic\n\n\u25cf if we make that code just a little more complex\u2026 (assume a is an argument)\nlet x = 5 * 5;\nif a { f(); }\nreturn x;\n\nbb0: x = 5 * 5\nif a bb1 else bb2\nbb1: f()\ngoto bb2\n\nbb2: $t0 = x\nreturn\n\nwe can still constfold up here\u2026\n\nbut now the\nassignment to $t0\nis in a different BB!\n\nif we want our optimizations to be worthwhile at all, we're\ngoing to have to make them operate on the whole CFG.\nintuitively, the above should be possible to optimize, no?\n5\n\n\fTrying to intuit our way through it\n\u25cf we're going to use the same rules for copy prop/dead stores as\nbefore, but we'll look at all the BBs instead of just one at a time.\nbb0: x = 25\nif a bb1 else bb2\nbb1: f()\ngoto bb2\nbb2: $t0 = x\nreturn\n\nx is only assigned\nonce, so copy its RHS\neverywhere it's used.\n\nbb0: x = 25\nif a bb1 else bb2\nbb1: f()\ngoto bb2\nbb2: $t0 = 25\nreturn\n\nnow x is never\nused, so delete it.\n\nbb0: if a bb1 else bb2\nbb1: f()\ngoto bb2\nbb2: $t0 = 25\nreturn\n\nthat wasn't so\nbad, was it?\n\nwell\u2026\n6\n\n\fIntuit THIS\n\u25cf if x is reassigned, does that always mean we can't propagate?\nbb0: x = 25\nif a bb1 else bb2\nbb1: x = 10\ngoto bb2\nbb2: $t0 = x\nreturn\n\nhere, x has different\nvalues on each path\nto bb2, so we can't\npropagate.\n\nbb0: x = 25\nif a bb1 else bb2\nbb1: x = 10\ngoto bb3\n\nbb2: x = 10\ngoto bb3\n\nbb3: $t0 = x\nreturn\n\nbut here, although x is assigned in\nmultiple places, it has the same value\non both paths to bb3, so\u2026 we can\npropagate it to $t0 = 10???\n7\n\n\fFalse confidence\n\u25cf it only gets worse.\n\nintuitively, we can simplify this whole function\n\nlet x = 0;\nto return 5; but how do you prove that?\nfor i in 0, 10 {\nx = 5;\nx is assigned twice, or maybe 11 times?\nbb0: x = 0\n}\n(do assignments in loops count as \"once\"?)\ni = 0\ngoto bb1\nreturn x;\nbb1: $t1 = i < 10\nif $t1 bb2 else bb3\nbb2: x = 5\ni = i + 1\ngoto bb1\n\nbut the first assignment\nx = 0 is never used\u2026\n\nand the assignment(s) in\nthe loop are redundant\u2026\n(does that mean the whole\nloop can be removed?)\n\nbb3: $t0 = x\nreturn\n8\n\n\fWe need some RIGOR\n\u25cf optimizations are basically proofs.\no if you can prove that a variable is never read, you can remove it.\no if you can prove that a variable only ever holds a constant value,\nyou can replace all uses of it with that constant.\n\u25cf what we need is some kind of framework to build these proofs from.\no many optimizations have the same kind of \"algorithmic shape.\"\no most of them have repeated steps that stem from a common\nunderlying reason.\n\u25cf so let's talk about data flow analysis.\n\n9\n\n\fData Flow Analysis\n\n10\n\n\fComing for a visit (animated)\n\u25cf remember this graph-visiting algorithm?\nthe visited set records which nodes\nfn visit_node(n, visited) {\nif visited[n] { return; }\nhave already been visited, and is\nvisited[n] = true;\nnecessary to prevent infinite loops.\nfor s in n.successors() {\nvisit_node(s, visited);\n}\n\n}\nvisit_node\n\n1\n\nso you can imagine all the nodes\nstarting in an \"unvisited\" set, and\ngradually being moved to visited.\nUnvisited\n\n2\n\n1\n\n2\n\n3\n\n3\n\n4\n\n4\n\nVisited\n\n11\n\n\fWhy does it terminate?\n\u25cf it might seem silly to ask, but termination is crucial to being able to\nspecify optimizations that don't get our compiler stuck in a loop.\n1. every node is in one of a finite number\nof sets. (here, it's one of two sets.)\n4. on every step,\n3. once a node\nwe move at least\nreaches the \"last\"\nUnvisited\nVisited\none node from\nset, we don't look\none set to another.\nat it anymore.\n2. nodes can move from one set to\nanother, but only in one direction.\n\ntherefore, the big-O upper bound on the number\nof steps in the algorithm is the number of nodes\nmultiplied by the number of sets .\nminus one\n\n12\n\n\fA simple control flow optimization\n\u25cf in this function, can we ever run the else code (g())?\nif true {\nf();\n} else {\ng();\n}\n\nno. what does that\nlook like in the CFG?\n\nthis can come up in real code:\n\nthese nodes/edges\nare useless; we can\nremove them.\n\nif\n\nf()\n\ng()\nf()\n\u2026\n\nconst FEATURE_ENABLED = true;\n...\nif FEATURE_ENABLED {\nor, the condition may have\nf();\nbecome a constant due to\n} else {\nother optimizations.\ng();\n}\n\n\u2026\n\n13\n\n\fTweaking the visitor algorithm\n\u25cf we want to detect if a BB is unreachable, meaning it can never run.\n\u25cf we'll modify the visiting algorithm in a simple way to do this.\nfn visit_node(n, visited) {\nif visited[n] { return; }\nvisited[n] = true;\nlet t = n.terminator;\nif t's condition is constant true {\nvisit_node(t.true_side, visited);\n} else if it's constant false {\nvisit_node(t.false_side, visited);\n} else {\nfor s in n.successors() {\nvisit_node(s, visited);\n}\n}\n}\n\nI'm paraphrasing the \"real\ncode\" but the idea is simple:\nif the condition is constant,\nonly recursively visit the BB\nthat corresponds to it.\nat the end of running this,\nany nodes not in the visited\nset are unreachable and can\nbe removed from the CFG.\n14\n\n\fRunning it on this CFG (animated)\n\u25cf we'll mark any visited node with a green circle.\nif true {\nf();\n} else {\ng();\n}\n\nif\nf()\n\ng()\n\n\u2026\n\ndone. now we can see that the\nelse node (g()) was not visited,\nand is therefore not reachable.\n(how we remove it from the CFG is a separate\nissue, but it's not super complicated.)\n\ndo you remember another algorithm that worked like\nthis? you start at a root and mark reachable things,\nthen sweep away anything that isn't reachable\u2026\n;o\n\n15\n\n\fForward analysis\n\u25cf the way this (and most optimizations) works is by transferring some\nkind of \"knowledge\" from BB to BB by following edges.\no here, that knowledge is the reachability of a node.\no when we enter visit_node, we know that n is reachable\u2026\no \u2026and that reachability is transferred to its successors.\n\u25cf a forward analysis spreads this knowledge forward with the edges:\nfrom the predecessors to the successors.\no a backward analysis does the opposite \u2013 from successors to\npredecessors \u2013 but we won't see one of those until next time.\n\u25cf so: let's use this new knowledge to solve the problems we\nencountered before!\n\n16\n\n\fGlobal Constant Copy\nPropagation (GCCP)\n\n17\n\n\fDefs and Uses\n\u25cf a def of a variable is when you assign it (it appears on ='s LHS).\no defs of x: x = 0, x = y\n\u25cf a use of a variable is when you get its value.\no uses of x: z = x, if x, f(x)\n\u25cf we'll use def-use to mean a pair of def and use, where the def sets\nthe value that the use gets.\nx = 3\ny = 5\nz = a + b\nf(x)\nhere's a def-use.\n\nx = 3\n\nx = 5\nf(x)\n\nthere can be multiple\ndefs for one use, too.\n18\n\n\fWhat is Global Constant Copy Propagation?\n\u25cf remember that copy propagation said that if we have an instruction\nof the form \u201dx = y\u201d, and x is never reassigned, then we can replace\nall uses of x with y.\n\u25cf constant copy propagation is the same thing, but only in the cases\nwhere the RHS of \u201dx = y\u201d is a constant.\no and global constant copy propagation is that, but applied to the\nentire CFG instead of just one BB!\n\u25cf for the purposes of this example, we will not be using SSA, so\nvariables can be reassigned.\no essentially SSA makes it so every use has exactly one def, which\nsimplifies some things\u2026\no but the details of SSA are too much for this course, so we\u2019ll stick\nwith non-SSA for these global optimizations.\n19\n\n\fGlobal Constant Copy Propagation\n\u25cf if we are looking at a use of x\u2026\n\u25cf and, every def for that use of x set it to some constant C\u2026\n\u25cf then, we can replace that use of x with that constant C.\nbb0: x = 25\nif a bb1 else bb2\n\nbb0: x = 25\nif a bb1 else bb2\n\nbb1: f()\ngoto bb2\n\nbb1: x = 10\ngoto bb2\n\nbb2: $t0 = x\nreturn\n\nbb2: $t0 = x\nreturn\n\n1 def-use, sets x\nto 25; we can\nreplace x with 25.\n\n2 def-uses; set x\nto different\nvalues; no good.\n\nbb0: x = 25\nif a bb1 else bb2\nbb1: x = 10\ngoto bb3\n\nbb2: x = 10\ngoto bb3\n\nbb3: $t0 = x\nreturn\n\n2 def-uses; both set x\nto same value; we can\nreplace x with 10.\n20\n\n\fFrom the bottom up (animated)\n\u25cf that's cool and all, but how do we start implementing this?\n\u25cf let's start by looking at the instructions within a basic block. we'll\nfocus on the variable x right now.\nbefore this code\nruns, we don't\nknow what's in x.\nbut each line\nchanges what\nwe know.\n\nKnowledge\nx = ???\nx = 4\nx = 4\ny = 5\nx = 4\n\nx = f()\nx = ???\n\nx = 9\nx = 9\n\nthe change in knowledge\nfrom one step to the next\nis formally known as the\ntransfer function.\nso let's be a bit more\nrigorous about this.\n21\n\n\fOur states and transfer function\n\u25cf the \"knowledge\" is properly called the state, and we have two states:\no x = ANY, meaning that x could be one of several values; and\no x = CONST(c), meaning x holds a constant c. (e.g. CONST(7))\n\u25cf each instruction has an in-state and an out-state\u2026\no and the out-state of one instruction is the in-state of the next.\n\u25cf the transfer function takes an instruction and its in-state, and\nproduces its out-state.\n\u25cf the transfer function here is simple:\no if the instruction is of the form x = c for some constant c,\n\u25aa then the out-state is CONST(c).\no else, if the instruction is of the form x = \u2026 for any other RHS,\n\u25aa then the out-state is ANY.\no else, the out-state is the in-state, unmodified.\n22\n\n\fLather, rinse, repeat\n\u25cf we can use this transfer function to compute the out-state for a\nbasic block as a whole, as well.\nx = ANY\nx = CONST(4)\nx = CONST(4)\nx = ANY\nx = CONST(9)\nx = CONST(9)\n\nthere is some in-state for this BB.\nx = 4\ny = 5\nx = f()\nx = 9\ny = g()\ngoto bb7\n\nx = CONST(9)\n\n$t0 = x\nreturn\n\nwe repeatedly apply the transfer\nfunction to the instructions inside\u2026\n\nand that gives us the BB's out-state.\nand as you might imagine, that can\nbecome the in-state for the next BB!\n\u2026but wait, BBs can have\nmultiple predecessors.\n23\n\n\fThe join function\n\u25cf a BB's predecessors may all be feeding different states into it.\n\u25cf the join function combines those states to produce a BB's in-state.\n\u25cf let's look at some examples. the labels are the state for x.\nx = 5\nCONST(5)\n\nx = f()\nANY\n\nso, red's in-state\nmust be x = ANY.\n\nx = 5\nCONST(5)\n\nx = 3\nCONST(3)\n\nstill, red's in-state\nmust be x = ANY.\n\nx = 3\nCONST(3)\n\nx = 3\nCONST(3)\n\nsuccess! red's in-state\nis x = CONST(3).\n\nso: if all the predecessors say CONST(c) for the same constant c,\nthen the in-state is CONST(c); otherwise, it's ANY.\n24\n\n\fLet's try it out!\n\u25cf here are two functions from before. let's annotate the edges with\nthe state for x.\nx = 25\nif a bb1 else bb2\n\nx = 25\nif a bb1 else bb2\n\nCONST(25)\nx = 10\n\nCONST(25)\n\nCONST(25)\nx = 10\n\nCONST(25)\n\nx = 10\n\nCONST(10)\n\n$t0 = x\nCONST(10) return\n\nCONST(10)\n$t0 = x\nreturn\n\nso, red's in-state\nmust be x = ANY.\n\nso, red's in-state is\nx = CONST(10)!\n\nproblem solved!\n............right?\n\n25\n\n\fThe catch\n\u25cf let's try it on this CFG! again, we're annotating the state for x.\nx = 10\ni = 0\n\nwait, there's nothing on this\nedge. then how do we compute\nthe in-state for the orange BB?\n\nand if we try to follow it\nbackwards, we end up back\nat the same orange BB!\n\nCONST(10)\n$t1 = i < 10\nif $t1 bb2 else bb3\n\nprint(\"ha\")\ni = i + 1\n\nIT KEEPS HAPPENING! I TOLD YOU\nABOUT CYCLIC GRAPHS BRO!!\n\n$t0 = x\nreturn\n\n26\n\n\fFixing it\n\n27\n\n\fOh yeah, we forgot a state\n\u25cf we need one more state to indicate that we haven't visited that\ninstruction/BB, UNK for \"unknown.\"\n\u25cf it will be the initial value: every instruction/BB's in-state and outstate will be set to UNK before the algorithm begins.\n\u25cf our transfer function isn't going to have to change, fortunately.\no it implicitly handles UNK in the \"else\" case: unknown in, unknown\nout!\n\u25cf but there's the other function\u2026\n\n28\n\n\fThe new, improved join function\n\u25cf here's where things get a bit weird, but it will all work out.\nif any predecessor says x = ANY,\nthen the output is x = ANY.\n\np1: x = CONST(10)\np2: x = CONST(4)\np3: x = ANY\np4: x = UNK\n\nx = ANY\n\nif all predecessors say x = UNK,\nthen the output is x = UNK.\n\np1: x = UNK\np2: x = UNK\np3: x = UNK\np4: x = UNK\n\nx = UNK\n\nif the predecessors are a mix of\nx = UNK and x = CONST, then\nignore the UNKs, and the output\nis CONST or ANY like before.\n\np1: x = UNK\np2: x = CONST(3)\np3: x = UNK\np4: x = CONST(3)\n\nx = CONST(3)\n\n29\n\n\fLet's watch it go (animated, important, you have to watch this)\n\u25cf if these rules seem strange, wait till you see how it behaves.\n\u25cf notice that x starts off as UNK everywhere.\nguess what: we are visiting this\norange BB a second time!\n\nUNK x = 10\ni = 0\n\nUNK\nCONST(10)\njoin(CONST(10),\njoin(CONST(10),\nCONST(10))\nUNK)\n= CONST(10)\n$t1 = i < 10\nif $t1 bb2 else bb3\n\nCONST(10)\nUNK\n\nbut no more changes occur.\nwe have reached equilibrium:\nthe algorithm is done.\n\nCONST(10)\nUNK\n\nCONST(10)\nUNK\n\nprint(\"ha\")\ni = i + 1\n$t0 = x\nreturn\n30\n\n\fSometimes one visit is not enough\n\u25cf because each visit to a BB might move it from one set (UNK) to\nanother (say, CONST(10))\u2026 and because we have three sets\u2026\no then we may have to visit a BB more than one time!\n\u25cf we're not risking an infinite loop though. why?\n\nCONST\n\nUNK\n\nwe have a finite number of states (3),\nand the transitions between them\nare unidirectional.\nANY\n\nthat's all we need to prove to\nguarantee termination. nice.\n\n31\n\n\fShortcomings (animated)\n\u25cf now let's see what happens when we reassign x in the loop.\nUNK x = 10\ni = 0\n\nUNK\nCONST(10)\njoin(CONST(10),\njoin(CONST(10),\nCONST(20))\nUNK)\n= CONST(10)\n= ANY\n$t1 = i < 10\n\nwhat happened? well, it\nCONST(20)\nUNK\ndetermined that at the start of the\norange BB, x could be 10 or 20. so\nit assumes it's ANY from then on.\n\nthe algorithm doesn't know that this\nloop always runs. it doesn't know\nanything about loops at all!\n\nif $t1 bb2 else bb3\n\nCONST(10)\nUNK\nANY\n\nCONST(10)\nUNK\nANY\n\nx = 20\ni = i + 1\n$t0 = x\nreturn\n\n32\n\n\fIt never hurts to not optimize\n\u25cf the example on the previous slide is an example of the algorithm\nbeing a little cautious.\no yeah, we can see that x = 20 at the return, but that wouldn't be\ntrue if the loop never ran!\no consider a slight modification where the loop upper bound is an\nargument \u2013 in that case, the loop may run 0 times.\n\u25cf what you don't want is for your algorithm to optimize in a situation\nwhere it shouldn't.\no cause that's a broken proof, and you'll get a broken program.\n\u25cf sometimes an optimization pass won't find anything to do.\no that's okay. there's no judgment. it can't know until it tries.\n\u25cf and if it doesn't optimize anything, you'll still have a correct program.\n\n33\n\n\fSumming it up\n\u25cf to recap how dataflow analysis works:\n\njoin(p1, p2, p3)\n\nin-state\n\nthe transfer function\nis repeatedly applied\nto its instructions,\nwhich computes the\nBB's out-state.\n\ninst1\ninst2\ninst3\ninst4\ninst5\ngoto bb2\n\nout-state\n\nstate flows from a BB's\npredecessors into its join\nfunction, which computes\nthe in-state for the BB.\n\nthis is repeated for every\nBB until the in- and outstates reach equilibrium:\nthey stop changing.\n\nas long as there are a finite number of states, and they\nchange monotonically, this algorithm will terminate.\n\n34\n\n\fLiveness\ntime check \u2264 87\n\n35\n\n\fLiveness\n\u25cf a local variable is live if its value will be used in the future.\no this is not its lifetime; liveness can be \u2013 and often is \u2013 shorter!\n\u25cf it lasts from a def until the last use of that def.\n\narg is only used once on the\nfirst line, so it's dead after that.\n\narguments are \"def'ed\" at\nthe start of the function.\narg\nret\n\nfn lifey(arg: int): int {\nlet ret = arg + 10;\n\nret becomes live when we\ndeclare it, and lives until its last\nuse in the return statement.\n\nprintln_i(ret);\nreturn ret;\n\n}\n\nthese lines are the\nlocals' liveness ranges.\n\n36\n\n\fOne local, many ranges\n\u25cf sometimes, a local can be live and dead multiple times!\nx\n\nx is live twice in this code\u2026\nwith a sort of \"dead zone\" in between.\nthis seems weird, but it's telling us\nsomething useful: x is behaving like\ntwo different variables in this code.\n\nlet x = 10;\nprintln_i(x);\nprintln_s(\"?\");\n\nx = 20;\nprintln_i(x);\n\n(remember SSA? this feels like a step towards it\u2026)\n\nliveness is the basis for a lot of other optimizations (and error\nchecking!), and we'll see other examples along the way.\n37\n\n\fTwo perspectives\n\ni\nobj\n\nnow we can answer:\nat any point in this\nfunction, which\nvariables are live?\n\nfound\nn\nval\nl\n\n\u25cf we already saw that we can view liveness as a set of ranges of\ninstructions (and basic blocks) during which a variable is live.\n\u25cf but another view becomes useful when you have multiple variables.\n\nthis is very relevant to\nregister allocation, since\nwe're trying to map these\nvariables onto the limited\nCPU registers.\n\nfn has(l: List, val: int): bool {\nlet n = l.length();\nlet found = false;\nfor i in 0, n {\nlet obj = l.get(i);\nif obj.value() == val {\nfound = true;\n}\n}\nreturn found;\n}\n38\n\n\fTrying (and failing) to determine liveness\n\u25cf below, the O and X say whether x is alive O or dead X.\no the state is tracked between instructions, hence the misalignment.\nlet's assume by default that it's dead.\nthis def seems to make x live.\nhere's a use of x. but is x used again after this?\nlet's assume it'll be used again\u2026\n\nx = 5\n\nprintln_i(x)\ny = 10\n\nprintln_i(y)\n\nanother use. let's keep assuming.\n\nz = x == y\nprintln_b(z)\n\nuh oh. it's the end. clearly, x's last use\nwas in x == y. so this is wrong\u2026\n\n39\n\n\f", "label": [[-2, -1, "Concept"]], "Comments": []}