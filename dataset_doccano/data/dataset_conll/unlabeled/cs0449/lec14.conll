unlabeled|cs0449|lec14
-DOCSTART- -X- -X- O

14 _ _ O
The _ _ O
Memory _ _ O
Hierarchy _ _ O
CS _ _ O
/ _ _ O
COE _ _ O
0449 _ _ O
Introduction _ _ O
to _ _ O
Systems _ _ O
Software _ _ O
Luis _ _ O
Oliveira _ _ O
( _ _ O
with _ _ O
content _ _ O
borrowed _ _ O
from _ _ O
wilkie _ _ O
and _ _ O
Vinicius _ _ O
Petrucci _ _ O
) _ _ O

This _ _ O
is _ _ O
a _ _ O
Pyramid _ _ O
Scheme _ _ O
But _ _ O
this _ _ O
knowledge _ _ O
is _ _ O
a _ _ O
safe _ _ O
investment _ _ O
. _ _ O
2 _ _ O

Wanting _ _ O
Moore _ _ O
and _ _ O
Moore _ _ O
Processors _ _ O
and _ _ O
memory _ _ O
work _ _ O
together _ _ O
but _ _ O
improve _ _ O
at _ _ O
different _ _ O
rates _ _ O
. _ _ O
Memory _ _ O
was _ _ O
initially _ _ O
faster _ _ O
than _ _ O
CPU _ _ O
, _ _ O
but _ _ O
its _ _ O
innovation _ _ O
was _ _ O
slower _ _ O
. _ _ O
Throughput _ _ O
Innovation _ _ O
starts _ _ O
to _ _ O
slow _ _ O
The _ _ O
CPU _ _ O
overtakes _ _ O
memory _ _ O
performance _ _ O
3 _ _ O

Cost _ _ O
of _ _ O
DRAM _ _ O
/ _ _ O
Disk _ _ O
in _ _ O
2020 _ _ O
• _ _ O
8GiB _ _ O
$ _ _ O
35 _ _ O
- _ _ O
70 _ _ O
• _ _ O
1TiB _ _ O
$ _ _ O
50 _ _ O
– _ _ O
80 _ _ O
• _ _ O
16GiB _ _ O
$ _ _ O
70 _ _ O
- _ _ O
100 _ _ O
• _ _ O
8TiB _ _ O
$ _ _ O
200 _ _ O
- _ _ O
$ _ _ O
300 _ _ O
• _ _ O
32GiB _ _ O
$ _ _ O
140 _ _ O
- _ _ O
300 _ _ O
• _ _ O
16TiB _ _ O
$ _ _ O
400 _ _ O
- _ _ O
500 _ _ O
4 _ _ O

The _ _ O
memory _ _ O
hierarchy _ _ O
Registers _ _ O
Faster _ _ O
, _ _ O
Denser _ _ O
Expensive _ _ O
L1 _ _ O
Cache _ _ O
Cheaper _ _ O
, _ _ O
Slower _ _ O
, _ _ O
Larger _ _ O
( _ _ O
DRAM _ _ O
) _ _ O
Main _ _ O
Memory _ _ O
L2 _ _ O
Cache _ _ O
Local _ _ O
Disk _ _ O
Distributed _ _ O
Storage _ _ O
( _ _ O
Do _ _ O
n’t _ _ O
forget _ _ O
it _ _ O
! _ _ O
) _ _ O
Tape _ _ O
5 _ _ O

The _ _ O
hierarchy _ _ O
of _ _ O
speed _ _ O
Faster _ _ O
, _ _ O
Denser _ _ O
Expensive _ _ O
Cheaper _ _ O
, _ _ O
Slower _ _ O
, _ _ O
Larger _ _ O
A _ _ O
“ _ _ O
cache _ _ O
” _ _ O
is _ _ O
used _ _ O
to _ _ O
hold _ _ O
useful _ _ O
data _ _ O
closer _ _ O
than _ _ O
main _ _ O
memory _ _ O
to _ _ O
improve _ _ O
speed _ _ O
. _ _ O
Registers _ _ O
L1 _ _ O
Cache _ _ O
L2 _ _ O
Cache _ _ O
DRAM _ _ O
is _ _ O
simply _ _ O
too _ _ O
slow _ _ O
( _ _ O
DRAM _ _ O
) _ _ O
Main _ _ O
Memory _ _ O
Local _ _ O
Disk _ _ O
Distributed _ _ O
Storage _ _ O
( _ _ O
Do _ _ O
n’t _ _ O
forget _ _ O
it _ _ O
! _ _ O
) _ _ O
Tape _ _ O
6 _ _ O

Memory _ _ O
Hierarchy _ _ O
: _ _ O
Core _ _ O
2 _ _ O
Duo _ _ O
Not _ _ O
drawn _ _ O
to _ _ O
scale _ _ O
SRAM _ _ O
DRAM _ _ O
Static _ _ O
Random _ _ O
Access _ _ O
Memory _ _ O
Dynamic _ _ O
Random _ _ O
Access _ _ O
Memory _ _ O
~4 _ _ O
MB _ _ O
L2 _ _ O
unified _ _ O
cache _ _ O
L1 _ _ O
I-cache _ _ O
~8 _ _ O
GB _ _ O
~500 _ _ O
GB _ _ O
Main _ _ O
Memory _ _ O
Disk _ _ O
32 _ _ O
KB _ _ O
CPU _ _ O
Reg _ _ O
Throughput _ _ O
: _ _ O
16 _ _ O
B _ _ O
/ _ _ O
cycle _ _ O
Latency _ _ O
: _ _ O
3 _ _ O
cycles _ _ O
L1 _ _ O
D-cache _ _ O
8 _ _ O
B _ _ O
/ _ _ O
cycle _ _ O
2 _ _ O
B _ _ O
/ _ _ O
cycle _ _ O
1 _ _ O
B _ _ O
/ _ _ O
30 _ _ O
cycles _ _ O
14 _ _ O
cycles _ _ O
100 _ _ O
cycles _ _ O
millions _ _ O
Miss _ _ O
Penalty _ _ O
( _ _ O
latency _ _ O
) _ _ O
33x _ _ O
Miss _ _ O
Penalty _ _ O
( _ _ O
latency _ _ O
) _ _ O
10 _ _ O
, _ _ O
000x _ _ O

Memory _ _ O
Caching _ _ O
Cache _ _ O
: _ _ O
Another _ _ O
thing _ _ O
us _ _ O
teachers _ _ O
could _ _ O
really _ _ O
use _ _ O
more _ _ O
of _ _ O
. _ _ O
8 _ _ O

Experiment _ _ O
: _ _ O
Scientific _ _ O
Maths _ _ O
Spring _ _ O
2019 _ _ O
/ _ _ O
2020 _ _ O
9 _ _ O

Practical _ _ O
Performance _ _ O
• _ _ O
Caching _ _ O
is _ _ O
necessary _ _ O
for _ _ O
the _ _ O
utility _ _ O
of _ _ O
computers _ _ O
. _ _ O
▪ _ _ O
The _ _ O
CPU _ _ O
/ _ _ O
Memory _ _ O
gap _ _ O
increases _ _ O
( _ _ O
The _ _ O
Memory _ _ O
Wall _ _ O
) _ _ O
• _ _ O
In _ _ O
order _ _ O
to _ _ O
actually _ _ O
use _ _ O
these _ _ O
fast _ _ O
CPUs _ _ O
, _ _ O
we _ _ O
need _ _ O
to _ _ O
improve _ _ O
the _ _ O
apparent _ _ O
speed _ _ O
of _ _ O
RAM _ _ O
. _ _ O
“ _ _ O
That _ _ O
’s _ _ O
a _ _ O
nice _ _ O
CPU _ _ O
you _ _ O
have _ _ O
there _ _ O
… _ _ O
it _ _ O
’d _ _ O
be _ _ O
terrible _ _ O
if _ _ O
something _ _ O
were _ _ O
to _ _ O
happen _ _ O
to _ _ O
it _ _ O
. _ _ O
” _ _ O
▪ _ _ O
Programs _ _ O
use _ _ O
memory _ _ O
a _ _ O
whole _ _ O
lot _ _ O
. _ _ O
▪ _ _ O
The _ _ O
bottleneck _ _ O
would _ _ O
grind _ _ O
performance _ _ O
to _ _ O
the _ _ O
point _ _ O
where _ _ O
CPUs _ _ O
can _ _ O
not _ _ O
improve _ _ O
. _ _ O
10 _ _ O

The _ _ O
problem _ _ O
: _ _ O
data _ _ O
is _ _ O
faaaaar _ _ O
away _ _ O
• _ _ O
Let _ _ O
’s _ _ O
say _ _ O
you _ _ O
want _ _ O
to _ _ O
read _ _ O
a _ _ O
book _ _ O
. _ _ O
• _ _ O
You _ _ O
check _ _ O
it _ _ O
out _ _ O
of _ _ O
the _ _ O
library _ _ O
. _ _ O
▪ _ _ O
You _ _ O
have _ _ O
to _ _ O
go _ _ O
there _ _ O
. _ _ O
▪ _ _ O
Find _ _ O
the _ _ O
book _ _ O
. _ _ O
▪ _ _ O
Maybe _ _ O
take _ _ O
the _ _ O
bus _ _ O
back _ _ O
. _ _ O
• _ _ O
Wait _ _ O
in _ _ O
traffic _ _ O
. _ _ O
• _ _ O
Now _ _ O
it _ _ O
sits _ _ O
on _ _ O
your _ _ O
desk _ _ O
. _ _ O
▪ _ _ O
As _ _ O
long _ _ O
as _ _ O
it _ _ O
is _ _ O
near _ _ O
you _ _ O
, _ _ O
it _ _ O
’s _ _ O
easy _ _ O
to _ _ O
access _ _ O
the _ _ O
information _ _ O
. _ _ O
▪ _ _ O
Yet _ _ O
, _ _ O
if _ _ O
you _ _ O
need _ _ O
another _ _ O
book _ _ O
… _ _ O
• _ _ O
You _ _ O
would _ _ O
take _ _ O
the _ _ O
book _ _ O
ALL _ _ O
THE _ _ O
WAY _ _ O
back _ _ O
! _ _ O
( _ _ O
bare _ _ O
with _ _ O
me _ _ O
) _ _ O
11 _ _ O

Caching _ _ O
: _ _ O
Keeping _ _ O
things _ _ O
close _ _ O
• _ _ O
Let _ _ O
’s _ _ O
say _ _ O
you _ _ O
want _ _ O
to _ _ O
read _ _ O
a _ _ O
book _ _ O
. _ _ O
▪ _ _ O
It _ _ O
’s _ _ O
not _ _ O
on _ _ O
your _ _ O
bookshelf _ _ O
. _ _ O
• _ _ O
So _ _ O
, _ _ O
still _ _ O
have _ _ O
to _ _ O
check _ _ O
it _ _ O
out _ _ O
of _ _ O
the _ _ O
library _ _ O
. _ _ O
▪ _ _ O
You _ _ O
got _ _ O
ta _ _ O
go _ _ O
there _ _ O
. _ _ O
Find _ _ O
the _ _ O
book _ _ O
. _ _ O
Etc _ _ O
. _ _ O
▪ _ _ O
Take _ _ O
the _ _ O
bus _ _ O
back _ _ O
. _ _ O
• _ _ O
Now _ _ O
it _ _ O
sits _ _ O
on _ _ O
your _ _ O
desk _ _ O
. _ _ O
▪ _ _ O
As _ _ O
long _ _ O
as _ _ O
it _ _ O
is _ _ O
near _ _ O
you _ _ O
, _ _ O
it _ _ O
is _ _ O
easy _ _ O
to _ _ O
access _ _ O
the _ _ O
information _ _ O
. _ _ O
▪ _ _ O
When _ _ O
we _ _ O
need _ _ O
another _ _ O
book _ _ O
… _ _ O
we _ _ O
put _ _ O
it _ _ O
aside _ _ O
. _ _ O
• _ _ O
Maybe _ _ O
a _ _ O
bookshelf _ _ O
. _ _ O
▪ _ _ O
The _ _ O
next _ _ O
time _ _ O
we _ _ O
need _ _ O
it _ _ O
, _ _ O
it _ _ O
will _ _ O
be _ _ O
nearby _ _ O
. _ _ O
12 _ _ O

The _ _ O
metaphorical _ _ O
cache _ _ O
• _ _ O
The _ _ O
bookshelf _ _ O
is _ _ O
a _ _ O
cache _ _ O
. _ _ O
▪ _ _ O
It _ _ O
holds _ _ O
information _ _ O
that _ _ O
you _ _ O
might _ _ O
want _ _ O
later _ _ O
. _ _ O
• _ _ O
It _ _ O
is _ _ O
[ _ _ O
much _ _ O
] _ _ O
smaller _ _ O
than _ _ O
a _ _ O
library _ _ O
, _ _ O
but _ _ O
faster _ _ O
to _ _ O
retrieve _ _ O
things _ _ O
. _ _ O
• _ _ O
However _ _ O
, _ _ O
it _ _ O
is _ _ O
small _ _ O
. _ _ O
Placing _ _ O
a _ _ O
new _ _ O
book _ _ O
on _ _ O
the _ _ O
shelf _ _ O
may _ _ O
require _ _ O
taking _ _ O
an _ _ O
old _ _ O
book _ _ O
off _ _ O
. _ _ O
13 _ _ O

Memory _ _ O
cache _ _ O
( _ _ O
CPU _ _ O
) _ _ O
• _ _ O
RAM _ _ O
is _ _ O
the _ _ O
library _ _ O
. _ _ O
It _ _ O
is _ _ O
far _ _ O
away _ _ O
and _ _ O
getting _ _ O
stuff _ _ O
from _ _ O
there _ _ O
is _ _ O
slow _ _ O
. _ _ O
• _ _ O
To _ _ O
better _ _ O
handle _ _ O
the _ _ O
performance _ _ O
gap _ _ O
between _ _ O
the _ _ O
CPU _ _ O
and _ _ O
memory _ _ O
we _ _ O
add _ _ O
a _ _ O
smaller _ _ O
, _ _ O
fast _ _ O
memory _ _ O
near _ _ O
the _ _ O
CPU _ _ O
. _ _ O
• _ _ O
This _ _ O
is _ _ O
the _ _ O
CPU _ _ O
cache _ _ O
. _ _ O
14 _ _ O

Data _ _ O
, _ _ O
the _ _ O
journey _ _ O
• _ _ O
When _ _ O
data _ _ O
is _ _ O
requested _ _ O
, _ _ O
the _ _ O
goal _ _ O
is _ _ O
to _ _ O
read _ _ O
a _ _ O
word _ _ O
into _ _ O
a _ _ O
CPU _ _ O
register _ _ O
. _ _ O
• _ _ O
The _ _ O
CPU _ _ O
first _ _ O
contacts _ _ O
the _ _ O
cache _ _ O
and _ _ O
asks _ _ O
if _ _ O
it _ _ O
has _ _ O
a _ _ O
copy _ _ O
. _ _ O
▪ _ _ O
If _ _ O
it _ _ O
does _ _ O
… _ _ O
that _ _ O
is _ _ O
a _ _ O
cache _ _ O
hit _ _ O
, _ _ O
and _ _ O
, _ _ O
well _ _ O
, _ _ O
that _ _ O
was _ _ O
easy _ _ O
. _ _ O
Just _ _ O
copy _ _ O
that _ _ O
value _ _ O
into _ _ O
the _ _ O
register _ _ O
. _ _ O
• _ _ O
If _ _ O
it _ _ O
does _ _ O
not _ _ O
, _ _ O
this _ _ O
is _ _ O
a _ _ O
cache _ _ O
miss _ _ O
. _ _ O
▪ _ _ O
It _ _ O
will _ _ O
then _ _ O
contact _ _ O
the _ _ O
next _ _ O
component _ _ O
in _ _ O
the _ _ O
memory _ _ O
hierarchy _ _ O
. _ _ O
( _ _ O
RAM _ _ O
) _ _ O
• _ _ O
Ram _ _ O
copies _ _ O
the _ _ O
value _ _ O
to _ _ O
cache _ _ O
, _ _ O
and _ _ O
the _ _ O
cache _ _ O
copies _ _ O
the _ _ O
value _ _ O
to _ _ O
the _ _ O
register _ _ O
. _ _ O
15 _ _ O

Missing _ _ O
the _ _ O
mark _ _ O
• _ _ O
When _ _ O
the _ _ O
CPU _ _ O
requests _ _ O
memory _ _ O
in _ _ O
an _ _ O
empty _ _ O
cache _ _ O
, _ _ O
the _ _ O
data _ _ O
obviously _ _ O
wo _ _ O
n’t _ _ O
be _ _ O
available _ _ O
locally _ _ O
. _ _ O
• _ _ O
This _ _ O
is _ _ O
a _ _ O
compulsory _ _ O
miss _ _ O
, _ _ O
a _ _ O
“ _ _ O
miss _ _ O
” _ _ O
due _ _ O
to _ _ O
the _ _ O
first _ _ O
access _ _ O
of _ _ O
a _ _ O
block _ _ O
of _ _ O
data _ _ O
. _ _ O
▪ _ _ O
Also _ _ O
known _ _ O
as _ _ O
a _ _ O
“ _ _ O
cold _ _ O
miss _ _ O
. _ _ O
” _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
4 _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
8 _ _ O
9 _ _ O
A _ _ O
B _ _ O
C _ _ O
D _ _ O
E _ _ O
8 _ _ O
• _ _ O
These _ _ O
are _ _ O
, _ _ O
as _ _ O
they _ _ O
suggest _ _ O
, _ _ O
completely _ _ O
unavoidable _ _ O
. _ _ O
▪ _ _ O
They _ _ O
always _ _ O
incur _ _ O
the _ _ O
high _ _ O
penalty _ _ O
associated _ _ O
with _ _ O
a _ _ O
memory _ _ O
read _ _ O
. _ _ O
8 _ _ O
16 _ _ O

Hitting _ _ O
the _ _ O
target _ _ O
• _ _ O
When _ _ O
the _ _ O
CPU _ _ O
requests _ _ O
memory _ _ O
that _ _ O
happens _ _ O
to _ _ O
already _ _ O
be _ _ O
in _ _ O
the _ _ O
cache _ _ O
, _ _ O
the _ _ O
data _ _ O
is _ _ O
read _ _ O
locally _ _ O
( _ _ O
quickly _ _ O
) _ _ O
. _ _ O
• _ _ O
This _ _ O
is _ _ O
a _ _ O
cache _ _ O
hit _ _ O
. _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
4 _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
8 _ _ O
9 _ _ O
A _ _ O
B _ _ O
C _ _ O
D _ _ O
E _ _ O
▪ _ _ O
Your _ _ O
best-case _ _ O
scenario _ _ O
. _ _ O
• _ _ O
These _ _ O
avoid _ _ O
having _ _ O
to _ _ O
communicate _ _ O
at _ _ O
all _ _ O
with _ _ O
memory _ _ O
. _ _ O
▪ _ _ O
No _ _ O
penalty _ _ O
taken _ _ O
for _ _ O
reading _ _ O
/ _ _ O
writing _ _ O
to _ _ O
memory _ _ O
. _ _ O
▪ _ _ O
Very _ _ O
cheap _ _ O
in _ _ O
terms _ _ O
of _ _ O
time _ _ O
. _ _ O
8 _ _ O
8 _ _ O
17 _ _ O

A _ _ O
cache _ _ O
half _ _ O
full _ _ O
… _ _ O
• _ _ O
As _ _ O
the _ _ O
CPU _ _ O
requests _ _ O
memory _ _ O
, _ _ O
the _ _ O
cache _ _ O
will _ _ O
fill _ _ O
to _ _ O
satisfy _ _ O
each _ _ O
compulsory _ _ O
miss _ _ O
. _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
4 _ _ O
• _ _ O
When _ _ O
it _ _ O
fills _ _ O
up _ _ O
completely _ _ O
, _ _ O
it _ _ O
will _ _ O
have _ _ O
no _ _ O
further _ _ O
room _ _ O
for _ _ O
the _ _ O
next _ _ O
miss _ _ O
. _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
8 _ _ O
9 _ _ O
A _ _ O
B _ _ O
C _ _ O
D _ _ O
E _ _ O
• _ _ O
On _ _ O
a _ _ O
miss _ _ O
, _ _ O
it _ _ O
requests _ _ O
the _ _ O
data _ _ O
from _ _ O
memory _ _ O
. _ _ O
4 _ _ O
6 _ _ O
C _ _ O
1 _ _ O
8 _ _ O
E _ _ O
▪ _ _ O
Yet _ _ O
, _ _ O
where _ _ O
does _ _ O
it _ _ O
go _ _ O
? _ _ O
? _ _ O
We _ _ O
must _ _ O
remove _ _ O
one _ _ O
. _ _ O
• _ _ O
This _ _ O
is _ _ O
a _ _ O
capacity _ _ O
miss _ _ O
. _ _ O
The _ _ O
memory _ _ O
requirements _ _ O
of _ _ O
the _ _ O
program _ _ O
are _ _ O
larger _ _ O
than _ _ O
the _ _ O
cache _ _ O
. _ _ O
8 _ _ O
18 _ _ O

Looking _ _ O
closer _ _ O
… _ _ O
• _ _ O
It _ _ O
is _ _ O
difficult _ _ O
to _ _ O
know _ _ O
what _ _ O
block _ _ O
of _ _ O
data _ _ O
to _ _ O
omit _ _ O
from _ _ O
this _ _ O
cache _ _ O
on _ _ O
such _ _ O
a _ _ O
miss _ _ O
. _ _ O
▪ _ _ O
However _ _ O
we _ _ O
can _ _ O
exploit _ _ O
the _ _ O
common _ _ O
locality _ _ O
patterns _ _ O
of _ _ O
programs _ _ O
to _ _ O
improve _ _ O
our _ _ O
cache _ _ O
. _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
4 _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
8 _ _ O
9 _ _ O
• _ _ O
There _ _ O
is _ _ O
temporal _ _ O
locality _ _ O
: _ _ O
accessed _ _ O
data _ _ O
is _ _ O
likely _ _ O
to _ _ O
be _ _ O
used _ _ O
again _ _ O
in _ _ O
near _ _ O
future _ _ O
. _ _ O
A _ _ O
B _ _ O
C _ _ O
D _ _ O
E _ _ O
4 _ _ O
6 _ _ O
C _ _ O
1 _ _ O
8 _ _ O
▪ _ _ O
This _ _ O
is _ _ O
what _ _ O
caches _ _ O
generally _ _ O
capture _ _ O
. _ _ O
• _ _ O
However _ _ O
, _ _ O
spatial _ _ O
locality _ _ O
is _ _ O
also _ _ O
likely _ _ O
: _ _ O
data _ _ O
is _ _ O
often _ _ O
grouped _ _ O
together _ _ O
. _ _ O
▪ _ _ O
When _ _ O
we _ _ O
access _ _ O
a _ _ O
struct _ _ O
field _ _ O
, _ _ O
we _ _ O
will _ _ O
often _ _ O
access _ _ O
another _ _ O
which _ _ O
is _ _ O
nearby _ _ O
in _ _ O
memory _ _ O
. _ _ O
8 _ _ O
19 _ _ O

Exploring _ _ O
space _ _ O
… _ _ O
• _ _ O
We _ _ O
would _ _ O
like _ _ O
to _ _ O
keep _ _ O
data _ _ O
that _ _ O
is _ _ O
adjacent _ _ O
in _ _ O
memory _ _ O
in _ _ O
the _ _ O
cache _ _ O
, _ _ O
together _ _ O
, _ _ O
at _ _ O
the _ _ O
same _ _ O
time _ _ O
. _ _ O
• _ _ O
To _ _ O
do _ _ O
this _ _ O
, _ _ O
we _ _ O
“ _ _ O
hash _ _ O
” _ _ O
the _ _ O
address _ _ O
. _ _ O
This _ _ O
is _ _ O
used _ _ O
to _ _ O
determine _ _ O
the _ _ O
cache _ _ O
slot _ _ O
. _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
4 _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
8 _ _ O
9 _ _ O
A _ _ O
B _ _ O
C _ _ O
D _ _ O
E _ _ O
▪ _ _ O
Just _ _ O
a _ _ O
fancy _ _ O
way _ _ O
to _ _ O
say _ _ O
: _ _ O
we _ _ O
divide _ _ O
the _ _ O
address _ _ O
by _ _ O
the _ _ O
cache _ _ O
size _ _ O
and _ _ O
use _ _ O
the _ _ O
remainder _ _ O
. _ _ O
• _ _ O
Every _ _ O
0th _ _ O
block _ _ O
, _ _ O
1st _ _ O
block _ _ O
, _ _ O
2nd _ _ O
block _ _ O
, _ _ O
etc _ _ O
. _ _ O
• _ _ O
The _ _ O
5th _ _ O
block _ _ O
( _ _ O
in _ _ O
this _ _ O
example _ _ O
) _ _ O
goes _ _ O
to _ _ O
the _ _ O
slot _ _ O
, _ _ O
the _ _ O
6th _ _ O
goes _ _ O
to _ _ O
the _ _ O
slot _ _ O
, _ _ O
and _ _ O
so _ _ O
on _ _ O
. _ _ O
8 _ _ O
20 _ _ O

Direct _ _ O
and _ _ O
to _ _ O
the _ _ O
point _ _ O
… _ _ O
• _ _ O
Let _ _ O
’s _ _ O
read _ _ O
addresses _ _ O
3 _ _ O
, _ _ O
4 _ _ O
, _ _ O
5 _ _ O
, _ _ O
6 _ _ O
, _ _ O
and _ _ O
7 _ _ O
( _ _ O
in _ _ O
that _ _ O
order _ _ O
) _ _ O
from _ _ O
memory _ _ O
. _ _ O
• _ _ O
Reading _ _ O
address _ _ O
8 _ _ O
next _ _ O
incurs _ _ O
a _ _ O
capacity _ _ O
miss _ _ O
, _ _ O
but _ _ O
it _ _ O
evicts _ _ O
the _ _ O
address _ _ O
that _ _ O
is _ _ O
furthest _ _ O
away _ _ O
from _ _ O
the _ _ O
others _ _ O
. _ _ O
▪ _ _ O
This _ _ O
type _ _ O
of _ _ O
cache _ _ O
is _ _ O
good _ _ O
for _ _ O
programs _ _ O
that _ _ O
read _ _ O
through _ _ O
data _ _ O
sequentially _ _ O
. _ _ O
▪ _ _ O
That _ _ O
is _ _ O
because _ _ O
such _ _ O
programs _ _ O
will _ _ O
always _ _ O
remove _ _ O
the _ _ O
least _ _ O
recently _ _ O
used _ _ O
block _ _ O
on _ _ O
a _ _ O
miss _ _ O
, _ _ O
as _ _ O
shown _ _ O
here _ _ O
. _ _ O
• _ _ O
Because _ _ O
every _ _ O
address _ _ O
has _ _ O
a _ _ O
specific _ _ O
cache _ _ O
slot _ _ O
, _ _ O
this _ _ O
is _ _ O
called _ _ O
a _ _ O
direct-mapped _ _ O
cache _ _ O
. _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
4 _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
8 _ _ O
9 _ _ O
A _ _ O
B _ _ O
C _ _ O
D _ _ O
E _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
3 _ _ O
8 _ _ O
4 _ _ O
8 _ _ O
21 _ _ O

Missing _ _ O
your _ _ O
connection _ _ O
… _ _ O
• _ _ O
Let _ _ O
’s _ _ O
consider _ _ O
an _ _ O
antagonist _ _ O
pattern _ _ O
. _ _ O
▪ _ _ O
What _ _ O
is _ _ O
the _ _ O
worst _ _ O
case _ _ O
for _ _ O
this _ _ O
cache _ _ O
? _ _ O
• _ _ O
If _ _ O
we _ _ O
read _ _ O
every _ _ O
5th _ _ O
address _ _ O
in _ _ O
our _ _ O
memory _ _ O
in _ _ O
order _ _ O
, _ _ O
we _ _ O
would _ _ O
overwhelm _ _ O
our _ _ O
directmapped _ _ O
cache _ _ O
. _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
4 _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
8 _ _ O
9 _ _ O
A _ _ O
B _ _ O
C _ _ O
D _ _ O
E _ _ O
▪ _ _ O
Let _ _ O
’s _ _ O
access _ _ O
0 _ _ O
, _ _ O
5 _ _ O
, _ _ O
A _ _ O
in _ _ O
that _ _ O
order _ _ O
. _ _ O
• _ _ O
Accessing _ _ O
address _ _ O
0 _ _ O
is _ _ O
a _ _ O
compulsory _ _ O
miss _ _ O
. _ _ O
A _ _ O
5 _ _ O
0 _ _ O
▪ _ _ O
Address _ _ O
5 _ _ O
, _ _ O
however _ _ O
, _ _ O
is _ _ O
a _ _ O
miss _ _ O
. _ _ O
▪ _ _ O
But _ _ O
our _ _ O
cache _ _ O
is _ _ O
n’t _ _ O
full _ _ O
! _ _ O
! _ _ O
• _ _ O
A _ _ O
miss _ _ O
that _ _ O
occurs _ _ O
even _ _ O
though _ _ O
your _ _ O
cache _ _ O
could _ _ O
fit _ _ O
the _ _ O
block _ _ O
is _ _ O
called _ _ O
a _ _ O
conflict _ _ O
miss _ _ O
. _ _ O
A _ _ O
22 _ _ O

How _ _ O
big _ _ O
is _ _ O
that _ _ O
block _ _ O
? _ _ O
• _ _ O
Spatial _ _ O
locality _ _ O
is _ _ O
SO _ _ O
prevalent _ _ O
that _ _ O
it _ _ O
makes _ _ O
a _ _ O
whole _ _ O
lot _ _ O
of _ _ O
sense _ _ O
to _ _ O
pull _ _ O
more _ _ O
data _ _ O
than _ _ O
is _ _ O
requested _ _ O
. _ _ O
▪ _ _ O
If _ _ O
we _ _ O
request _ _ O
a _ _ O
word _ _ O
( _ _ O
8 _ _ O
bytes _ _ O
) _ _ O
from _ _ O
memory _ _ O
, _ _ O
and _ _ O
we _ _ O
have _ _ O
a _ _ O
cache _ _ O
miss _ _ O
, _ _ O
let _ _ O
’s _ _ O
pull _ _ O
8 _ _ O
words _ _ O
at _ _ O
a _ _ O
time _ _ O
( _ _ O
64 _ _ O
bytes _ _ O
) _ _ O
. _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
4 _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
8 _ _ O
9 _ _ O
A _ _ O
B _ _ O
C _ _ O
D _ _ O
E _ _ O
64 _ _ O
bytes _ _ O
• _ _ O
Therefore _ _ O
, _ _ O
the _ _ O
blocks _ _ O
visualized _ _ O
to _ _ O
the _ _ O
right _ _ O
can _ _ O
have _ _ O
a _ _ O
size _ _ O
, _ _ O
called _ _ O
the _ _ O
block _ _ O
size _ _ O
. _ _ O
▪ _ _ O
The _ _ O
bigger _ _ O
the _ _ O
block _ _ O
, _ _ O
the _ _ O
better _ _ O
spatial _ _ O
locality _ _ O
will _ _ O
become _ _ O
. _ _ O
▪ _ _ O
However _ _ O
, _ _ O
the _ _ O
more _ _ O
time _ _ O
it _ _ O
takes _ _ O
to _ _ O
copy _ _ O
from _ _ O
memory _ _ O
and _ _ O
the _ _ O
higher _ _ O
penalty _ _ O
if _ _ O
you _ _ O
throw _ _ O
it _ _ O
away _ _ O
on _ _ O
a _ _ O
miss _ _ O
! _ _ O
8 _ _ O
bytes _ _ O
23 _ _ O

Block _ _ O
size _ _ O
helps _ _ O
locality _ _ O
• _ _ O
When _ _ O
we _ _ O
request _ _ O
an _ _ O
address _ _ O
from _ _ O
our _ _ O
cache _ _ O
, _ _ O
we _ _ O
are _ _ O
requesting _ _ O
the _ _ O
block _ _ O
that _ _ O
contains _ _ O
that _ _ O
address _ _ O
. _ _ O
▪ _ _ O
Here _ _ O
, _ _ O
Block _ _ O
0 _ _ O
contains _ _ O
byte _ _ O
addresses _ _ O
0x00 _ _ O
through _ _ O
0x39 _ _ O
. _ _ O
Block _ _ O
1 _ _ O
is _ _ O
0x40 _ _ O
to _ _ O
0x79 _ _ O
, _ _ O
etc _ _ O
. _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
4 _ _ O
5 _ _ O
6 _ _ O
7 _ _ O
8 _ _ O
9 _ _ O
A _ _ O
B _ _ O
C _ _ O
D _ _ O
E _ _ O
64 _ _ O
bytes _ _ O
• _ _ O
Let _ _ O
’s _ _ O
request _ _ O
64-bit _ _ O
words _ _ O
in _ _ O
order _ _ O
starting _ _ O
at _ _ O
address _ _ O
0x40 _ _ O
( _ _ O
Block _ _ O
1 _ _ O
) _ _ O
▪ _ _ O
There _ _ O
are _ _ O
8 _ _ O
words _ _ O
in _ _ O
each _ _ O
cache _ _ O
block _ _ O
. _ _ O
▪ _ _ O
Therefore _ _ O
, _ _ O
we _ _ O
have _ _ O
only _ _ O
one _ _ O
compulsory _ _ O
miss _ _ O
. _ _ O
▪ _ _ O
And _ _ O
then _ _ O
we _ _ O
have _ _ O
7 _ _ O
cache _ _ O
hits _ _ O
! _ _ O
! _ _ O
• _ _ O
If _ _ O
we _ _ O
request _ _ O
the _ _ O
ninth _ _ O
word _ _ O
, _ _ O
we _ _ O
will _ _ O
be _ _ O
at _ _ O
address _ _ O
0x80 _ _ O
( _ _ O
and _ _ O
a _ _ O
compulsory _ _ O
miss _ _ O
. _ _ O
) _ _ O
1 _ _ O
2 _ _ O
24 _ _ O

Once _ _ O
again _ _ O
… _ _ O
A _ _ O
Tale _ _ O
of _ _ O
Two _ _ O
C _ _ O
… _ _ O
um _ _ O
… _ _ O
programs _ _ O
Allocates _ _ O
matrices _ _ O
. _ _ O
( _ _ O
Array _ _ O
of _ _ O
arrays _ _ O
) _ _ O
Copies _ _ O
one _ _ O
matrix _ _ O
to _ _ O
another _ _ O
. _ _ O
( _ _ O
data _ _ O
itself _ _ O
is _ _ O
uninitialized _ _ O
. _ _ O
) _ _ O
Spring _ _ O
2019 _ _ O
/ _ _ O
2020 _ _ O
Iterates _ _ O
through _ _ O
column _ _ O
. _ _ O
( _ _ O
Other _ _ O
code _ _ O
goes _ _ O
through _ _ O
row _ _ O
) _ _ O
25 _ _ O

Once _ _ O
again _ _ O
… _ _ O
A _ _ O
Tale _ _ O
of _ _ O
Two _ _ O
C _ _ O
… _ _ O
um _ _ O
… _ _ O
programs _ _ O
• _ _ O
We _ _ O
will _ _ O
simplify _ _ O
by _ _ O
looking _ _ O
at _ _ O
a _ _ O
4x4 _ _ O
matrix _ _ O
. _ _ O
▪ _ _ O
We _ _ O
want _ _ O
to _ _ O
get _ _ O
the _ _ O
addresses _ _ O
being _ _ O
used _ _ O
to _ _ O
see _ _ O
the _ _ O
access _ _ O
pattern _ _ O
. _ _ O
( _ _ O
Goes _ _ O
across _ _ O
row _ _ O
) _ _ O
26 _ _ O

Once _ _ O
again _ _ O
… _ _ O
A _ _ O
Tale _ _ O
of _ _ O
Two _ _ O
C _ _ O
… _ _ O
um _ _ O
… _ _ O
programs _ _ O
• _ _ O
We _ _ O
will _ _ O
simplify _ _ O
by _ _ O
looking _ _ O
at _ _ O
a _ _ O
4x4 _ _ O
matrix _ _ O
. _ _ O
▪ _ _ O
Notice _ _ O
the _ _ O
different _ _ O
type _ _ O
of _ _ O
access _ _ O
pattern _ _ O
. _ _ O
▪ _ _ O
( _ _ O
Goes _ _ O
down _ _ O
the _ _ O
column _ _ O
) _ _ O
27 _ _ O

The _ _ O
Antagonist _ _ O
• _ _ O
One _ _ O
program _ _ O
reads _ _ O
words _ _ O
sequentially _ _ O
in _ _ O
memory _ _ O
( _ _ O
good _ _ O
spatial _ _ O
locality _ _ O
) _ _ O
▪ _ _ O
The _ _ O
other _ _ O
reads _ _ O
each _ _ O
word _ _ O
as _ _ O
far _ _ O
apart _ _ O
as _ _ O
possible _ _ O
! _ _ O
( _ _ O
worst _ _ O
spatial _ _ O
locality _ _ O
) _ _ O
• _ _ O
Let _ _ O
’s _ _ O
look _ _ O
at _ _ O
making _ _ O
the _ _ O
matrices _ _ O
much _ _ O
larger _ _ O
! _ _ O
Let _ _ O
’s _ _ O
make _ _ O
each _ _ O
row _ _ O
span _ _ O
256 _ _ O
Bytes _ _ O
. _ _ O
( _ _ O
4 _ _ O
blocks _ _ O
, _ _ O
which _ _ O
is _ _ O
the _ _ O
size _ _ O
of _ _ O
our _ _ O
cache _ _ O
! _ _ O
) _ _ O
This _ _ O
cache _ _ O
item _ _ O
holds _ _ O
, _ _ O
, _ _ O
, _ _ O
etc _ _ O
0 _ _ O
1 _ _ O
2 _ _ O
3 _ _ O
Cache _ _ O
size _ _ O
: _ _ O
256B _ _ O
64 _ _ O
bytes _ _ O
per _ _ O
block _ _ O
. _ _ O
28 _ _ O

Cache _ _ O
Performance _ _ O
• _ _ O
Recall _ _ O
that _ _ O
caches _ _ O
make _ _ O
computers _ _ O
practical _ _ O
. _ _ O
▪ _ _ O
Why _ _ O
? _ _ O
Well _ _ O
… _ _ O
▪ _ _ O
Our _ _ O
“ _ _ O
slow _ _ O
” _ _ O
program _ _ O
effectively _ _ O
did _ _ O
not _ _ O
use _ _ O
cache _ _ O
, _ _ O
and _ _ O
it _ _ O
was _ _ O
10 _ _ O
times _ _ O
slower _ _ O
. _ _ O
• _ _ O
Simply _ _ O
: _ _ O
Caches _ _ O
offer _ _ O
much _ _ O
faster _ _ O
accesses _ _ O
than _ _ O
DRAM _ _ O
. _ _ O
▪ _ _ O
Perhaps _ _ O
100s _ _ O
of _ _ O
times _ _ O
faster _ _ O
. _ _ O
• _ _ O
Consider _ _ O
the _ _ O
math _ _ O
: _ _ O
▪ _ _ O
miss _ _ O
rate _ _ O
( _ _ O
MR _ _ O
) _ _ O
: _ _ O
Fraction _ _ O
of _ _ O
memory _ _ O
accesses _ _ O
not _ _ O
in _ _ O
cache _ _ O
. _ _ O
▪ _ _ O
hit _ _ O
rate _ _ O
( _ _ O
HR _ _ O
) _ _ O
: _ _ O
Fraction _ _ O
of _ _ O
memory _ _ O
accesses _ _ O
found _ _ O
in _ _ O
cache _ _ O
. _ _ O
( _ _ O
H𝑅 _ _ O
= _ _ O
1 _ _ O
− _ _ O
𝑀𝑅 _ _ O
) _ _ O
▪ _ _ O
hit _ _ O
time _ _ O
( _ _ O
HT _ _ O
) _ _ O
: _ _ O
Time _ _ O
it _ _ O
takes _ _ O
to _ _ O
read _ _ O
a _ _ O
block _ _ O
from _ _ O
cache _ _ O
to _ _ O
CPU _ _ O
. _ _ O
( _ _ O
Best _ _ O
case _ _ O
) _ _ O
▪ _ _ O
miss _ _ O
penalty _ _ O
( _ _ O
MP _ _ O
) _ _ O
: _ _ O
Time _ _ O
it _ _ O
takes _ _ O
to _ _ O
read _ _ O
from _ _ O
main _ _ O
memory _ _ O
to _ _ O
cache _ _ O
. _ _ O
29 _ _ O

Cache _ _ O
Performance _ _ O
• _ _ O
Recall _ _ O
that _ _ O
caches _ _ O
make _ _ O
computers _ _ O
practical _ _ O
. _ _ O
• _ _ O
Consider _ _ O
the _ _ O
math _ _ O
: _ _ O
▪ _ _ O
miss _ _ O
rate _ _ O
( _ _ O
MR _ _ O
) _ _ O
: _ _ O
Fraction _ _ O
of _ _ O
memory _ _ O
accesses _ _ O
not _ _ O
in _ _ O
cache _ _ O
. _ _ O
▪ _ _ O
hit _ _ O
rate _ _ O
( _ _ O
HR _ _ O
) _ _ O
: _ _ O
Fraction _ _ O
of _ _ O
memory _ _ O
accesses _ _ O
found _ _ O
in _ _ O
cache _ _ O
. _ _ O
( _ _ O
H𝑅 _ _ O
= _ _ O
1 _ _ O
− _ _ O
𝑀𝑅 _ _ O
) _ _ O
▪ _ _ O
hit _ _ O
time _ _ O
( _ _ O
HT _ _ O
) _ _ O
: _ _ O
Time _ _ O
it _ _ O
takes _ _ O
to _ _ O
read _ _ O
a _ _ O
block _ _ O
from _ _ O
cache _ _ O
to _ _ O
CPU _ _ O
. _ _ O
( _ _ O
Best _ _ O
case _ _ O
) _ _ O
▪ _ _ O
miss _ _ O
penalty _ _ O
( _ _ O
MP _ _ O
) _ _ O
: _ _ O
Time _ _ O
it _ _ O
takes _ _ O
to _ _ O
read _ _ O
from _ _ O
main _ _ O
memory _ _ O
to _ _ O
cache _ _ O
. _ _ O
• _ _ O
Average _ _ O
Memory _ _ O
Access _ _ O
Time _ _ O
( _ _ O
AMAT _ _ O
) _ _ O
: _ _ O
The _ _ O
time _ _ O
it _ _ O
takes _ _ O
, _ _ O
on _ _ O
average _ _ O
, _ _ O
to _ _ O
perform _ _ O
a _ _ O
memory _ _ O
request _ _ O
, _ _ O
considering _ _ O
the _ _ O
cache _ _ O
performance _ _ O
. _ _ O
▪ _ _ O
𝐴𝑀𝐴𝑇 _ _ O
= _ _ O
𝐻𝑇 _ _ O
+ _ _ O
𝑀𝑅 _ _ O
× _ _ O
𝑀𝑃 _ _ O
• _ _ O
Assuming _ _ O
a _ _ O
HT _ _ O
of _ _ O
1 _ _ O
clock _ _ O
cycle _ _ O
and _ _ O
a _ _ O
MP _ _ O
of _ _ O
100 _ _ O
clock _ _ O
cycles _ _ O
… _ _ O
▪ _ _ O
A _ _ O
HR _ _ O
of _ _ O
97 _ _ O
% _ _ O
: _ _ O
𝐴𝑀𝐴𝑇 _ _ O
= _ _ O
1 _ _ O
+ _ _ O
0.03 _ _ O
× _ _ O
100 _ _ O
= _ _ O
4 _ _ O
𝑐𝑦𝑐𝑙𝑒𝑠 _ _ O
▪ _ _ O
A _ _ O
HR _ _ O
of _ _ O
99 _ _ O
% _ _ O
: _ _ O
𝐴𝑀𝐴𝑇 _ _ O
= _ _ O
1 _ _ O
+ _ _ O
0.01 _ _ O
× _ _ O
100 _ _ O
= _ _ O
2 _ _ O
𝑐𝑦𝑐𝑙𝑒𝑠 _ _ O
▪ _ _ O
A _ _ O
hit-rate _ _ O
jump _ _ O
from _ _ O
just _ _ O
97 _ _ O
% _ _ O
to _ _ O
99 _ _ O
% _ _ O
doubles _ _ O
memory _ _ O
performance _ _ O
. _ _ O
Wow _ _ O
. _ _ O
30 _ _ O

Cache _ _ O
Layout _ _ O
Summary _ _ O
• _ _ O
We _ _ O
have _ _ O
seen _ _ O
two _ _ O
types _ _ O
of _ _ O
cache _ _ O
layouts _ _ O
. _ _ O
▪ _ _ O
A _ _ O
freeform _ _ O
cache _ _ O
: _ _ O
blocks _ _ O
go _ _ O
wherever _ _ O
. _ _ O
¯\_ _ _ O
( _ _ O
ツ _ _ O
) _ _ O
_ _ _ O
/ _ _ O
¯ _ _ O
• _ _ O
Also _ _ O
called _ _ O
a _ _ O
fully _ _ O
associative _ _ O
cache _ _ O
. _ _ O
▪ _ _ O
A _ _ O
direct-mapped _ _ O
cache _ _ O
: _ _ O
blocks _ _ O
go _ _ O
into _ _ O
slots _ _ O
. _ _ O
• _ _ O
They _ _ O
have _ _ O
their _ _ O
own _ _ O
trade-offs _ _ O
, _ _ O
and _ _ O
as _ _ O
usual _ _ O
… _ _ O
▪ _ _ O
We _ _ O
can _ _ O
have _ _ O
a _ _ O
hybrid _ _ O
approach _ _ O
! _ _ O
• _ _ O
Here _ _ O
, _ _ O
each _ _ O
cache _ _ O
slot _ _ O
has _ _ O
multiple _ _ O
bins _ _ O
. _ _ O
▪ _ _ O
You _ _ O
only _ _ O
need _ _ O
to _ _ O
evict _ _ O
when _ _ O
you _ _ O
fill _ _ O
up _ _ O
the _ _ O
bins _ _ O
. _ _ O
Best _ _ O
of _ _ O
both _ _ O
worlds _ _ O
! _ _ O
▪ _ _ O
Which _ _ O
do _ _ O
you _ _ O
evict _ _ O
? _ _ O
( _ _ O
Hmm _ _ O
… _ _ O
difficult _ _ O
choice _ _ O
. _ _ O
) _ _ O
31 _ _ O

Associativity _ _ O
• _ _ O
With _ _ O
an _ _ O
associative _ _ O
cache _ _ O
, _ _ O
the _ _ O
address _ _ O
determines _ _ O
the _ _ O
slot _ _ O
. _ _ O
▪ _ _ O
Much _ _ O
like _ _ O
a _ _ O
direct-mapped _ _ O
cache _ _ O
. _ _ O
▪ _ _ O
However _ _ O
, _ _ O
the _ _ O
slot _ _ O
has _ _ O
a _ _ O
number _ _ O
of _ _ O
bins _ _ O
. _ _ O
▪ _ _ O
Any _ _ O
bin _ _ O
in _ _ O
the _ _ O
slot _ _ O
is _ _ O
viable _ _ O
for _ _ O
a _ _ O
block _ _ O
. _ _ O
▪ _ _ O
The _ _ O
number _ _ O
of _ _ O
bins _ _ O
is _ _ O
the _ _ O
number _ _ O
of _ _ O
“ _ _ O
ways _ _ O
” _ _ O
• _ _ O
A _ _ O
direct-mapped _ _ O
cache _ _ O
is _ _ O
a _ _ O
1-way _ _ O
cache _ _ O
. _ _ O
• _ _ O
When _ _ O
the _ _ O
cache _ _ O
determines _ _ O
if _ _ O
the _ _ O
block _ _ O
is _ _ O
in _ _ O
the _ _ O
cache _ _ O
already _ _ O
… _ _ O
▪ _ _ O
It _ _ O
determines _ _ O
the _ _ O
slot _ _ O
. _ _ O
▪ _ _ O
It _ _ O
scans _ _ O
every _ _ O
bin _ _ O
for _ _ O
a _ _ O
block _ _ O
tagged _ _ O
with _ _ O
that _ _ O
exact _ _ O
address _ _ O
. _ _ O
▪ _ _ O
Therefore _ _ O
, _ _ O
the _ _ O
cache _ _ O
performance _ _ O
degrades _ _ O
as _ _ O
you _ _ O
increase _ _ O
the _ _ O
number _ _ O
of _ _ O
ways _ _ O
. _ _ O
32 _ _ O

Another _ _ O
way _ _ O
of _ _ O
viewing _ _ O
it _ _ O
All _ _ O
have _ _ O
the _ _ O
same _ _ O
size _ _ O
, _ _ O
so _ _ O
… _ _ O
On _ _ O
a _ _ O
fully _ _ O
associative _ _ O
cache _ _ O
all _ _ O
blocks _ _ O
belong _ _ O
to _ _ O
the _ _ O
same _ _ O
set _ _ O
On _ _ O
a _ _ O
direct-mapped _ _ O
cache _ _ O
all _ _ O
blocks _ _ O
belong _ _ O
to _ _ O
a _ _ O
different _ _ O
set _ _ O
On _ _ O
a _ _ O
n-way _ _ O
associative _ _ O
cache _ _ O
n _ _ O
blocks _ _ O
belong _ _ O
to _ _ O
the _ _ O
same _ _ O
set _ _ O
33 _ _ O

Mapping _ _ O
WT _ _ O
F…Cache _ _ O
! _ _ O
? _ _ O

Sooo _ _ O
… _ _ O
exactly _ _ O
what _ _ O
can _ _ O
go _ _ O
where _ _ O
? _ _ O
• _ _ O
Given _ _ O
a _ _ O
memory _ _ O
address _ _ O
, _ _ O
in _ _ O
which _ _ O
set _ _ O
does _ _ O
it _ _ O
go _ _ O
? _ _ O
• _ _ O
How _ _ O
many _ _ O
sets _ _ O
are _ _ O
there _ _ O
? _ _ O
• _ _ O
Let _ _ O
’s _ _ O
start _ _ O
by _ _ O
defining _ _ O
a _ _ O
cache _ _ O
size _ _ O
• _ _ O
32KiB _ _ O
64B _ _ O
32𝐾𝑖𝐵 _ _ O
215 _ _ O
I _ _ O
need _ _ O
64𝐵 _ _ O
= _ _ O
26 _ _ O
= _ _ O
29 _ _ O
= _ _ O
512 _ _ O
lines _ _ O
• _ _ O
How _ _ O
many _ _ O
cache _ _ O
lines _ _ O
do _ _ O
you _ _ O
need _ _ O
? _ _ O
• _ _ O
Well _ _ O
it _ _ O
depends _ _ O
on _ _ O
the _ _ O
size _ _ O
of _ _ O
each _ _ O
cache _ _ O
line _ _ O
• _ _ O
# _ _ O
Cache _ _ O
line _ _ O
? _ _ O
# _ _ O
Cache _ _ O
row _ _ O
? _ _ O
# _ _ O
Block _ _ O
? _ _ O
# _ _ O
bins _ _ O
? _ _ O
• _ _ O
Let _ _ O
’s _ _ O
use _ _ O
: _ _ O
64B _ _ O
! _ _ O
35 _ _ O

Sooo _ _ O
… _ _ O
exactly _ _ O
what _ _ O
can _ _ O
where _ _ O
? _ _ O
64B _ _ O
• _ _ O
Let _ _ O
’s _ _ O
start _ _ O
by _ _ O
defining _ _ O
a _ _ O
cache _ _ O
size _ _ O
• _ _ O
32KiB _ _ O
• _ _ O
How _ _ O
many _ _ O
cache _ _ O
rows _ _ O
do _ _ O
you _ _ O
need _ _ O
? _ _ O
• _ _ O
Well _ _ O
it _ _ O
depends _ _ O
on _ _ O
the _ _ O
size _ _ O
of _ _ O
each _ _ O
row _ _ O
• _ _ O
Let _ _ O
’s _ _ O
use _ _ O
: _ _ O
64B _ _ O
! _ _ O
• _ _ O
Decrease _ _ O
the _ _ O
size _ _ O
32𝐾𝑖𝐵 _ _ O
215 _ _ O
I _ _ O
need _ _ O
64𝐵 _ _ O
= _ _ O
26 _ _ O
= _ _ O
29 _ _ O
= _ _ O
512 _ _ O
rows _ _ O
• _ _ O
+ _ _ O
rows _ _ O
, _ _ O
+ _ _ O
( _ _ O
but _ _ O
faster _ _ O
) _ _ O
memory _ _ O
access _ _ O
, _ _ O
-locality _ _ O
• _ _ O
Increase _ _ O
the _ _ O
size _ _ O
• _ _ O
-rows _ _ O
, _ _ O
- _ _ O
( _ _ O
but _ _ O
slower _ _ O
) _ _ O
memory _ _ O
access _ _ O
, _ _ O
+ _ _ O
locality _ _ O
36 _ _ O

How _ _ O
many _ _ O
sets _ _ O
• _ _ O
The _ _ O
number _ _ O
of _ _ O
sets _ _ O
depends _ _ O
on _ _ O
the _ _ O
associativity _ _ O
• _ _ O
Remember _ _ O
we _ _ O
have _ _ O
a _ _ O
fixed _ _ O
amount _ _ O
of _ _ O
rows _ _ O
! _ _ O
• _ _ O
For _ _ O
fully _ _ O
associative _ _ O
( _ _ O
easy _ _ O
) _ _ O
we _ _ O
have _ _ O
1 _ _ O
set _ _ O
☺ _ _ O
• _ _ O
For _ _ O
n-way _ _ O
associative _ _ O
cache _ _ O
we _ _ O
need _ _ O
some _ _ O
maths _ _ O
: _ _ O
• _ _ O
n-way _ _ O
associative _ _ O
means _ _ O
we _ _ O
divide _ _ O
the _ _ O
lines _ _ O
in _ _ O
groups _ _ O
of _ _ O
n-elements _ _ O
0 _ _ O
… _ _ O
s-1 _ _ O
So _ _ O
how _ _ O
many _ _ O
sets _ _ O
? _ _ O
Each _ _ O
column _ _ O
( _ _ O
set _ _ O
) _ _ O
has _ _ O
n _ _ O
rows _ _ O
Still _ _ O
512 _ _ O
rows _ _ O
! _ _ O
s= _ _ O
# _ _ O
rows _ _ O
512 _ _ O
= _ _ O
𝑛 _ _ O
𝑛 _ _ O
37 _ _ O

How _ _ O
many _ _ O
sets _ _ O
• _ _ O
If _ _ O
we _ _ O
apply _ _ O
this _ _ O
to _ _ O
a _ _ O
4-way _ _ O
associative _ _ O
cache _ _ O
0 _ _ O
… _ _ O
127 _ _ O
So _ _ O
how _ _ O
many _ _ O
sets _ _ O
? _ _ O
Each _ _ O
column _ _ O
( _ _ O
set _ _ O
) _ _ O
has _ _ O
4 _ _ O
rows _ _ O
Still _ _ O
512 _ _ O
rows _ _ O
! _ _ O
# _ _ O
rows _ _ O
512 _ _ O
s= _ _ O
= _ _ O
𝑛 _ _ O
4 _ _ O
= _ _ O
128 _ _ O
𝑠𝑒𝑡𝑠 _ _ O
38 _ _ O

Address _ _ O
Manipulation _ _ O
Request _ _ O
from _ _ O
CPU _ _ O
: _ _ O
Access _ _ O
PT _ _ O
: _ _ O
𝑛-bit _ _ O
virtual _ _ O
address _ _ O
Virtual _ _ O
Page _ _ O
Number _ _ O
Page _ _ O
offset _ _ O
TRANSLATION _ _ O
𝑚-bit _ _ O
physical _ _ O
address _ _ O
: _ _ O
Split _ _ O
to _ _ O
access _ _ O
cache _ _ O
: _ _ O
Physical _ _ O
Page _ _ O
Number _ _ O
Cache _ _ O
Tag _ _ O
Page _ _ O
offset _ _ O
Set _ _ O
Index _ _ O
Offset _ _ O

Using _ _ O
our _ _ O
example _ _ O
• _ _ O
On _ _ O
our _ _ O
example _ _ O
: _ _ O
• _ _ O
Cache _ _ O
size _ _ O
: _ _ O
32KiB _ _ O
• _ _ O
Block _ _ O
size _ _ O
: _ _ O
64B _ _ O
= _ _ O
26 _ _ O
• _ _ O
Associativity _ _ O
: _ _ O
4-way _ _ O
• _ _ O
Number _ _ O
of _ _ O
sets _ _ O
: _ _ O
128 _ _ O
= _ _ O
27 _ _ O
25-bit _ _ O
physical _ _ O
address _ _ O
: _ _ O
Split _ _ O
to _ _ O
access _ _ O
cache _ _ O
: _ _ O
Physical _ _ O
Page _ _ O
Number _ _ O
Page _ _ O
offset _ _ O
Cache _ _ O
Tag _ _ O
Set _ _ O
Index _ _ O
Offset _ _ O
12 _ _ O
bits _ _ O
7 _ _ O
bits _ _ O
6 _ _ O
bits _ _ O
TAG _ _ O
Set _ _ O
valid _ _ O
Data _ _ O
0xFFF _ _ O
0 _ _ O
0 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
0 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x123 _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x456 _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
Only _ _ O
showing _ _ O
2 _ _ O
blocks _ _ O
per _ _ O
set _ _ O
( _ _ O
slide _ _ O
space _ _ O
) _ _ O

Using _ _ O
our _ _ O
example _ _ O
TAG _ _ O
Set _ _ O
valid _ _ O
Data _ _ O
0x000 _ _ O
0 _ _ O
0 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
0 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x123 _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x456 _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
25-bit _ _ O
physical _ _ O
address _ _ O
: _ _ O
Split _ _ O
to _ _ O
access _ _ O
cache _ _ O
: _ _ O
Hit _ _ O
! _ _ O
111111111111000000 _ _ O
0000000 _ _ O
0xFFF _ _ O
0 _ _ O
0 _ _ O
12 _ _ O
bits _ _ O
7 _ _ O
bits _ _ O
6 _ _ O
bits _ _ O

Using _ _ O
our _ _ O
example _ _ O
TAG _ _ O
Set _ _ O
valid _ _ O
Data _ _ O
0x000 _ _ O
0 _ _ O
0 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
0 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x123 _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x456 _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
25-bit _ _ O
physical _ _ O
address _ _ O
: _ _ O
Split _ _ O
to _ _ O
access _ _ O
cache _ _ O
: _ _ O
Miss _ _ O
! _ _ O
000000000000000000 _ _ O
0000000 _ _ O
0x000 _ _ O
0 _ _ O
0 _ _ O
12 _ _ O
bits _ _ O
7 _ _ O
bits _ _ O
6 _ _ O
bits _ _ O

Using _ _ O
our _ _ O
example _ _ O
TAG _ _ O
Set _ _ O
valid _ _ O
Data _ _ O
0x000 _ _ O
0 _ _ O
0 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
0 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x123 _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x456 _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
25-bit _ _ O
physical _ _ O
address _ _ O
: _ _ O
Split _ _ O
to _ _ O
access _ _ O
cache _ _ O
: _ _ O
Hit _ _ O
! _ _ O
000100100011000000 _ _ O
1000000 _ _ O
0x123 _ _ O
1 _ _ O
0 _ _ O
12 _ _ O
bits _ _ O
7 _ _ O
bits _ _ O
6 _ _ O
bits _ _ O

Using _ _ O
our _ _ O
example _ _ O
TAG _ _ O
Set _ _ O
valid _ _ O
Data _ _ O
0x000 _ _ O
0 _ _ O
0 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
0 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x123 _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x456 _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
25-bit _ _ O
physical _ _ O
address _ _ O
: _ _ O
Split _ _ O
to _ _ O
access _ _ O
cache _ _ O
: _ _ O
Miss _ _ O
! _ _ O
101010101010010101 _ _ O
0000000 _ _ O
0xAAA _ _ O
42 _ _ O
0 _ _ O
12 _ _ O
bits _ _ O
7 _ _ O
bits _ _ O
6 _ _ O
bits _ _ O

Offset _ _ O
TAG _ _ O
Set _ _ O
valid _ _ O
Data _ _ O
0x000 _ _ O
0 _ _ O
0 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
0 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x123 _ _ O
1 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0x456 _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
0xFFF _ _ O
42 _ _ O
1 _ _ O
( _ _ O
64B _ _ O
of _ _ O
data _ _ O
) _ _ O
Hit _ _ O
! _ _ O
63 _ _ O
62 _ _ O
61 _ _ O
… _ _ O
5 _ _ O
4 _ _ O
3 _ _ O
2 _ _ O
1 _ _ O
0 _ _ O
0xF5 _ _ O
0x32 _ _ O
0x45 _ _ O
… _ _ O
0xFF _ _ O
0xFE _ _ O
0x00 _ _ O
0x68 _ _ O
0x67 _ _ O
0x65 _ _ O
25-bit _ _ O
physical _ _ O
address _ _ O
: _ _ O
Split _ _ O
to _ _ O
access _ _ O
cache _ _ O
: _ _ O
111111111111000000 _ _ O
0000010 _ _ O
0xFFF _ _ O
0 _ _ O
2 _ _ O
12 _ _ O
bits _ _ O
7 _ _ O
bits _ _ O
6 _ _ O
bits _ _ O
45 _ _ O

Summary _ _ O
• _ _ O
The _ _ O
notion _ _ O
of _ _ O
storing _ _ O
data _ _ O
is _ _ O
a _ _ O
complicated _ _ O
one _ _ O
. _ _ O
▪ _ _ O
Different _ _ O
technologies _ _ O
have _ _ O
different _ _ O
strengths _ _ O
( _ _ O
and _ _ O
costs _ _ O
) _ _ O
▪ _ _ O
Often _ _ O
trade-off _ _ O
between _ _ O
: _ _ O
• _ _ O
fast _ _ O
/ _ _ O
small _ _ O
, _ _ O
expensive _ _ O
• _ _ O
slow _ _ O
/ _ _ O
big _ _ O
, _ _ O
cheap _ _ O
▪ _ _ O
Hardware _ _ O
designs _ _ O
attempt _ _ O
to _ _ O
accommodate _ _ O
a _ _ O
variety _ _ O
of _ _ O
technologies _ _ O
. _ _ O
• _ _ O
Often _ _ O
using _ _ O
fast _ _ O
/ _ _ O
small _ _ O
memories _ _ O
to _ _ O
act _ _ O
as _ _ O
a _ _ O
“ _ _ O
cache _ _ O
” _ _ O
for _ _ O
slower _ _ O
ones _ _ O
. _ _ O
• _ _ O
Caches _ _ O
can _ _ O
be _ _ O
arranged _ _ O
in _ _ O
several _ _ O
ways _ _ O
: _ _ O
▪ _ _ O
Blocks _ _ O
go _ _ O
anywhere _ _ O
( _ _ O
fully-associative _ _ O
) _ _ O
▪ _ _ O
Blocks _ _ O
go _ _ O
in _ _ O
particular _ _ O
slots _ _ O
( _ _ O
direct-mapped _ _ O
/ _ _ O
1-way _ _ O
associative _ _ O
) _ _ O
▪ _ _ O
Hybrid _ _ O
: _ _ O
Blocks _ _ O
go _ _ O
to _ _ O
particular _ _ O
slots _ _ O
… _ _ O
but _ _ O
then _ _ O
can _ _ O
go _ _ O
in _ _ O
any _ _ O
bin _ _ O
in _ _ O
that _ _ O
slot _ _ O
. _ _ O
• _ _ O
Caches _ _ O
attempt _ _ O
to _ _ O
exploit _ _ O
temporal _ _ O
and _ _ O
spatial _ _ O
locality _ _ O
of _ _ O
programs _ _ O
. _ _ O
▪ _ _ O
And _ _ O
even _ _ O
a _ _ O
slight _ _ O
improvement _ _ O
to _ _ O
hit _ _ O
rate _ _ O
can _ _ O
dramatically _ _ O
improve _ _ O
overall _ _ O
performance _ _ O
of _ _ O
a _ _ O
program _ _ O
! _ _ O
46 _ _ O



