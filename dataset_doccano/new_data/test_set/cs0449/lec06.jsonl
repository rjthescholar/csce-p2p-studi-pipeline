{"id": 6, "segment": ["test_set", "labeled"], "course": "cs0449", "lec": "lec06", "text": "6\n\nMemory\nManagement\n\nCS/COE 0449\nIntroduction to\nSystems Software\n\nLuis Oliveira\n(with content borrowed from wilkie and Vinicius Petrucci)\n\nOur Story So Far\nYou Hear a Voice Whisper: \"The Memory Layout is a Lie\"\n\n2\n\nReallocating our thoughts\n\u2022 A program has several sections:\n\u2022 Code\n\u2022 Static data\n\u2022 Stack\n\u2022 Heap\n\n\u2022 Today, we take a deeper dive at how dynamic\nmemory is allocated in the heap.\n\nPotential Layout\n(32-bit addresses)\n\nstack\ncurrently unused but\navailable memory\n\nheap\nstatic data\n\ncode\n3\n\nReallocating our thoughts\n\u2022 We have looked at\n\nand\n\n.\n\n\u2022 They stake out space in the heap and return an\naddress.\n\u2022 Right now, we live in a nice ideal world.\n\u2022 No other programs are running.\n\u2022 We have access to all of the memory.\n\u2022 Muhahahaha!!\n\n\u2022 The OS is lying to our program.\n\u2022 This memory is... virtual... reality.\n\u2022 We will investigate this lie later in the course.\n\nPotential Layout\n(32-bit addresses)\n\nstack\ncurrently unused but\navailable memory\n\nheap\nstatic data\n\ncode\n4\n\nThe World of Allocation\nIt is a puzzle without any optimal solution. Welcome to computers!\n\n5\n\nA heap of possibilities\n\u2022 Stack access often does not deviate much.\n\nPotential Layout\n(32-bit addresses)\n\n\u2022 We allocate a little bit at a time.\n\u2022 We allocate and free the memory VERY often.\n\nstack\n\u2022 Heap allocations have many access patterns that are\npossible.\n\u2022 You might allocate a lot at a time and keep it around for a\nlong time. Or a short time.\n\u2022 You might allocate a lot of small things, instead.\n\u2022 Maybe you do a little bit of everything?\n\n\u2022 Often, such patterns are not easy to predict.\n\u2022 Do you get a big file as input? A small file?\n\ncurrently unused but\navailable memory\n\nheap\nstatic data\n\ncode\n6\n\nA heaping helping of good luck\n\u2022 Allocations could happen in a nice order.\n\u2022 When something is allocated, it can be allocated\nafter everything else.\n\nstack\n\navailable memory\navailable memory\navailable memory\n\n\u2022 When freed, it makes room for new things.\n\n\u2022 IF ONLY.\n\u2022 I mean, it's possible... but like...\n\u2022 the heap and stack are different things for a reason.\n\nheap\nstatic data\ncode\n7\n\nDigital potholes... as annoying as real ones\n\u2022 Small allocations interfere with large ones.\n\u2022 When small gaps interfere with allocation, this is\ncalled fragmentation.\n\nstack\navailable memory\navailable memory\navailable\navailable memory\nmemory\navailable memory\n\nNext\nAllocation\n\nUgh\n\n?\nif we had omniscience of future\nallocations, we could avoid this...\nbut we can't know ahead of time!\n\nheap\nstatic data\ncode\n8\n\nThe worst case\nstack\n\n\u2022 When you allocate a lot of small things...\n\u2022 Free every other one...\n\u2022 And then attempt to allocate a bigger thing...\n\n\u2022 Even though there is technically enough memory...\n\u2022 There is no continuous space.\n\u2022 Therefore, our na\u00efve\nwill fail.\n\n\u2022 We have to come up with some strategy.\n\n???\n\nheap\nstatic data\ncode\n9\n\nMoving is never easy\nstack\n\n\u2022 Why not move things around??\n\u2022 A defragmentation process/algorithm\n\n\u2022 Moving around something in the heap is hard!\n\u2022 Any pointers referring to data within a block must be updated.\n\u2022 Finding these pointers automatically is effectively as difficult\nas garbage collection.\n\n\u2022 Because of this, moving blocks around is discouraged.\n(Easier to solve it another way.)\n???\n\nheap\nstatic data\ncode\n10\n\nMoving is NEVER easy\nstack\navailable memory\n\n\u2022 When blocks move, pointers\nto anything within them must be updated.\n\u2022 This is hard to keep track of!\n\u2022 C does not check validity of pointers after\n\nheap\nstatic data\ncode\n11\n\nStressing it out\n\u2022 If we allocate a large array it will be allocated on the\nheap somewhere.\n\u2022 Other allocations can also happen, and they go \"above\"\nthat array.\n\nstack\n\navailable memory\n\nint arr[200]\n\n\u2022 What happens when you need to append a 101st\nelement to this array?\n\u2022 Uh oh!\nold\ndata:\nint arr[100]\nint\narr[100]\n\n\u2022 You will need to allocate more space.\n\u2022 And then copy the array contents.\n\u2022 Free the old array.\n\u2022 How long does that take?\n\nfragmentation\n\nheap\n12\n\nStressing it out: Big Arrays\n\u2022 This happens in very practical situations!\n\u2022 Reallocating means getting rid of a small thing\n\u2022 And replacing it with a larger thing.\n\u2022 You could have TiBs of memory and this will be a problem.\n\nstack\n\navailable memory\n\n\u2022 This affects performance: (in terms of writes:)\n\u2022 Appending item arr[0]: O 1\n\u2022 Appending item arr[1]: O 1\n\u2022 ...\n\u2022 Appending item arr[99]: O 1\n\u2022 Appending item arr[100]: O n + 1 oh no!\n\n\u2022 When you would overflow the buffer...\n\u2022 You then need to copy all previous values as well.\n\nold\ndata:\nint arr[100]\nint\narr[100]\n\nheap\n13\n\nStressing it out: Performance Consistency\n\u2022 Big arrays want to be continuous.\n\u2022 Ensuring continuous space is difficult when you do not know\nhow much you will ultimately need.\n\n\u2022 This is exactly why linked lists exist!\n\nstack\n\navailable memory\n\n\u2022 Since a linked list allocates on every append.\n\u2022 Each append takes the same amount of time.\n\n\u2022 However, everything is a trade-off.\n\u2022 Dang it!!!\n\u2022 One cost is extra overhead for metadata.\n\u2022 Linked list traversal can stress memory caches.\n\u2022 It means traversing the array is slower.\n\u2022 However, we will mostly ignore this for now.\n\nold\ndata:\nint arr[100]\nint\narr[100]\n\nheap\n14\n\nThe Linked List\nA story about trade-offs.\n\n15\n\nWhat is a linked list?\n\u2022 A linked list is a non-continuous data structure representing an ordered list.\n\u2022 Each item in the linked list is represented by metadata called a node.\n\u2022 This metadata indirectly refers to the actual data.\n\u2022 Furthermore, it indirectly refers to at least one other item in the list.\n\nNode\n\n\"struct\" required since\nNode is not technically\ndefined until after it is\ndefined!\n\n16\n\nKeeping ahead of the list.\n\u2022 Creation of a list occurs when one allocates a single node and tracks it in a\npointer. This is the head of our list (first element.)\n\nNode\n\n17\n\nAdding some links to our chain\n\u2022 If we want to append an item, we can add a node anywhere!\n\n\"tail\"\n\n\"node\"\n\nRemember the\n'\\0' sentinel!\n\n18\n\nWe can add them anywhere!!\n\u2022 Consider what happens if we update our append to take any Node:\n\n\"curNode\"\n\n\"node\"\n\nTail\n\n19\n\nWe can add them anywhere!!\n\u2022 This function has very consistent performance (constant time):\n\n\u2022 The append always allocates the same amount.\n\u2022 It always copies the same amount.\n\u2022 Compare to a big array where you may have to copy the entire thing to\nappend something new!\n\nTraversal... on the other hand...\n\u2022 Accessing an array element is generally very simple.\n\u2022\nis the same as\nbecause its location is very well-known!\n\u2022 This is because array items are continuous in memory. Not true for linked lists!\n\n\u2022 Here is a function that performs the equivalent for linked lists:\n\nQ: How many times is memory accessed relative to the requested index?\n\n21\n\nRemoving... on the other, other hand!\n\u2022 One nice thing about linked lists\nis their flexibility to changing\nshape.\n\u2022 I used to be able to bend a lot\nbetter, too, when I was in my 20s.\nAlas.\nCan't find item at index.\nWe are deleting the head.\n\n\u2022 Since we don't have a way to go\n\"backward\"\n\u2022 We first find the node we want to\ndelete (\n)\n\u2022 Keeping track of the node of\n- (\n)\n\u2022 Rewire\nto cut out\n.\n\nReturns new head (or old head if unchanged).\n\n22\n\nRemoving... on the other, other hand!\n\u2022 This looks complex, but it really is\na simple traversal.\n\u2022 So it takes O n to find the item.\n\u2022 And it performs a simple update\nand deallocation. (quick to do)\n\n\u2022 A big array, on the other hand.\n\u2022 It can find the element to remove\nimmediately.\n\u2022 However, removing it means\nshifting over every item after it left.\n\u2022 That can be an expensive update!\n(Memory is slow!!)\n23\n\nOn your own!\n\nThink about the code you would need to do any of the following:\n\u2022 Delete/free the entire linked list.\n\u2022 Sort a linked list.\n\u2022 Append a linked list to an existing one.\n\u2022 Copy a subset of a linked list to a new list.\nOften, operations can be abstracted in such a way that all of these can be written relatively\nsimply.\nConsider the performance of these operations compared to an Array.\n24\n\nLinked lists ... link you ... to the world!\n\u2022 Consider how much cleaner you can make certain operations if you tracked the\nprevious node as well.\n\u2022 This is a doubly linked list.\n\u2022 This is typically \"double-ended\" as well: keeping track of both head and tail.\n\nNode\n\nNode\n\nNode\n\n25\n\nSeeing the trees through the forest\n\u2022 A binary tree can be represented by the same nodes as a linked list.\n\u2022 In this case, you have a left and right child node instead of next and prev.\nNode\n\n\u2022 The operations are\nvery different, though.\n\nNode\n\nNode\n\nNode\n\n26\n\nDe-Stressing it out: Linked Lists\n\u2022 We know big arrays want to be continuous.\n\u2022 However, ensuring continuous space is difficult when you do\nnot know how much you will ultimately need.\n\n\u2022 Linked lists allocate very small chunks of metadata.\n\u2022 These chunks can be allocated easily on-demand.\n\u2022 And then deallocated without creating wide gaps.\n\nstack\n\navailable memory\n\n\u2022 This reduces fragmentation.\n\u2022 Deallocating always leaves a small amount of room.\n\u2022 It is always the exact amount needed to append!\n\u2022 However, it is all at the expense of complexity!\n\u2022 And traversal can be expensive (but we can find ways to deal\nwith that.)\n\nsome other data\n\nheap\n27\n\nImplementing Malloc\nIt really sounds like some kind of He-Man or She-Ra villain of the week.\n\n28\n\nThe malloc essentials\n\u2022 The\nfollowing:\n\nstack\n\nfunction does the\n\n\u2022 Allocates memory of at least\nbytes.\n\u2022 Returns the address to that block of memory (or\nerror)\n\non\n\navailable memory\n\n\u2022 Essentially, your program has a potentially large chunk of\nmemory.\n\u2022 The\nfunction tears off a piece of the chunk.\n\u2022 Also\nmust then allow that chunk to be reused.\n\u2022 The job of\nis to do so in the \"best\" way to reduce\nfragmentation.\nWe want to avoid fragmentation\n29\n\nChoosing where to allocate\n\u2022 Our first problem is, when\nwe tear off a chunk?\n\nis called, where do\n\n\u2022 We can do a few simple things:\n\u2022 First-Fit: start at lowest address, find first available section.\n\nstack\navailable memory\n\n\u2022 Fast, but small blocks clog up the works.\n\n\u2022 Next-fit: Do \"First-Fit\" but start where we last allocated.\n\u2022 Fast and spreads small blocks around a little better.\n\n\u2022 Best-Fit: laboriously look for the smallest available section to\ndivide up.\n\nLast Allocated\n\n\u2022 Slow, but limits fragmentation.\n\n???\n30\n\nManaging that metadata!\n\u2022 You have a whole section of memory to divide up.\n\u2022 You need to keep track of what is allocated and what is free.\n\u2022 One of the least complicated ways of doing so is to use... hmm...\n\u2022 A linked list! (or two!) We know how to do this!!\n\n\u2022 We can treat each allocated block (and each empty space) as a node in a linked\nlist.\n\u2022 Allocating memory is just appending a node to our list.\n\n\u2022 The trick is to think about how we want to split up the nodes representing\navailable memory.\n\n31\n\nTracking memory: Our fresh new world.\n\u2022 Let's orient our memory visually horizontally.\n\u2022 We have control over EVERY byte of it. We can place metadata ANYWHERE.\n\n\u2022 Every\n\nis responsible for allocating a block of memory.\n\n\u2022 How, then, do we manage where things are allocated and where is empty space?\n\u2022 We can have \"allocation\" reduce to creating a new node in a linked list.\n\navailable memory\n\nWe have the power to write data ANYWHERE!\nSo where do linked list nodes go?\n\n32\n\nLinked lists are our friend, here\n\u2022 We will augment our normal doubly linked list to be useful for tracking the size of\nthe block it represents. (an explicit list allocator)\n\u2022 Here, we will maintain a single linked lists of all allocated or free blocks.\n\u2022 The size field denotes how big the block is (how much is used/available.)\n\u2022 We need to know when a block represents allocated space or if it is free.\n\u2022 Hmm... we could use a single bit to denote that. Or... negativity!\n\u2022 The\n\nis NEVER\n\n. In fact,\n\nfails when requesting size of\n\n.\n\nAllocNode\n\nWe can make other clever\nspace optimizations, but we\nwill start with this.\n\nSigned! Negative number\nmeans a free block.\n\n33\n\nTracking memory: High level metadata\n\u2022 We can keep track of used/empty spaces cheaply by having linked list nodes\nat the beginning of them. The nodes track the size of the space.\n\u2022 Here we have an allocated block followed by a free and then allocated block.\n\u2022 The metadata for the linked list is just smashed into the block itself.\n\navailable memory\n\nQ: What happens when we write over the block boundary?\n\n34\n\nImplementing\n\u2022 To allocate some amount of space, we find a free block that is at least that\nsize + metadata size. (Which one? Well, first-fit and friends apply!)\n\u2022 Then we will want to split that free block.\nx\n\nx\n\nx\n\navailable memory\n\n35\n\nImplementing\nCarefully negate size\n\n\u2022 Allocating means finding a free\nblock big enough.\n\u2022 Including the metadata size.\n\n\u2022 Then splitting it into a used block\nand a smaller free block.\nLinked list traversal; O(n)\n\n\u2022 This is incomplete. (Why?)\n\nLinked list append; O(1)\n\n\u2022 (you don't always split)\n\nRecall that we made size\nnegative for a free block.\nPositive means non-free.\nis negative.\nThink about it!\nQ: This is first-fit. What should be added to implement next-fit? Best-fit?\n36\n\nImplementing\n\u2022 When freeing the middle block, you will create empty space.\n\u2022 Consider allocations... it's somewhat difficult to see the empty space.\n\u2022 You have \"false fragmentation,\" so you will want to merge adjacent free blocks.\n\navailable memory\n\n37\n\nImplementing\n\u2022 So, when we free blocks, we look to the left. We look to the right.\n\u2022 We coalesce the newly free block with ANY adjacent free blocks.\n\u2022 First one...\n\u2022 Then the other. (And it is linked list node removal; a constant time operation!)\n\navailable memory\n\n38\n\nImplementing\nHeader is just before ptr\n\n\u2022 Finding the header metadata\nnode is simple.\n\u2022 Look at our\n\n\u2022\n\n's\n\n.\n\nis slightly less complex.\n\u2022 It does not have to search.\n\n\u2022 Where\n\u2022\n\nResembles linked list\ndelete; O(1)\n\nsplits nodes\nmerges them.\n\n\u2022 Whenever a block is freed next\nto an existing one...\n\u2022 It should merge them!\n\nHowever it subtracts from size\n(which makes reflect a larger space)\n\n\u2022 Consider how much a doubly\nlinked list helped.\nQ: Are any changes required here for best-fit?\n\n39\n\nThinking about next-fit\n\n\u2022 With a typical first-fit version of the malloc function...\n\u2022 We can now consider simple improvements.\n\u2022 Traversing the list is expensive! O n !\n\n\u2022 Next-fit helps because we start from the last allocated item.\n\u2022 Generally, what do you think comes after the last allocated item.\n\u2022 Consider the normal operation...\n\u2022 It splits the node and creates free space.\n\n\u2022 Therefore, seems likely free space will exist near the last allocation.\n\u2022 Perhaps causing the average case for malloc to bias itself toward O(1)\n\u2022 However, all strategies have their own worst-case!!\n\u2022 Think about what that might be.\n\n40\n\nThinking about best-fit\n\u2022 Best-fit, on the other hand, is not about avoiding traversal.\n\u2022 Instead, we focus on fragmentation.\n\n\u2022 Allocating anywhere means worst-case behavior splits nodes poorly.\n\u2022 If we find a PERFECT fit, we remove fragmentation.\n\n\u2022 Traversal is still bad... and we brute force the search...\n\u2022 But, hey, solve one problem, cause another. That's systems!\n\u2022 Fragmentation may indeed be a major issue on small memory systems.\n\n\u2022 What is the best of both worlds? Next-fit + Best-fit?\n\u2022 Hmm.\n\u2022 Works best if you keep large areas open.\nCS/COE 0449 - Spring 2019/2020\n\n41\n\nOther thoughts\n\u2022 Don't need\npointers since adding size to the block's address will also\nmove there. (unusually, the linked list is always ordered!)\n\u2022 You don't need to keep the used blocks in the list.\n\u2022 More complex to understand but removes implementation complexity.\n\u2022 Free nodes point to the next and previous free nodes. Used nodes point to their\nneighbors. Traversal is improved since it only visits free nodes; still O(n)\n\n\u2022 The idea is to only keep track of necessary metadata.\n\u2022 You only coalesce when free blocks are adjacent.\n\u2022 With a list of only free blocks, you can easily tell when that condition is met...\n\u2022 just see if\n\nis the same address as\n\n\u2022 The only other concern is getting from a used block you want to free to its\nneighboring free block. So those have normal pointers.\n\n42\n\nExplicit free lists: giving you VIP access\n\u2022 When you allocate, you go through the free list.\n\u2022 You don't care about allocated nodes.\n\n\u2022 When you free, you only care about coalescing neighbors.\n\navailable memory\n\nQ: Do free nodes need a\n\npointer?\n\n43\n\nTrees are your buddy\n\n\u2022 Recall that we easily took the ideas around linked lists and made binary trees.\n\u2022 You can manage memory with a binary tree as well.\n\n\u2022 This is called a buddy allocator.\n\n45\n\nDivide and conquer\n\u2022 Buddy allocators divide memory into halves that are powers of two.\n\u2022 Can cause internal fragmentation\n\n\u25aa The total memory,\n, is a\npower of two.\n\u25aa Each split is, then, also a\npower of two.\n\nAllocation is not a power of two: internal fragmentation\n\n46\n\nAllocating with trees\n\u2022 Assuming\n\nis\n\n, and we allocate 242MiB:\n\n\u2022 We travel left until we find a block\nthat fits.\n\n\u25aa We travel back up when we can't go\nfurther left and go right.\n\u25aa When we find a\nunsplit node that\nfits, we allocate\nthere.\n\n47\n\nBurying the hatchet: Chopping the trees\n\u2022 Let's allocate 64MiB. So nice, we will allocate it twice.\n\u2022 Again a depth-first search to find\nthe first unsplit node that fits us.\n\n\u25aa This node is fine! Allocate that!\n\u25aa Do it again!\n\u25aa When we find a\nunsplit node that is\ntoo big, we split in\nhalf and keep going.\n\nCS/COE 0449 - Spring 2019/2020\n\n48\n\nCoalescing friendships (animated)\n\u2022 Coalescing happens because every block has a buddy!\n\u2022 When both sides of a split node\nare free, coalesce them!\n\n\u25aa If this keeps happening, it will\ncoalesce larger spaces.\n\u25aa Repeating as\nmuch as\nnecessary.\n\nx\n\nx\n\nx\n49\n\nThinking like an arborist (but only if you are feeling listless)\n\u2022 How does a tree-based\nallocation system deal with\nfragmentation?\n\u2022 What are some immediate\ndrawbacks from using a\ntree scheme?\n\navailable\nmemory\n\n\u2022 Can you imagine a\npossibility of using a\nhybrid approach?\n50\n\nLies and Damned Lies!\n\u2022 Does your program actually own all of memory?\n\u2022 On modern systems, absolutely heckin not.\n\n\u2022 Your program still has to request memory allocations from the OS.\n\u2022 Generally,\ntakes on this responsibility behind the scenes.\n\u2022 In Linux, you request pages in the normal heap in LIFO order with\n\u2022 Or, you request specific virtual memory pages with\n.\n\n.\n\n\u2022 What is a segmentation fault.\n\u2022 Segments are the \"code\", \"data\", \"heap\" separation. You fault by doing something\nthe segment does not allow. (write to read-only memory)\n\u2022 A historic misnomer since we actually have paging, not segmented memory.\n\n\u2022 What is a \"page\"? Virtual memory??\n\u2022 It replaced segments and is part of the much grander lie about sharing memory\nwith multiple applications at the same time. More on this later!\n\n51\n\nI want to know MORE\n\u2022 If you find this topic interesting, it is a WIDE area of research.\n\u2022 Malloc is generally more complex or specialized these days than the options\nhere.\n\u2022 Or some kind of hybrid, as the need arises.\n\n\u2022 The Linux kernel makes use of a Slab Allocator\n\u2022 https://en.wikipedia.org/wiki/Slab_allocation\n\n\u2022 Modern C (glibc) uses a hybrid malloc:\n\u2022 https://www.gnu.org/software/libc/manual/html_node/The-GNU-Allocator.html\n\n\u2022 Professor Knuth has written about several classic algorithms.\n\u2022 Buddy Allocation comes from the 60s. Groovy.\n52\n\n", "label": [[189, 202, "Concept"], [279, 283, "Concept"], [494, 498, "Concept"], [974, 978, "Concept"], [1679, 1683, "Concept"], [2065, 2069, "Concept"], [2476, 2480, "Concept"], [2810, 2814, "Concept"], [3231, 3235, "Concept"], [3452, 3456, "Concept"], [7541, 7545, "Concept"], [18260, 18264, "Concept"], [286, 297, "Concept"], [481, 492, "Concept"], [961, 972, "Concept"], [1666, 1677, "Concept"], [2053, 2064, "Concept"], [2464, 2475, "Concept"], [2798, 2809, "Concept"], [3219, 3230, "Concept"], [3440, 3451, "Concept"], [300, 305, "Concept"], [431, 436, "Concept"], [911, 916, "Concept"], [1103, 1108, "Concept"], [1268, 1273, "Concept"], [1837, 1842, "Concept"], [2006, 2011, "Concept"], [2241, 2246, "Concept"], [2499, 2504, "Concept"], [2839, 2844, "Concept"], [3261, 3266, "Concept"], [3623, 3628, "Concept"], [4153, 4158, "Concept"], [4724, 4729, "Concept"], [8797, 8802, "Concept"], [9246, 9251, "Concept"], [9858, 9863, "Concept"], [308, 312, "Concept"], [387, 391, "Concept"], [476, 480, "Concept"], [587, 591, "Concept"], [956, 960, "Concept"], [1079, 1083, "Concept"], [1276, 1280, "Concept"], [1661, 1665, "Concept"], [1997, 2001, "Concept"], [2048, 2052, "Concept"], [2459, 2463, "Concept"], [2793, 2797, "Concept"], [2949, 2953, "Concept"], [3214, 3218, "Concept"], [3435, 3439, "Concept"], [3537, 3541, "Concept"], [3919, 3923, "Concept"], [4496, 4500, "Concept"], [5116, 5120, "Concept"], [9099, 9103, "Concept"], [18125, 18129, "Concept"], [18276, 18280, "Concept"], [2225, 2238, "Concept"], [3904, 3917, "Concept"], [8837, 8850, "Concept"], [9607, 9620, "Concept"], [9639, 9652, "Concept"], [10160, 10173, "Concept"], [13138, 13151, "Concept"], [14723, 14736, "Concept"], [14846, 14859, "Concept"], [14987, 15000, "Concept"], [16555, 16568, "Concept"], [16699, 16712, "Concept"], [17677, 17690, "Concept"], [2881, 2896, "Concept"], [13132, 13151, "Concept"], [16546, 16568, "Concept"], [16690, 16712, "Concept"], [3098, 3116, "Concept"], [5681, 5688, "Concept"], [16234, 16241, "Concept"], [3503, 3508, "Concept"], [3615, 3620, "Concept"], [3725, 3730, "Concept"], [3838, 3843, "Concept"], [3869, 3874, "Concept"], [5014, 5019, "Concept"], [6206, 6211, "Concept"], [6331, 6336, "Concept"], [6447, 6452, "Concept"], [7309, 7314, "Concept"], [7902, 7907, "Concept"], [4759, 4770, "Concept"], [4940, 4951, "Concept"], [5129, 5140, "Concept"], [5182, 5193, "Concept"], [5199, 5210, "Concept"], [5295, 5306, "Concept"], [7614, 7625, "Concept"], [7636, 7647, "Concept"], [7660, 7671, "Concept"], [7713, 7724, "Concept"], [8078, 8089, "Concept"], [8289, 8300, "Concept"], [10395, 10406, "Concept"], [11051, 11062, "Concept"], [11137, 11148, "Concept"], [11234, 11245, "Concept"], [11934, 11945, "Concept"], [12119, 12130, "Concept"], [12672, 12683, "Concept"], [12731, 12742, "Concept"], [13418, 13429, "Concept"], [13684, 13695, "Concept"], [13915, 13926, "Concept"], [15313, 15324, "Concept"], [5343, 5347, "Concept"], [5480, 5484, "Concept"], [5510, 5514, "Concept"], [5657, 5661, "Concept"], [5737, 5741, "Concept"], [5823, 5827, "Concept"], [5848, 5852, "Concept"], [5975, 5979, "Concept"], [5994, 5998, "Concept"], [6964, 6968, "Concept"], [7014, 7018, "Concept"], [8045, 8049, "Concept"], [8173, 8177, "Concept"], [8179, 8183, "Concept"], [8185, 8189, "Concept"], [8350, 8354, "Concept"], [8381, 8385, "Concept"], [8433, 8437, "Concept"], [8439, 8443, "Concept"], [8445, 8449, "Concept"], [10508, 10512, "Concept"], [10571, 10575, "Concept"], [11041, 11045, "Concept"], [13430, 13434, "Concept"], [13565, 13569, "Concept"], [14342, 14346, "Concept"], [16923, 16927, "Concept"], [17118, 17122, "Concept"], [17145, 17149, "Concept"], [17214, 17218, "Concept"], [17423, 17427, "Concept"], [5702, 5706, "Concept"], [6892, 6896, "Concept"], [7063, 7067, "Concept"], [7076, 7080, "Concept"], [8157, 8161, "Concept"], [5840, 5844, "Concept"], [6001, 6005, "Concept"], [8166, 8170, "Concept"], [4952, 4961, "Concept"], [6282, 6291, "Concept"], [7187, 7196, "Concept"], [9012, 9021, "Concept"], [12684, 12693, "Concept"], [14689, 14698, "Concept"], [14864, 14873, "Concept"], [15560, 15569, "Concept"], [7272, 7284, "Concept"], [8071, 8089, "Concept"], [11227, 11245, "Concept"], [8235, 8246, "Concept"], [16383, 16394, "Concept"], [16424, 16439, "Concept"], [9121, 9127, "Concept"], [9210, 9216, "Concept"], [14054, 14060, "Concept"], [14485, 14491, "Concept"], [18733, 18739, "Concept"], [18993, 18999, "Concept"], [1239, 1243, "Concept"], [2553, 2557, "Concept"], [3856, 3860, "Concept"], [7598, 7602, "Concept"], [10317, 10321, "Concept"], [11405, 11409, "Concept"], [11564, 11568, "Concept"], [11821, 11825, "Concept"], [12065, 12069, "Concept"], [12308, 12312, "Concept"], [12445, 12449, "Concept"], [12553, 12557, "Concept"], [12660, 12664, "Concept"], [12825, 12829, "Concept"], [12856, 12860, "Concept"], [13189, 13193, "Concept"], [13252, 13256, "Concept"], [13332, 13336, "Concept"], [13361, 13365, "Concept"], [14359, 14363, "Concept"], [14398, 14402, "Concept"], [15469, 15473, "Concept"], [15511, 15515, "Concept"], [15603, 15607, "Concept"], [15708, 15712, "Concept"], [15756, 15760, "Concept"], [15924, 15928, "Concept"], [15948, 15952, "Concept"], [16005, 16009, "Concept"], [16079, 16083, "Concept"], [16142, 16146, "Concept"], [16215, 16219, "Concept"], [17432, 17436, "Concept"], [4928, 4936, "Concept"], [5325, 5333, "Concept"], [5356, 5364, "Concept"], [8685, 8693, "Concept"], [10198, 10206, "Concept"], [10831, 10839, "Concept"], [11866, 11874, "Concept"], [12102, 12110, "Concept"], [12348, 12356, "Concept"], [12592, 12600, "Concept"], [13556, 13564, "Concept"], [15673, 15681, "Concept"], [13508, 13514, "Concept"], [13549, 13555, "Concept"], [11821, 11831, "Concept"], [12308, 12318, "Concept"], [12445, 12455, "Concept"], [12660, 12670, "Concept"], [12825, 12835, "Concept"], [13332, 13342, "Concept"], [15948, 15958, "Concept"], [10464, 10479, "Concept"], [12035, 12050, "Concept"], [12079, 12094, "Concept"], [16079, 16088, "Concept"], [11313, 11336, "Concept"], [9791, 9800, "Concept"], [9943, 9952, "Concept"], [12381, 12390, "Concept"], [12902, 12911, "Concept"], [14029, 14038, "Concept"], [9929, 9937, "Concept"], [12947, 12955, "Concept"], [14002, 14010, "Concept"], [14161, 14169, "Concept"], [15090, 15098, "Concept"], [10048, 10056, "Concept"], [12957, 12965, "Concept"], [13972, 13980, "Concept"], [14627, 14635, "Concept"], [14638, 14646, "Concept"], [15101, 15109, "Concept"], [16168, 16178, "Concept"], [17306, 17316, "Concept"], [17342, 17352, "Concept"], [18220, 18238, "Concept"], [18468, 18472, "Concept"], [18424, 18430, "Concept"], [18176, 18190, "Concept"], [18475, 18489, "Concept"], [18896, 18910, "Concept"], [18972, 18977, "Concept"]]}