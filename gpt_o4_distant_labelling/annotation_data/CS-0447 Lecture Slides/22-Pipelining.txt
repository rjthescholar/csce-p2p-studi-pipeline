#16
CS 0447
Introduction to
Computer Programming

Pipelining

LuÃ­s Oliveira

Fall 2020

Announcements
â— OMETS!!!!!!!!11!!!!!!!!!1!!!1eleven!!!!

2

How can we make the CPU
more efficient? â€¦

P

3

Doing the laundry
Luis (me), Artur, Stephen, and Ray have one load of clothes to
o Wash
Washer takes 60 minutes

o Dry
o Fold

Dryer takes 60 minutes

Folding takes 60 minutes

Where we live, we can only do laundry Saturday from 9:00 to 18:00!
4

Sequential laundry
â— We have four loads of laundry to do (Luis, Artur, Stephen, and Ray)

First, I wash

9:00

10:00 11:00 12:00 13:00 14:00 15:00 16:00 17:00

Then, I dry

Finally, I fold

It took me 3:00, we
still have three
loads remaining!
Yikes!

Itâ€™s 15:00, we still
have two loads to go

Itâ€™s 18:00, and Ray
cannot do his laundry!
5

How can we solve this?
â— Buy more machines!!!

â— Orâ€¦
6

Pipelined laundry
â— We have four loads of laundry to do (Luis, Artur, Stephen, and Ray)
9:00

10:00 11:00 12:00 13:00 14:00 15:00 16:00 17:00

But did the time it
takes to wash the
clothes change?

The washer is now
free!!

We can start the
next load!

Everyone can do
their laundry

Rinse and
repeat
7

Upgrading the multi-cycle CPU
Letâ€™s apply the same concept to a multi-cycle CPU!
Keep the same clock
â— Reuse resources with â€¦

Time

0

1

add t2,t2,t3

Mem

Reg

lw t0,0(t1)

2

3

4

5

Mem

Reg

6

7

Reg

Mem

Reg

8

Lighting up the silicon (animated)
Executing instructions in a pipeline
F
D

X

M

Memory

Control

sub
add
sw
Register
File

Memory
again

W
Uses
memory

Uses decoder/registers

Uses ALU

Uses
memory
9

Pipeline vs Multi-cycle
Pipelining doesnâ€™t help latency of a single instruction!
It helps throughput of the entire workload!
Different tasks operating different resources
can execute simultaneously
More stages, more potential speedup (too many stages is not good!)
Time

0

1

add t2,t2,t3

Mem

Reg

lw t0,0(t1)

Mem

2

3

4

5

Mem

Reg

6

7

Reg

Reg

10

So how did we improve performance?
â— Did we make any individual instruction faster?
o No, the add still took 4 cyclesâ€¦ the lw took 5 cycles
â— But the whole thing finished faster. right?
Yes, by overlapping the instructions,
we increased the throughput.
In any given clock cycle, we're
now doing more work.
With this we can get the CPI
down closer to 1.
11

The average CPI
â— Itâ€™s the average number of Cycles Per Instruction
o For any program, we count the # of cycles
â–ª and divide by the # of instructions
Time

0

1

add t0,t1,t2

Mem

Reg

add t3,t4,t5

Mem

2

3

Reg

5

6

7

CPI = 7 Ã· 4
= 1.75

Reg

Reg

Mem

Reg

What
happens when we have an
add s3,s4,s5
infinite number of instructions?

Mem

add s0,s1,s2

4

Reg

Reg

Reg

12

Pipeline (real-world) issues

13

Instructions are co-dependent ïŒ
â— Sometimes, the next instruction cannot execute in the next cycle
o We call those pipeline hazards.
â— Hazards happen when for any reason an instruction is unable to advance
(execute) in the pipeline
â— Weâ€™ll look at three types of hazards
o Structural hazards
o Data hazards
o Control hazards

14

Structural hazards
Attempting to use the same resource two different ways simultaneously. E.g.:
â— You get home soaking wet and need to dry your clothes while someone is
using the dryer
In a CPU with a single memory:
â— Can we fetch a new instruction while reading a word from memory?
o NOPe: structural hazard

15

Structural hazards
â— Two instructions using the same hardware at the same time
Time

0

1

lw t0,0($0)

Mem

Reg

lw t1,4($0)

lw t2,8($0)

lw t3,12($0)

Mem

2

3

4

Mem

Reg

Mem

Reg

Mem

Reg

6

7

Reg

Mem

Reg

Mem

5

Reg

Mem

Reg

16

Structural hazards â€“ What can I do???
â— Structural hazards arise from lack of resources
â— Soâ€¦ We can eliminate the hazard by adding more resources!
o Add a second memory?
â–ª The Harvard architecture!
â— Another solution:
o Stall the instruction until the resource is available
Time

lw t3,12($0)

0

1

2

3

4

5

6

7

NOP

NOP

NOP

NOP

NOP

Mem

Reg

Mem

Reg
17

Structural hazards â€“ What can I do???
â— You may need more than one stall!
Time

0

1

lw t0,0($0)

Mem

Reg

lw t1,4($0)

lw t2,8($0)

lw t3,12($0)

Mem

2

3

4

Mem

Reg

Mem

Reg

Mem

Reg

5

6

7

Reg

Mem

Reg

NOP

NOP

NOP

NOP

NOP

NOP

NOP
NOP

NOP
NOP

NOP

NOP
NOP

NOP

NOP

NOP

NOP

NOP

Mem

Reg

Mem

Reg

18

Data hazards
Attempting to use an item before it is ready. E.g.:
â— Only one sock of a pair is found during folding
â— Itâ€™s in the dryer! Folding has to wait!

In a CPU:
â— Instruction depends on result of prior instruction still in the pipeline
add s0, t0, t1
sub t2, t2, s0

s0 must be produced before it can
be used

19

Data hazards â€“ What can I do???
â— Are these common?
o Yup! You bet!
i=i+1
array[i]

â— Solution 1: Stall until value is written back to the register file
o Penalty is high with this solution.
Time

0

1

add s0,t0,t1

Mem

Reg

sub t2,t2,s0

NOP

2

3

4

5

6

7

Reg

NOP

Mem

Reg

Reg
20

Data hazards â€“ What can I do???
â— Solution 2: What if we improve the register file?

Write to the register on
the falling edge

Time

0

1

add s0,t0,t1

Mem

Reg

sub t2,t2,s0

NOP

2

Read register during
the second half

Register
File

3

4

5

6

7

W
Reg

Mem

RegR

Reg
21

Data hazards â€“ What can I do???
â— Solution 3: Can we forward the ALU output?
o Add path from ALU output to one of its inputs
Forwarding: Passing the result from a
later stage to an earlier one

Time

0

1

add s0,t0,t1

Mem

Reg

sub t2,t2,s0

Mem

2

3

4

Reg

Reg

Reg

5

6

7

The value needed by the
sub isnâ€™t read from the reg
file - it comes directly from
the result output from
doing the add operation
22

Control hazards
Attempting to make a decision before condition is evaluated
â— If the dirty clothes are not clean after washing!
â— Then I must wash them again
In a CPU:
â— Branches
blt s0, s1, DONE
add t0, t1, t2
or t0, t1, t2
DONE:
sub t0, t1, t2

Which path will the
program take?
Which instruction do
we fetch next?

23

Control hazards
Attempting to make a decision before condition is evaluated
â— If the dirty clothes are not clean after washing!
â— Then I must wash them again
In a CPU:
â— Branches
if s0 < s1 goto DONE
add t0, t1, t2
or t0, t1, t2
DONE:
sub t0, t1, t2

Which path will the
program take?
Which instruction do
we fetch next?

24

Control hazards â€“ What can I do???
â— We can stallâ€¦ until the outcome is known!
Time

0

1

blt s0,s1,DONE

Mem

Reg

sub t0,t1,t2

NOP

2

3

4

NOP

Mem

Reg

5

6

7

Reg

â— This is a bit wasteful! We really donâ€™t like stalls! â˜º
â— We want the pipeline always full and doing useful work!
25

Control hazards â€“ What can I do???
â— Soooâ€¦ we can predict that the branch is never taken! (naÃ¯ve)
Time

0

1

blt s0,s1,DONE

Mem

Reg

add t0,t1,t2

Mem

2

Reg

3

4

5

6

7

Reg

â— We attempt to execute the next sequential instruction!
â— It is a gamble! that the branch will never be taken.
â— But if we are right, there is no stall!!! â˜º
26

Control hazards â€“ What if we are wrong?????!!!
â— Ok, what if we are wrong???!!
Time

0

1

blt s0,s1,DONE

Mem

Reg

add t0,t1,t2

or t0,t1,t2

sub t0,t1,t2

Mem

2

3

4

Reg

NOP

NOP

Mem

NOP

NOP

Mem

Reg

5

6

7

NOP

Reg

â— Just abort (stall the remaining steps) to fix it! Nothing was actually changed!
â— Read the correct instruction!

27

Fun facts!
â— How often do you think a (less-naÃ¯ve) branch predictor is correct?
Using 128 Bytes all these predictors
have an accuracy of >90%!!!

McFarling, Scott. Combining branch predictors. Vol. 49. Technical
Report TN-36, Digital Western Research Laboratory, 1993.

28

What to know more?
â— CS 1541 â€“ Introduction to Computer Architecture
o Learn more about hazards.
o Learn more about branch predictors.
o Learn about memory hierarchies.
o And moreâ€¦

29

Performance and
The Law of Diminishing Returns

30

Don't waste your time...
â— suppose you're trying to get better at time management
â— you got an app that lets you time how long you do stuff
if you wanted to get
more free time by
halving the amount of
time it takes to do one
task, which task would
you choose?

Commuting

Hygiene

Watching
Youtube

Meals

Working
31

If you cut Youtube by half...
â— look at all the extra free time you have!
Hygiene
Commuting

Free time!

Meals

Watching
Youtube

Working

32

If you cut commuting by half...
â— look at ... all the extra free time... you have.
Free time!
Hygiene
Commuting

Watching
Youtube

Meals

Working

33

The tale of two multipliers
â— The tale starts with a simple program
li

$1, 100

lw
lw
mult
mflo
sw
addi
bne

$2, A[i]
$3, B[i]
$3, $2
$4
$4, C[i]
$1, $1, -1
$1, $0, L0

L0:
; pseudo-code to load A[i]
; pseudo-code to load B[i]

; pseudo-code to store C[i]

â— How many times does the loop execute?

Runs 100 times

34

The tale of two multipliers
â— You measure how long it takes to execute.
o It took 102010ns
li

$1, 100

10ns

L0:
lw
lw
mult
mflo
sw
addi
bne

Thatâ€™s too long!

$2, A[i]
$3, B[i]
$3, $2
$4
$4, C[i]
$1, $1, -1
$1, $0, L0

10ns
10ns
960ns
10ns
10ns
10ns
10ns

I need to improve this,
what should I do?

Let me check what is
going on here!

96000ns!!!
ğ‘¡ğ‘–ğ‘šğ‘’ = 1 Ã— 10ğ‘›ğ‘  +
6 Ã— 100 Ã— 10ğ‘›ğ‘  +
1 Ã— 100 Ã— 960ğ‘›ğ‘  = 102010ğ‘›ğ‘ 
35

The tale of two multipliers
â— It seems this CPU implements a slow multiplier
o It needs to execute 3 distinct steps:
(1) add, (2) shift left, and (3) shift right
o Multiplication takes 32-bit numbers
â–ª The ALU and the adder are 64-bits!
o The 64-bit addition takes 10ns
o Shifts also take 10ns
o The multiplication takes 96 steps â†’ 3 Ã— 32bits

What if I used another
multiplier design?

â–ª total = 96 steps Ã— 10ğ‘›ğ‘  = 960ğ‘›ğ‘ 

36

The tale of two multipliers
â— I know, letâ€™s use a Fast multiplier design I have
1. It combines some registers
2. And we can make it do the 3 steps simultaneously
3. And the ALU only needs to be 32-bits!

o Assuming a linear relationship between bits and adder speed:
â–ª The 32-bit addition takes 5ns
o The multiplication takes 32 steps â†’ 1(ğ‘ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘’ğ‘‘) Ã— 32bits
â–ª total = 32 steps Ã— 5ğ‘›ğ‘  = 160ğ‘›ğ‘ 
Cool! Thatâ€™s a lot
faster!!

37

The tale of two multipliers
â— Letâ€™s calculate how much faster it is:
o Letâ€™s calculate the speedup ratio:
â–ª The factor by which the new version is faster than the old one

slow multiplier time 960ğ‘›ğ‘ 
speedup =
=
=6Ã—
ğ‘“ğ‘ğ‘ ğ‘¡ ğ‘šğ‘¢ğ‘™ğ‘¡ğ‘–ğ‘ğ‘™ğ‘–ğ‘’ğ‘Ÿ ğ‘¡ğ‘–ğ‘šğ‘’ 160ğ‘›ğ‘ 
But will the program
improve that much?

38

The tale of two multipliers
ğ‘¡ğ‘–ğ‘šğ‘’ = 1 Ã— 10ğ‘›ğ‘  +
6 Ã— 100 Ã— 10ğ‘›ğ‘  +
1 Ã— 100 Ã— 160ğ‘›ğ‘  = 22010ğ‘›ğ‘ 

slow program 102010ğ‘›ğ‘ 
ğ¬ğ©ğğğğ®ğ© =
=
ğ‘“ğ‘ğ‘ ğ‘¡ ğ‘ğ‘Ÿğ‘œğ‘”ğ‘Ÿğ‘ğ‘š
22010ğ‘›ğ‘ 
= ğŸ’. ğŸ”ğŸ‘ Ã—

It still an improvement!
But not 6x. Why?

â— The multiplier is only used once!

39

The tale of two multipliers
â— What happens if we decrease the proportion of execution time?
Suppose 101 instructions: 100 non-multiply, 1 multiply
ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘ ğ‘™ğ‘œğ‘¤ = 100 Ã— 10ğ‘›ğ‘  + 960ğ‘›ğ‘  = 1960ğ‘›ğ‘ 
ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘“ğ‘ğ‘ ğ‘¡ = 100 Ã— 10ğ‘›ğ‘  + 160ğ‘›ğ‘  = 1160ğ‘›ğ‘ 
1960ğ‘›ğ‘ 
ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¢ğ‘ =
= 1.7 Ã—
1160ğ‘›ğ‘ 
Suppose 1001 instructions: 1000 non-multiply, 1 multiply
ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘ ğ‘™ğ‘œğ‘¤ = 1000 Ã— 10ğ‘›ğ‘  + 960ğ‘›ğ‘  = 10960ğ‘›ğ‘ 
ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘“ğ‘ğ‘ ğ‘¡ = 1000 Ã— 10ğ‘›ğ‘  + 160ğ‘›ğ‘  = 10160ğ‘›ğ‘ 
10960ğ‘›ğ‘ 
ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¢ğ‘ =
= 1.08 Ã—
10160ğ‘›ğ‘ 

40

Decreasing gains
â— 6 Ã—â†’ 4.63 Ã—â†’ 1.7 Ã—â†’ 1.08 Ã—

â— What happened?
o Proportion of time spent multiplying was not enough to have gains
â— Optimization is a balancing act.
o As you solve a bottleneck, a new one will appear.
o Improve things to a point, then there are diminishing returns!
5s

4s

3s

2s

4s

3s

2s

3s

3s
41

What about pipelining?
â— How much faster (and why) is a pipelined implementation of MIPS?
â— As we saw last class, we compute the speedup for this:

slow time
speedup =
ğ‘“ğ‘ğ‘ ğ‘¡ ğ‘¡ğ‘–ğ‘šğ‘’
â— And how do we compute â€œtimeâ€?
CPU time = ğ‘› Ã— ğ¶ğ‘ƒğ¼ Ã— ğ‘¡ seconds

42

Average Instruction CPI
â— What is an â€œaverage instructionâ€ CPI?
o Remember how we calculated the average CPI of a program?
â— Given a program, how many cycles does an instruction typically take?
o It depends on the program!
o How many instructions, and what types?
â–ª E.g.: all adds vs. all loads for multi-cycle implementation

â— The average instruction CPI is the average cycle count per instruction

43

Instruction Mix
â— Instruction mix: Is the % total instruction count (n) corresponding to each
instruction class
â— Program A: 100 adds, 100 subtracts, 50 loads, 25 stores, 50 branches, and 10
jumps. Total 335 instructions.

â— What is the mix?
Arithmetic

(100+100) / 335 =

0.597 =

59.7%

Load

50 / 335 =

0.149 =

14.9%

Store

25/335 =

0.075 =

7.5%

Branch

50/335 =

0.149 =

14.9%

Jump

10/335 =

0.03 =

3.0%

44

CPI â€“ Multi-cycle
â— Given this mix, what is the Average Cycles Per Instruction (CPI)?
o E.g., with a multi-cycle CPU.
â— We compute the weighted average
CPI= Î£ğ‘ğ‘™ğ‘™ ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘  ğ‘“ğ‘Ÿğ‘’ğ‘ Ã— ğ‘ğ‘¦ğ‘ğ‘™ğ‘’ğ‘ 
Class

Frequency

Cycles

Contribution

Arithmetic

59.7%

4

2.388

Load

14.9%

5

0.745

Store

7.5%

4

0.3

Branch

14.9%

3

0.447

Jump

3.0%

3

0.09

Total

3.97 CPI
45

CPU time
â— And now we can calculate the CPU time
o Assuming a cycle length of 2ns
CPU time = 335 Ã— 3.97 Ã— 2ğ‘›ğ‘ 
= 2660ğ‘›ğ‘ 
Class

Frequency

Cycles

Contribution

Arithmetic

59.7%

4

2.388

Load

14.9%

5

0.745

Store

7.5%

4

0.3

Branch

14.9%

3

0.447

Jump

3.0%

3

0.09

Total

3.97 CPI
46

What about in the pipeline implementation?
â— In the best case, what is the CPI?
o How many instructions are we starting every clock cycle?
â— What about the typical case, what is the CPI?
o We have to consider hazards.
o Say, 20% of branches are predicted correctly.
o 60% of loads do not conflict with other memory accesses.

â— Assume the same program and clock cycle.

47

Instruction Mix â€“ Pipeline
â— Instruction mix: Treat the delayed load and branch instructions as a separate
class
Class
Arithmetic

Frequency

Cycles

59.7%

1

0.6*14.9%=8.94%

1

Load â€“ delay

5.96%

2

Store

7.5%

1

0.2*14.9%=2.98%

1

11.92%

3

3.0%

1

Load â€“ no delay

Branch predicted
Branch not predicted
Jump

48

CPI â€“ Pipeline
â— We compute the weighted average
CPI= Î£ğ‘ğ‘™ğ‘™ ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘  ğ‘“ğ‘Ÿğ‘’ğ‘ Ã— ğ‘ğ‘¦ğ‘ğ‘™ğ‘’ğ‘ 
Class

Cycles

Contribution

59.7%

1

0.597

0.6*14.9%=8.94%

1

0.0894

Load â€“ delay

5.96%

2

0.1192

Store

7.5%

1

.075

0.2*14.9%=2.98%

1

.0298

11.92%

3

0.3576

3.0%

1

0.03

Arithmetic
Load â€“ no delay

Branch predicted
Branch not predicted
Jump

Frequency

Total

1.30 CPI

49

The speedup
â— Compute CPU execution time of pipelined implementation
o Every value except CPI is the same as in the multi-cycle
â–ª n â€“ is a property of the program

Pipeline CPU time = 335 Ã— 1.30 Ã— 2ğ‘›ğ‘ 
= 871ğ‘›ğ‘ 

2660ğ‘›ğ‘ 
speedup =
= 3.05 Ã—
871ğ‘›ğ‘ 

50

