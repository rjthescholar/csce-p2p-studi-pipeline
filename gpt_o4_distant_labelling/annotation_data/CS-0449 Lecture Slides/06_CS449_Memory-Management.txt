6

Memory
Management

CS/COE 0449
Introduction to
Systems Software

Luis Oliveira
(with content borrowed from wilkie and Vinicius Petrucci)

Our Story So Far
You Hear a Voice Whisper: ‚ÄúThe Memory Layout is a Lie‚Äù

2

Reallocating our thoughts
‚Ä¢ A program has several sections:
‚Ä¢ Code
‚Ä¢ Static data
‚Ä¢ Stack
‚Ä¢ Heap

‚Ä¢ Today, we take a deeper dive at how dynamic
memory is allocated in the heap.

Potential Layout
(32-bit addresses)

stack
currently unused but
available memory

heap
static data

code
3

Reallocating our thoughts
‚Ä¢ We have looked at

and

.

‚Ä¢ They stake out space in the heap and return an
address.
‚Ä¢ Right now, we live in a nice ideal world.
‚Ä¢ No other programs are running.
‚Ä¢ We have access to all of the memory.
‚Ä¢ Muhahahaha!!

‚Ä¢ The OS is lying to our program.
‚Ä¢ This memory is‚Ä¶ virtual... reality.
‚Ä¢ We will investigate this lie later in the course.

Potential Layout
(32-bit addresses)

stack
currently unused but
available memory

heap
static data

code
4

The World of Allocation
It is a puzzle without any optimal solution. Welcome to computers!

5

A heap of possibilities
‚Ä¢ Stack access often does not deviate much.

Potential Layout
(32-bit addresses)

‚Ä¢ We allocate a little bit at a time.
‚Ä¢ We allocate and free the memory VERY often.

stack
‚Ä¢ Heap allocations have many access patterns that are
possible.
‚Ä¢ You might allocate a lot at a time and keep it around for a
long time. Or a short time.
‚Ä¢ You might allocate a lot of small things, instead.
‚Ä¢ Maybe you do a little bit of everything?

‚Ä¢ Often, such patterns are not easy to predict.
‚Ä¢ Do you get a big file as input? A small file?

currently unused but
available memory

heap
static data

code
6

A heaping helping of good luck
‚Ä¢ Allocations could happen in a nice order.
‚Ä¢ When something is allocated, it can be allocated
after everything else.

stack

available memory
available memory
available memory

‚Ä¢ When freed, it makes room for new things.

‚Ä¢ IF ONLY.
‚Ä¢ I mean, it‚Äôs possible‚Ä¶ but like‚Ä¶
‚Ä¢ the heap and stack are different things for a reason.

heap
static data
code
7

Digital potholes‚Ä¶ as annoying as real ones
‚Ä¢ Small allocations interfere with large ones.
‚Ä¢ When small gaps interfere with allocation, this is
called fragmentation.

stack
available memory
available memory
available
available memory
memory
available memory

Next
Allocation

Ugh

?
if we had omniscience of future
allocations, we could avoid this‚Ä¶
but we can‚Äôt know ahead of time!

heap
static data
code
8

The worst case
stack

‚Ä¢ When you allocate a lot of small things‚Ä¶
‚Ä¢ Free every other one‚Ä¶
‚Ä¢ And then attempt to allocate a bigger thing‚Ä¶

‚Ä¢ Even though there is technically enough memory‚Ä¶
‚Ä¢ There is no continuous space.
‚Ä¢ Therefore, our na√Øve
will fail.

‚Ä¢ We have to come up with some strategy.

???

heap
static data
code
9

Moving is never easy
stack

‚Ä¢ Why not move things around??
‚Ä¢ A defragmentation process/algorithm

‚Ä¢ Moving around something in the heap is hard!
‚Ä¢ Any pointers referring to data within a block must be updated.
‚Ä¢ Finding these pointers automatically is effectively as difficult
as garbage collection.

‚Ä¢ Because of this, moving blocks around is discouraged.
(Easier to solve it another way.)
???

heap
static data
code
10

Moving is NEVER easy
stack
available memory

‚Ä¢ When blocks move, pointers
to anything within them must be updated.
‚Ä¢ This is hard to keep track of!
‚Ä¢ C does not check validity of pointers after

heap
static data
code
11

Stressing it out
‚Ä¢ If we allocate a large array it will be allocated on the
heap somewhere.
‚Ä¢ Other allocations can also happen, and they go ‚Äúabove‚Äù
that array.

stack

available memory

int arr[200]

‚Ä¢ What happens when you need to append a 101st
element to this array?
‚Ä¢ Uh oh!
old
data:
int arr[100]
int
arr[100]

‚Ä¢ You will need to allocate more space.
‚Ä¢ And then copy the array contents.
‚Ä¢ Free the old array.
‚Ä¢ How long does that take?

fragmentation

heap
12

Stressing it out: Big Arrays
‚Ä¢ This happens in very practical situations!
‚Ä¢ Reallocating means getting rid of a small thing
‚Ä¢ And replacing it with a larger thing.
‚Ä¢ You could have TiBs of memory and this will be a problem.

stack

available memory

‚Ä¢ This affects performance: (in terms of writes:)
‚Ä¢ Appending item arr[0]: ùëÇ 1
‚Ä¢ Appending item arr[1]: ùëÇ 1
‚Ä¢ ‚Ä¶
‚Ä¢ Appending item arr[99]: ùëÇ 1
‚Ä¢ Appending item arr[100]: ùëÇ ùëõ + 1 oh no!

‚Ä¢ When you would overflow the buffer‚Ä¶
‚Ä¢ You then need to copy all previous values as well.

old
data:
int arr[100]
int
arr[100]

heap
13

Stressing it out: Performance Consistency
‚Ä¢ Big arrays want to be continuous.
‚Ä¢ Ensuring continuous space is difficult when you do not know
how much you will ultimately need.

‚Ä¢ This is exactly why linked lists exist!

stack

available memory

‚Ä¢ Since a linked list allocates on every append.
‚Ä¢ Each append takes the same amount of time.

‚Ä¢ However, everything is a trade-off.
‚Ä¢ Dang it!!!
‚Ä¢ One cost is extra overhead for metadata.
‚Ä¢ Linked list traversal can stress memory caches.
‚Ä¢ It means traversing the array is slower.
‚Ä¢ However, we will mostly ignore this for now.

old
data:
int arr[100]
int
arr[100]

heap
14

The Linked List
A story about trade-offs.

15

What is a linked list?
‚Ä¢ A linked list is a non-continuous data structure representing an ordered list.
‚Ä¢ Each item in the linked list is represented by metadata called a node.
‚Ä¢ This metadata indirectly refers to the actual data.
‚Ä¢ Furthermore, it indirectly refers to at least one other item in the list.

Node

‚Äústruct‚Äù required since
Node is not technically
defined until after it is
defined!

16

Keeping ahead of the list.
‚Ä¢ Creation of a list occurs when one allocates a single node and tracks it in a
pointer. This is the head of our list (first element.)

Node

17

Adding some links to our chain
‚Ä¢ If we want to append an item, we can add a node anywhere!

‚Äútail‚Äù

‚Äúnode‚Äù

Remember the
‚Äò\0‚Äô sentinel!

18

We can add them anywhere!!
‚Ä¢ Consider what happens if we update our append to take any Node:

‚ÄúcurNode‚Äù

‚Äúnode‚Äù

Tail

19

We can add them anywhere!!
‚Ä¢ This function has very consistent performance (constant time):

‚Ä¢ The append always allocates the same amount.
‚Ä¢ It always copies the same amount.
‚Ä¢ Compare to a big array where you may have to copy the entire thing to
append something new!

Traversal‚Ä¶ on the other hand‚Ä¶
‚Ä¢ Accessing an array element is generally very simple.
‚Ä¢
is the same as
because its location is very well-known!
‚Ä¢ This is because array items are continuous in memory. Not true for linked lists!

‚Ä¢ Here is a function that performs the equivalent for linked lists:

Q: How many times is memory accessed relative to the requested index?

21

Removing‚Ä¶ on the other, other hand!
‚Ä¢ One nice thing about linked lists
is their flexibility to changing
shape.
‚Ä¢ I used to be able to bend a lot
better, too, when I was in my 20s.
Alas.
Can‚Äôt find item at index.
We are deleting the head.

‚Ä¢ Since we don‚Äôt have a way to go
‚Äúbackward‚Äù
‚Ä¢ We first find the node we want to
delete (
)
‚Ä¢ Keeping track of the node of
‚Äì (
)
‚Ä¢ Rewire
to cut out
.

Returns new head (or old head if unchanged).

22

Removing‚Ä¶ on the other, other hand!
‚Ä¢ This looks complex, but it really is
a simple traversal.
‚Ä¢ So it takes ùëÇ ùëõ to find the item.
‚Ä¢ And it performs a simple update
and deallocation. (quick to do)

‚Ä¢ A big array, on the other hand.
‚Ä¢ It can find the element to remove
immediately.
‚Ä¢ However, removing it means
shifting over every item after it left.
‚Ä¢ That can be an expensive update!
(Memory is slow!!)
23

On your own!

Think about the code you would need to do any of the following:
‚Ä¢ Delete/free the entire linked list.
‚Ä¢ Sort a linked list.
‚Ä¢ Append a linked list to an existing one.
‚Ä¢ Copy a subset of a linked list to a new list.
Often, operations can be abstracted in such a way that all of these can be written relatively
simply.
Consider the performance of these operations compared to an Array.
24

Linked lists ‚Ä¶ link you ‚Ä¶ to the world!
‚Ä¢ Consider how much cleaner you can make certain operations if you tracked the
previous node as well.
‚Ä¢ This is a doubly linked list.
‚Ä¢ This is typically ‚Äúdouble-ended‚Äù as well: keeping track of both head and tail.

Node

Node

Node

25

Seeing the trees through the forest
‚Ä¢ A binary tree can be represented by the same nodes as a linked list.
‚Ä¢ In this case, you have a left and right child node instead of next and prev.
Node

‚Ä¢ The operations are
very different, though.

Node

Node

Node

26

De-Stressing it out: Linked Lists
‚Ä¢ We know big arrays want to be continuous.
‚Ä¢ However, ensuring continuous space is difficult when you do
not know how much you will ultimately need.

‚Ä¢ Linked lists allocate very small chunks of metadata.
‚Ä¢ These chunks can be allocated easily on-demand.
‚Ä¢ And then deallocated without creating wide gaps.

stack

available memory

‚Ä¢ This reduces fragmentation.
‚Ä¢ Deallocating always leaves a small amount of room.
‚Ä¢ It is always the exact amount needed to append!
‚Ä¢ However, it is all at the expense of complexity!
‚Ä¢ And traversal can be expensive (but we can find ways to deal
with that.)

some other data

heap
27

Implementing Malloc
It really sounds like some kind of He-Man or She-Ra villain of the week.

28

The malloc essentials
‚Ä¢ The
following:

stack

function does the

‚Ä¢ Allocates memory of at least
bytes.
‚Ä¢ Returns the address to that block of memory (or
error)

on

available memory

‚Ä¢ Essentially, your program has a potentially large chunk of
memory.
‚Ä¢ The
function tears off a piece of the chunk.
‚Ä¢ Also
must then allow that chunk to be reused.
‚Ä¢ The job of
is to do so in the ‚Äúbest‚Äù way to reduce
fragmentation.
We want to avoid fragmentation
29

Choosing where to allocate
‚Ä¢ Our first problem is, when
we tear off a chunk?

is called, where do

‚Ä¢ We can do a few simple things:
‚Ä¢ First-Fit: start at lowest address, find first available section.

stack
available memory

‚Ä¢ Fast, but small blocks clog up the works.

‚Ä¢ Next-fit: Do ‚ÄúFirst-Fit‚Äù but start where we last allocated.
‚Ä¢ Fast and spreads small blocks around a little better.

‚Ä¢ Best-Fit: laboriously look for the smallest available section to
divide up.

Last Allocated

‚Ä¢ Slow, but limits fragmentation.

???
30

Managing that metadata!
‚Ä¢ You have a whole section of memory to divide up.
‚Ä¢ You need to keep track of what is allocated and what is free.
‚Ä¢ One of the least complicated ways of doing so is to use‚Ä¶ hmm‚Ä¶
‚Ä¢ A linked list! (or two!) We know how to do this!!

‚Ä¢ We can treat each allocated block (and each empty space) as a node in a linked
list.
‚Ä¢ Allocating memory is just appending a node to our list.

‚Ä¢ The trick is to think about how we want to split up the nodes representing
available memory.

31

Tracking memory: Our fresh new world.
‚Ä¢ Let‚Äôs orient our memory visually horizontally.
‚Ä¢ We have control over EVERY byte of it. We can place metadata ANYWHERE.

‚Ä¢ Every

is responsible for allocating a block of memory.

‚Ä¢ How, then, do we manage where things are allocated and where is empty space?
‚Ä¢ We can have ‚Äúallocation‚Äù reduce to creating a new node in a linked list.

available memory

We have the power to write data ANYWHERE!
So where do linked list nodes go?

32

Linked lists are our friend, here
‚Ä¢ We will augment our normal doubly linked list to be useful for tracking the size of
the block it represents. (an explicit list allocator)
‚Ä¢ Here, we will maintain a single linked lists of all allocated or free blocks.
‚Ä¢ The size field denotes how big the block is (how much is used/available.)
‚Ä¢ We need to know when a block represents allocated space or if it is free.
‚Ä¢ Hmm‚Ä¶ we could use a single bit to denote that. Or‚Ä¶ negativity!
‚Ä¢ The

is NEVER

. In fact,

fails when requesting size of

.

AllocNode

We can make other clever
space optimizations, but we
will start with this.

Signed! Negative number
means a free block.

33

Tracking memory: High level metadata
‚Ä¢ We can keep track of used/empty spaces cheaply by having linked list nodes
at the beginning of them. The nodes track the size of the space.
‚Ä¢ Here we have an allocated block followed by a free and then allocated block.
‚Ä¢ The metadata for the linked list is just smashed into the block itself.

available memory

Q: What happens when we write over the block boundary?

34

Implementing
‚Ä¢ To allocate some amount of space, we find a free block that is at least that
size + metadata size. (Which one? Well, first-fit and friends apply!)
‚Ä¢ Then we will want to split that free block.
x

x

x

available memory

35

Implementing
Carefully negate size

‚Ä¢ Allocating means finding a free
block big enough.
‚Ä¢ Including the metadata size.

‚Ä¢ Then splitting it into a used block
and a smaller free block.
Linked list traversal; ùëÇ(ùëõ)

‚Ä¢ This is incomplete. (Why?)

Linked list append; ùëÇ(1)

‚Ä¢ (you don‚Äôt always split)

Recall that we made size
negative for a free block.
Positive means non-free.
is negative.
Think about it!
Q: This is first-fit. What should be added to implement next-fit? Best-fit?
36

Implementing
‚Ä¢ When freeing the middle block, you will create empty space.
‚Ä¢ Consider allocations‚Ä¶ it‚Äôs somewhat difficult to see the empty space.
‚Ä¢ You have ‚Äúfalse fragmentation,‚Äù so you will want to merge adjacent free blocks.

available memory

37

Implementing
‚Ä¢ So, when we free blocks, we look to the left. We look to the right.
‚Ä¢ We coalesce the newly free block with ANY adjacent free blocks.
‚Ä¢ First one‚Ä¶
‚Ä¢ Then the other. (And it is linked list node removal; a constant time operation!)

available memory

38

Implementing
Header is just before ptr

‚Ä¢ Finding the header metadata
node is simple.
‚Ä¢ Look at our

‚Ä¢

‚Äôs

.

is slightly less complex.
‚Ä¢ It does not have to search.

‚Ä¢ Where
‚Ä¢

Resembles linked list
delete; ùëÇ(1)

splits nodes
merges them.

‚Ä¢ Whenever a block is freed next
to an existing one‚Ä¶
‚Ä¢ It should merge them!

However it subtracts from size
(which makes reflect a larger space)

‚Ä¢ Consider how much a doubly
linked list helped.
Q: Are any changes required here for best-fit?

39

Thinking about next-fit

‚Ä¢ With a typical first-fit version of the malloc function‚Ä¶
‚Ä¢ We can now consider simple improvements.
‚Ä¢ Traversing the list is expensive! ùëÇ ùëõ !

‚Ä¢ Next-fit helps because we start from the last allocated item.
‚Ä¢ Generally, what do you think comes after the last allocated item.
‚Ä¢ Consider the normal operation‚Ä¶
‚Ä¢ It splits the node and creates free space.

‚Ä¢ Therefore, seems likely free space will exist near the last allocation.
‚Ä¢ Perhaps causing the average case for malloc to bias itself toward ùëÇ(1)
‚Ä¢ However, all strategies have their own worst-case!!
‚Ä¢ Think about what that might be.

40

Thinking about best-fit
‚Ä¢ Best-fit, on the other hand, is not about avoiding traversal.
‚Ä¢ Instead, we focus on fragmentation.

‚Ä¢ Allocating anywhere means worst-case behavior splits nodes poorly.
‚Ä¢ If we find a PERFECT fit, we remove fragmentation.

‚Ä¢ Traversal is still bad‚Ä¶ and we brute force the search...
‚Ä¢ But, hey, solve one problem, cause another. That‚Äôs systems!
‚Ä¢ Fragmentation may indeed be a major issue on small memory systems.

‚Ä¢ What is the best of both worlds? Next-fit + Best-fit?
‚Ä¢ Hmm.
‚Ä¢ Works best if you keep large areas open.
CS/COE 0449 ‚Äì Spring 2019/2020

41

Other thoughts
‚Ä¢ Don‚Äôt need
pointers since adding size to the block‚Äôs address will also
move there. (unusually, the linked list is always ordered!)
‚Ä¢ You don‚Äôt need to keep the used blocks in the list.
‚Ä¢ More complex to understand but removes implementation complexity.
‚Ä¢ Free nodes point to the next and previous free nodes. Used nodes point to their
neighbors. Traversal is improved since it only visits free nodes; still ùëÇ(ùëõ)

‚Ä¢ The idea is to only keep track of necessary metadata.
‚Ä¢ You only coalesce when free blocks are adjacent.
‚Ä¢ With a list of only free blocks, you can easily tell when that condition is met‚Ä¶
‚Ä¢ just see if

is the same address as

‚Ä¢ The only other concern is getting from a used block you want to free to its
neighboring free block. So those have normal pointers.

42

Explicit free lists: giving you VIP access
‚Ä¢ When you allocate, you go through the free list.
‚Ä¢ You don‚Äôt care about allocated nodes.

‚Ä¢ When you free, you only care about coalescing neighbors.

available memory

Q: Do free nodes need a

pointer?

43

Trees are your buddy

‚Ä¢ Recall that we easily took the ideas around linked lists and made binary trees.
‚Ä¢ You can manage memory with a binary tree as well.

‚Ä¢ This is called a buddy allocator.

45

Divide and conquer
‚Ä¢ Buddy allocators divide memory into halves that are powers of two.
‚Ä¢ Can cause internal fragmentation

‚ñ™ The total memory,
, is a
power of two.
‚ñ™ Each split is, then, also a
power of two.

Allocation is not a power of two: internal fragmentation

46

Allocating with trees
‚Ä¢ Assuming

is

, and we allocate 242MiB:

‚Ä¢ We travel left until we find a block
that fits.

‚ñ™ We travel back up when we can‚Äôt go
further left and go right.
‚ñ™ When we find a
unsplit node that
fits, we allocate
there.

47

Burying the hatchet: Chopping the trees
‚Ä¢ Let‚Äôs allocate 64MiB. So nice, we will allocate it twice.
‚Ä¢ Again a depth-first search to find
the first unsplit node that fits us.

‚ñ™ This node is fine! Allocate that!
‚ñ™ Do it again!
‚ñ™ When we find a
unsplit node that is
too big, we split in
half and keep going.

CS/COE 0449 ‚Äì Spring 2019/2020

48

Coalescing friendships (animated)
‚Ä¢ Coalescing happens because every block has a buddy!
‚Ä¢ When both sides of a split node
are free, coalesce them!

‚ñ™ If this keeps happening, it will
coalesce larger spaces.
‚ñ™ Repeating as
much as
necessary.

x

x

x
49

Thinking like an arborist (but only if you are feeling listless)
‚Ä¢ How does a tree-based
allocation system deal with
fragmentation?
‚Ä¢ What are some immediate
drawbacks from using a
tree scheme?

available
memory

‚Ä¢ Can you imagine a
possibility of using a
hybrid approach?
50

Lies and Damned Lies!
‚Ä¢ Does your program actually own all of memory?
‚Ä¢ On modern systems, absolutely heckin not.

‚Ä¢ Your program still has to request memory allocations from the OS.
‚Ä¢ Generally,
takes on this responsibility behind the scenes.
‚Ä¢ In Linux, you request pages in the normal heap in LIFO order with
‚Ä¢ Or, you request specific virtual memory pages with
.

.

‚Ä¢ What is a segmentation fault.
‚Ä¢ Segments are the ‚Äúcode‚Äù, ‚Äúdata‚Äù, ‚Äúheap‚Äù separation. You fault by doing something
the segment does not allow. (write to read-only memory)
‚Ä¢ A historic misnomer since we actually have paging, not segmented memory.

‚Ä¢ What is a ‚Äúpage‚Äù? Virtual memory??
‚Ä¢ It replaced segments and is part of the much grander lie about sharing memory
with multiple applications at the same time. More on this later!

51

I want to know MORE
‚Ä¢ If you find this topic interesting, it is a WIDE area of research.
‚Ä¢ Malloc is generally more complex or specialized these days than the options
here.
‚Ä¢ Or some kind of hybrid, as the need arises.

‚Ä¢ The Linux kernel makes use of a Slab Allocator
‚Ä¢ https://en.wikipedia.org/wiki/Slab_allocation

‚Ä¢ Modern C (glibc) uses a hybrid malloc:
‚Ä¢ https://www.gnu.org/software/libc/manual/html_node/The-GNU-Allocator.html

‚Ä¢ Professor Knuth has written about several classic algorithms.
‚Ä¢ Buddy Allocation comes from the 60s. Groovy.
52

